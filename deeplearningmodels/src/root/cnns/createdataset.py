from PIL import Image
import io
import math
from matplotlib.pyplot import plot, title, xlabel, ylabel, savefig, legend
import numpy
from os import listdir
import os
from scipy import stats
from shutil import copyfile
import sys

import matplotlib.pyplot as plt
import numpy as np
from matplotlib import cm
from PIL import Image


# import cv2
width = 32
height = 32
#width = 1024
#height = 1024
length = 3073

# width = 224
# height = 224

#width = 300
#height = 100

# perfmetric = "precision"
# perfmetric = "recall"
perfmetric = "f1score"
# perfmetric = "tpr"
# perfmetric = "fpr"
executeonserver = False



def partitoner(Dir):
    os.chdir(Dir)
    
#     InDir = Dir + 'LabelledData/'
#     classdirs = ['BrownDog/','BlackDog/']
# 
#     TrainOutDir = Dir + 'TrainSplit/'
#     TestOutDir = Dir + 'TestSplit/'
#     percent = 0.8


    InDir = Dir + 'LabelledData/'
    classdirs = ['7/','9/']
#     classdirs = ['6/','8/']
#     classdirs = ['4/','1/']
    
#     classdirs = ['2/','8/']
#     classdirs = ['3/','8/']
#     classdirs = ['4/','9/']
#     classdirs = ['2/','6/']
#     classdirs = ['5/','8/']

    TrainOutDir = Dir + 'TrainSplit/'
    TestOutDir = Dir + 'TestSplit/'
    percent = 0.5

    for dir in classdirs:
        files = listdir(InDir + dir)
        
        splitind = int(math.floor(percent*len(files)))
        trainfiles = files[0:splitind]
        testfiles = files[splitind:]
    
        for file in trainfiles:
            copyfile(InDir+dir+file, TrainOutDir+dir+file)

        for file in testfiles:
            copyfile(InDir+dir+file, TestOutDir+dir+file)

def resizer(CurrDir):
    os.chdir(CurrDir)
    for f in listdir(CurrDir):
        
        img = Image.open(f)
        print(img.size)
        image = img.resize((width,height), Image.ANTIALIAS)
        image.save(CurrDir + f)
        print(img.size)
        
        
# def colourtograyscale(InDir,OutDir):
#     os.chdir(InDir)
#     for f in listdir(InDir):
#         img = Image.open(f)
#         # http://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python
#         # http://stackoverflow.com/questions/9506841/using-python-pil-to-turn-a-rgb-image-into-a-pure-black-and-white-image
        


def binarizer(CurrDir,ValDir,OutFile): 
    # resizer and binarizer have same directory
    # Pixel value is in the form (R,G,B) where R,G,B belongs in the range 0,255
    ind = 0
    L = []
    os.chdir(CurrDir)
    binfile = open(OutFile, 'wb')
    os.chdir(CurrDir + ValDir)
    ls = listdir(CurrDir + ValDir)
    ls.sort()
    for d in ls:
        os.chdir(CurrDir + ValDir + d)
        for f in listdir(CurrDir + ValDir + d):
            if not executeonserver:
                img = Image.open(f)
                l = numpy.insert(numpy.array(img.getdata()).flatten(order='F'),0, ind)
            else:
                img = cv2.imread(f)
                l = numpy.insert(numpy.array(img).flatten(order='F'),0, ind)
            if(len(l) == length):
                L.append(l)
        ind = ind + 1
    
    print(len(L)*length)
    print(len(numpy.concatenate(L)))
    
    numpy.concatenate(L).astype('int16').tofile(binfile)
#     file.write(numpy.concatenate(L).astype('int16'))
    binfile.close()
    
    
def generatereports():
#     rls = [(1, 0, 1, 0.5008010253123999, {'recall': 0.5127952755905512, 'fpr': 0.16724774405250206, 'f1score': 0.5008010253123999, 'precision': 0.48935504070131497, 'tpr': 0.5127952755905512}, 0), (0, 0, 1, 0.6223674655047204, {'recall': 0.8410206084396468, 'fpr': 0.07452678040913335, 'f1score': 0.6223674655047204, 'precision': 0.49394812680115274, 'tpr': 0.8410206084396468}, 0), (1.261150870056856, 0.5171407731582787, 0.25598990310142256, 0.5171407731582787, {'recall': 0.5283159463487332, 'fpr': 0.13661526294978252, 'f1score': 0.5171407731582787, 'precision': 0.5064285714285715, 'tpr': 0.5283159463487332}, 0), (1.2981137407009944, 0.5251798561151079, 0.22706611541411337, 0.5251798561151079, {'recall': 0.5423476968796433, 'fpr': 0.13929560743965175, 'f1score': 0.5251798561151079, 'precision': 0.5090655509065551, 'tpr': 0.5423476968796433}, 1), (1.2981137407009944, 0.5251798561151079, 0.22706611541411337, 0.5251798561151079, {'recall': 0.5423476968796433, 'fpr': 0.13929560743965175, 'f1score': 0.5251798561151079, 'precision': 0.5090655509065551, 'tpr': 0.5423476968796433}, 2), (0, 0.5251798561151079, 1.5251798561151078, 0.6334647079899678, {'recall': 0.8516377649325626, 'fpr': 0.07388199285835742, 'f1score': 0.6334647079899678, 'precision': 0.5042783799201369, 'tpr': 0.8516377649325626}, 3), (0, 0.5251798561151079, 1.5251798561151078, 0.6280575539568345, {'recall': 0.8500486854917235, 'fpr': 0.07474730315127835, 'f1score': 0.6280575539568345, 'precision': 0.4980034227039361, 'tpr': 0.8500486854917235}, 3)]
#     gen = 3
#     numgens = 10
#     numalphas = 20
#     myepsilon = 0.001
#     mylambda = 1
#     final_payoff = 1.2981137407009944

#     rls = [(1, 0, 1, 0.5023211141347848, {'recall': 0.5135842880523731, 'fpr': 0.16654694715238583, 'f1score': 0.5023211141347848, 'precision': 0.49154135338345867, 'tpr': 0.5135842880523731}, 0), (0, 0, 1, 0.6268980477223427, {'recall': 0.8458536585365853, 'fpr': 0.07422505307855626, 'f1score': 0.6268980477223427, 'precision': 0.49798966111430215, 'tpr': 0.8458536585365853}, 0), (1.2612787655263276, 0.5346112886048988, 0.27333252307857125, 0.5346112886048988, {'recall': 0.555719557195572, 'fpr': 0.14053518334985135, 'f1score': 0.5346112886048988, 'precision': 0.5150478796169631, 'tpr': 0.555719557195572}, 0), (1.2548944738611418, 0.5183836912995996, 0.26348921743845777, 0.5183836912995996, {'recall': 0.530156366344006, 'fpr': 0.1368400237294839, 'f1score': 0.5183836912995996, 'precision': 0.5071225071225072, 'tpr': 0.530156366344006}, 1), (1.213784390606654, 0.5161290322580645, 0.3023446416514104, 0.5161290322580645, {'recall': 0.5230312035661219, 'fpr': 0.13415116739216462, 'f1score': 0.5161290322580645, 'precision': 0.5094066570188133, 'tpr': 0.5230312035661219}, 2), (1.1541369357660634, 0.5228758169934641, 0.3687388812274006, 0.5228758169934641, {'recall': 0.5325443786982249, 'fpr': 0.13510301109350237, 'f1score': 0.5228758169934641, 'precision': 0.5135520684736091, 'tpr': 0.5325443786982249}, 3), (1.1541369357660634, 0.5228758169934641, 0.3687388812274006, 0.5228758169934641, {'recall': 0.5325443786982249, 'fpr': 0.13510301109350237, 'f1score': 0.5228758169934641, 'precision': 0.5135520684736091, 'tpr': 0.5325443786982249}, 4), (0, 0.5228758169934641, 1.522875816993464, 0.6276060388209921, {'recall': 0.8533724340175953, 'fpr': 0.07523138320455125, 'f1score': 0.6276060388209921, 'precision': 0.496304718590108, 'tpr': 0.8533724340175953}, 5), (0, 0.5228758169934641, 1.522875816993464, 0.6211135213304411, {'recall': 0.8504950495049505, 'fpr': 0.07608142493638677, 'f1score': 0.6211135213304411, 'precision': 0.4891799544419134, 'tpr': 0.8504950495049505}, 5)]
#     gen = 5
#     numgens = 10
#     numalphas = 20
#     myepsilon = 0.0001
#     mylambda = 1
#     final_payoff = 1.1541369357660634
 
#     rls = [(1, 0, 1, 0.5114878783077167, {'recall': 0.5238558909444986, 'fpr': 0.1662722502315053, 'f1score': 0.5114878783077167, 'precision': 0.4996904024767802, 'tpr': 0.5238558909444986}, 0), (0, 0, 1, 0.6286539155539517, {'recall': 0.8481012658227848, 'fpr': 0.07415272233075682, 'f1score': 0.6286539155539517, 'precision': 0.4994266055045872, 'tpr': 0.8481012658227848}, 0), (0.7453612461976168, 0.05208863058481657, 0.3067273843871997, 0.5208863058481656, {'recall': 0.532293986636971, 'fpr': 0.1363546408074411, 'f1score': 0.5208863058481656, 'precision': 0.5099573257467994, 'tpr': 0.532293986636971}, 0), (0.7379801618702354, 0.05373665480427047, 0.31575649293403496, 0.5373665480427047, {'recall': 0.5527086383601757, 'fpr': 0.13686928883591576, 'f1score': 0.5373665480427047, 'precision': 0.5228531855955678, 'tpr': 0.5527086383601757}, 1), (0.6984292027158623, 0.05024082993701371, 0.35181162722115134, 0.5024082993701371, {'recall': 0.5124716553287982, 'fpr': 0.13748276541264526, 'f1score': 0.5024082993701371, 'precision': 0.49273255813953487, 'tpr': 0.5124716553287982}, 2), (0.6984292027158623, 0.05024082993701371, 0.35181162722115134, 0.5024082993701371, {'recall': 0.5124716553287982, 'fpr': 0.13748276541264526, 'f1score': 0.5024082993701371, 'precision': 0.49273255813953487, 'tpr': 0.5124716553287982}, 3), (0, 0.05024082993701371, 1.0502408299370136, 0.6289803220035778, {'recall': 0.860078277886497, 'fpr': 0.07590422822210902, 'f1score': 0.6289803220035778, 'precision': 0.4957698815566836, 'tpr': 0.860078277886497}, 4), (0, 0.05024082993701371, 1.0502408299370136, 0.6198406951484432, {'recall': 0.8475247524752475, 'fpr': 0.07599660729431722, 'f1score': 0.6198406951484432, 'precision': 0.4885844748858447, 'tpr': 0.8475247524752475}, 4)]
#     gen = 4
#     numgens = 10
#     numalphas = 20
#     myepsilon = 0.0001
#     mylambda = 0.1
#     final_payoff = 0.6984292027158623
 
#     rls = [(1, 0, 1, 0.508301404853129, {'recall': 0.5158781594296824, 'fpr': 0.16326950792670372, 'f1score': 0.508301404853129, 'precision': 0.500943989930774, 'tpr': 0.5158781594296824}, 0), (0, 0, 1, 0.6295364714337046, {'recall': 0.8504854368932039, 'fpr': 0.07451146983857264, 'f1score': 0.6295364714337046, 'precision': 0.4997147746719909, 'tpr': 0.8504854368932039}, 0), (1.3159476296722432, 0.5241528478731075, 0.20820521820086424, 0.5241528478731075, {'recall': 0.5401188707280832, 'fpr': 0.13870201820340325, 'f1score': 0.5241528478731075, 'precision': 0.5091036414565826, 'tpr': 0.5401188707280832}, 0), (1.27991153365847, 0.5305826999638075, 0.25067116630533737, 0.5305826999638075, {'recall': 0.535427319211103, 'fpr': 0.1313854104551779, 'f1score': 0.5305826999638075, 'precision': 0.5258249641319943, 'tpr': 0.535427319211103}, 1), (1.27991153365847, 0.5305826999638075, 0.25067116630533737, 0.5305826999638075, {'recall': 0.535427319211103, 'fpr': 0.1313854104551779, 'f1score': 0.5305826999638075, 'precision': 0.5258249641319943, 'tpr': 0.535427319211103}, 2), (0, 0.5305826999638075, 1.5305826999638075, 0.6349319971367215, {'recall': 0.8553519768563163, 'fpr': 0.07396072430502423, 'f1score': 0.6349319971367215, 'precision': 0.5048377916903813, 'tpr': 0.8553519768563163}, 3), (0, 0.5305826999638075, 1.5305826999638075, 0.6240928882438317, {'recall': 0.8414872798434442, 'fpr': 0.07420614705382918, 'f1score': 0.6240928882438317, 'precision': 0.49596309111880044, 'tpr': 0.8414872798434442}, 3)]
#     gen = 3
#     numgens = 20
#     numalphas = 100
#     myepsilon = 0.0001
#     mylambda = 1
#     final_payoff = 1.27991153365847


#     rls = [(1, 0, 1, 0.5856910569105691, {'recall': 0.5856910569105691, 'fpr': 0.17902313624678665, 'f1score': 0.5443554480882575, 'precision': 0.5084697910784868, 'tpr': 0.5856910569105691}, 0), (0, 0, 1, 0.8013500482160077, {'recall': 0.8013500482160077, 'fpr': 0.13015387231148517, 'f1score': 0.4889673433362754, 'precision': 0.35182049110922947, 'tpr': 0.8013500482160077}, 0), (3.363583381722767, 2.6067961165048543, 0.24321273478208738, 0.5213592233009708, {'recall': 0.5213592233009708, 'fpr': 0.16498455200823892, 'f1score': 0.5111851499286054, 'precision': 0.5014005602240896, 'tpr': 0.5213592233009708}, 0), (3.363583381722767, 2.6067961165048543, 0.24321273478208738, 0.5213592233009708, {'recall': 0.5213592233009708, 'fpr': 0.16498455200823892, 'f1score': 0.5111851499286054, 'precision': 0.5014005602240896, 'tpr': 0.5213592233009708}, 1), (3.363583381722767, 2.6067961165048543, 0.24321273478208738, 0.8250728862973761, {'recall': 0.8250728862973761, 'fpr': 0.2086483731203806, 'f1score': 0.39178587909552376, 'precision': 0.2568835098335855, 'tpr': 0.8250728862973761}, 2), (3.363583381722767, 2.6067961165048543, 0.24321273478208738, 0.8488714425907753, {'recall': 0.8488714425907753, 'fpr': 0.08488243782361429, 'f1score': 0.5998613037447988, 'precision': 0.46380697050938335, 'tpr': 0.8488714425907753}, 2)]
#     gen = 2
#     numgens = 20
#     numalphas = 20
#     myepsilon = 0.0001
#     mylambda = 5
#     final_payoff = 3.363583381722767

#     rls = [(1, 0, 1, 0.6054776654711445, {'recall': 0.6054776654711445, 'fpr': 0.18319120517825954, 'f1score': 0.5537498136275533, 'precision': 0.5101648351648351, 'tpr': 0.6054776654711445}, 0), (0, 0, 1, 0.8079601990049752, {'recall': 0.8079601990049752, 'fpr': 0.13225943196269604, 'f1score': 0.4809002072845721, 'precision': 0.342327150084317, 'tpr': 0.8079601990049752}, 0), (6.127252532218103, 5.349740932642487, 0.22248840042438456, 0.5349740932642487, {'recall': 0.5349740932642487, 'fpr': 0.16989291598023065, 'f1score': 0.5170579029733959, 'precision': 0.5003028467595396, 'tpr': 0.5349740932642487}, 0), (6.127252532218103, 5.349740932642487, 0.22248840042438456, 0.5349740932642487, {'recall': 0.5349740932642487, 'fpr': 0.16989291598023065, 'f1score': 0.5170579029733959, 'precision': 0.5003028467595396, 'tpr': 0.5349740932642487}, 1), (6.127252532218103, 5.349740932642487, 0.22248840042438456, 0.831041257367387, {'recall': 0.831041257367387, 'fpr': 0.1116958071634697, 'f1score': 0.5320754716981132, 'precision': 0.391304347826087, 'tpr': 0.831041257367387}, 2), (6.127252532218103, 5.349740932642487, 0.22248840042438456, 0.8449612403100775, {'recall': 0.8449612403100775, 'fpr': 0.07741332426920462, 'f1score': 0.6195381882770871, 'precision': 0.4890633763320247, 'tpr': 0.8449612403100775}, 2)]
#     gen = 2
#     numgens = 20
#     numalphas = 20
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 6.127252532218103
 
#     rls = [(1, 0, 1, 0.6004507405022537, {'recall': 0.6004507405022537, 'fpr': 0.176810398184444, 'f1score': 0.5579655946148093, 'precision': 0.5210952780106175, 'tpr': 0.6004507405022537}, 0), (0, 0, 1, 0.7967244701348748, {'recall': 0.7967244701348748, 'fpr': 0.11945247406903588, 'f1score': 0.5058103975535169, 'precision': 0.37051971326164873, 'tpr': 0.7967244701348748}, 0), (0.9312022099987701, 0.3583955829814875, 0.4271933729827174, 0.716791165962975, {'recall': 0.716791165962975, 'fpr': 0.22065631107910708, 'f1score': 0.5939981160005383, 'precision': 0.5071231617647058, 'tpr': 0.716791165962975}, 0), (0.9312022099987701, 0.3583955829814875, 0.4271933729827174, 0.716791165962975, {'recall': 0.716791165962975, 'fpr': 0.22065631107910708, 'f1score': 0.5939981160005383, 'precision': 0.5071231617647058, 'tpr': 0.716791165962975}, 1), (0.9312022099987701, 0.3583955829814875, 0.4271933729827174, 0.7902439024390244, {'recall': 0.7902439024390244, 'fpr': 0.2783864118895966, 'f1score': 0.3168394289067084, 'precision': 0.19814090019569472, 'tpr': 0.7902439024390244}, 2), (0.9312022099987701, 0.3583955829814875, 0.4271933729827174, 0.8099415204678363, {'recall': 0.8099415204678363, 'fpr': 0.1597587905554612, 'f1score': 0.4446227929373997, 'precision': 0.3064159292035398, 'tpr': 0.8099415204678363}, 2)]
#     gen = 2
#     numgens = 20
#     numalphas = 20
#     myepsilon = 0.0001
#     mylambda = 0.5
#     final_payoff = 0.9312022099987701
 
#     rls = [(1, 0, 1, 0.6026597469996756, {'recall': 0.6026597469996756, 'fpr': 0.17700936503035916, 'f1score': 0.5578741930641045, 'precision': 0.519284516489659, 'tpr': 0.6026597469996756}, 0), (0, 0, 1, 0.8170254403131115, {'recall': 0.8170254403131115, 'fpr': 0.13652572592969944, 'f1score': 0.481962481962482, 'precision': 0.3417928776094965, 'tpr': 0.8170254403131115}, 0), (6.228078541076723, 5.647058823529411, 0.41898028245268826, 0.5647058823529412, {'recall': 0.5647058823529412, 'fpr': 0.17679671457905544, 'f1score': 0.5308755760368664, 'precision': 0.5008695652173913, 'tpr': 0.5647058823529412}, 0), (6.5879960730072655, 5.940983606557378, 0.35298753355011225, 0.5940983606557377, {'recall': 0.5940983606557377, 'fpr': 0.18471794871794872, 'f1score': 0.5438991445294912, 'precision': 0.5015222806531968, 'tpr': 0.5940983606557377}, 1), (9.930350804077625, 9.246018849528761, 0.3156680454511367, 0.9246018849528762, {'recall': 0.9246018849528762, 'fpr': 0.3210943124550036, 'f1score': 0.6291463954002654, 'precision': 0.4767890062007709, 'tpr': 0.9246018849528762}, 2), (9.930350804077625, 9.246018849528761, 0.3156680454511367, 0.9246018849528762, {'recall': 0.9246018849528762, 'fpr': 0.3210943124550036, 'f1score': 0.6291463954002654, 'precision': 0.4767890062007709, 'tpr': 0.9246018849528762}, 3), (9.930350804077625, 9.246018849528761, 0.3156680454511367, 0.7, {'recall': 0.7, 'fpr': 0.3576890399320306, 'f1score': 0.24190572051669182, 'precision': 0.14621780571892112, 'tpr': 0.7}, 4), (9.930350804077625, 9.246018849528761, 0.3156680454511367, 0.8568646543330087, {'recall': 0.8568646543330087, 'fpr': 0.07551176420623461, 'f1score': 0.6294706723891274, 'precision': 0.497456189937818, 'tpr': 0.8568646543330087}, 4)]
#     gen = 4
#     numgens = 20
#     numalphas = 50
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 9.930350804077625
 
#     rls = [(1, 0, 1, 0.5755418958265933, {'recall': 0.5755418958265933, 'fpr': 0.17458028633226902, 'f1score': 0.541964965727342, 'precision': 0.5120898100172712, 'tpr': 0.5755418958265933}, 0), (0, 0, 1, 0.8154296875, {'recall': 0.8154296875, 'fpr': 0.13612432065217392, 'f1score': 0.4823801270941652, 'precision': 0.3424938474159147, 'tpr': 0.8154296875}, 0), (6.313700201551771, 5.651612903225807, 0.3379127016740364, 0.5651612903225807, {'recall': 0.5651612903225807, 'fpr': 0.17051546391752578, 'f1score': 0.538579772517676, 'precision': 0.5143863769817968, 'tpr': 0.5651612903225807}, 0), (8.290367996601207, 7.940026075619296, 0.6496580790180904, 0.7940026075619296, {'recall': 0.7940026075619296, 'fpr': 0.23479243732018085, 'f1score': 0.6254974964693799, 'precision': 0.5159923744969286, 'tpr': 0.7940026075619296}, 1), (6.932056298963911, 6.685100845803513, 0.7530445468396021, 0.6685100845803513, {'recall': 0.6685100845803513, 'fpr': 0.18537939543491672, 'f1score': 0.5929024812463936, 'precision': 0.5326594090202177, 'tpr': 0.6685100845803513}, 2), (9.534734166208114, 9.174725983236621, 0.6399918170285073, 0.9174725983236621, {'recall': 0.9174725983236621, 'fpr': 0.3109919571045576, 'f1score': 0.6349843819723338, 'precision': 0.4854998294097578, 'tpr': 0.9174725983236621}, 3), (9.534734166208114, 9.174725983236621, 0.6399918170285073, 0.9174725983236621, {'recall': 0.9174725983236621, 'fpr': 0.3109919571045576, 'f1score': 0.6349843819723338, 'precision': 0.4854998294097578, 'tpr': 0.9174725983236621}, 4), (9.534734166208114, 9.174725983236621, 0.6399918170285073, 0.6702439024390244, {'recall': 0.6702439024390244, 'fpr': 0.40535031847133757, 'f1score': 0.21187355435620664, 'precision': 0.12582417582417582, 'tpr': 0.6702439024390244}, 5), (9.534734166208114, 9.174725983236621, 0.6399918170285073, 0.8218780251694094, {'recall': 0.8218780251694094, 'fpr': 0.0758902014107249, 'f1score': 0.6118918918918919, 'precision': 0.4873708381171068, 'tpr': 0.8218780251694094}, 5)]
#     gen = 5
#     numgens = 20
#     numalphas = 100
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 9.534734166208114
 
#     rls = [(1, 0, 1, 0.5896272285251215, {'recall': 0.5896272285251215, 'fpr': 0.17756047349459597, 'f1score': 0.5488007240911148, 'precision': 0.5132618510158014, 'tpr': 0.5896272285251215}, 0), (0, 0, 1, 0.8338164251207729, {'recall': 0.8338164251207729, 'fpr': 0.12571185720356992, 'f1score': 0.5111045306485046, 'precision': 0.36848847139197266, 'tpr': 0.8338164251207729}, 0), (0.832466068465521, 0.05302931596091205, 0.22056324749539113, 0.5302931596091205, {'recall': 0.5302931596091205, 'fpr': 0.17183967112024667, 'f1score': 0.5111459968602826, 'precision': 0.49333333333333335, 'tpr': 0.5302931596091205}, 0), (0.8123201244040121, 0.054739566483338734, 0.24241944207932664, 0.5473956648333873, {'recall': 0.5473956648333873, 'fpr': 0.1706663920074158, 'f1score': 0.5254658385093167, 'precision': 0.5052254404299791, 'tpr': 0.5473956648333873}, 1), (0.7922422182428226, 0.055030934549006844, 0.26278871630618417, 0.5503093454900684, {'recall': 0.5503093454900684, 'fpr': 0.17401582896495016, 'f1score': 0.5237062286953827, 'precision': 0.4995566065622229, 'tpr': 0.5503093454900684}, 2), (0.7879342938856537, 0.05298869143780291, 0.2650543975521491, 0.529886914378029, {'recall': 0.529886914378029, 'fpr': 0.16682122617207626, 'f1score': 0.5162102612527542, 'precision': 0.5032218471923903, 'tpr': 0.529886914378029}, 3), (0.7308809800749607, 0.05471391417425228, 0.3238329340992916, 0.5471391417425228, {'recall': 0.5471391417425228, 'fpr': 0.1729740847387906, 'f1score': 0.5225896599906846, 'precision': 0.500148588410104, 'tpr': 0.5471391417425228}, 4), (0.7308809800749607, 0.05471391417425228, 0.3238329340992916, 0.5471391417425228, {'recall': 0.5471391417425228, 'fpr': 0.1729740847387906, 'f1score': 0.5225896599906846, 'precision': 0.500148588410104, 'tpr': 0.5471391417425228}, 5), (0.7308809800749607, 0.05471391417425228, 0.3238329340992916, 0.7253176930596286, {'recall': 0.7253176930596286, 'fpr': 0.28827375392714616, 'f1score': 0.2875968992248062, 'precision': 0.1793570219966159, 'tpr': 0.7253176930596286}, 6), (0.7308809800749607, 0.05471391417425228, 0.3238329340992916, 0.8431752178121975, {'recall': 0.8431752178121975, 'fpr': 0.0744454831307895, 'f1score': 0.6266187050359712, 'precision': 0.4985689753863766, 'tpr': 0.8431752178121975}, 6)]
#     gen = 6
#     numgens = 20
#     numalphas = 100
#     myepsilon = 0.0001
#     mylambda = 0.1
#     final_payoff = 0.7308809800749607
 
#     rls = [(1, 0, 1, 0.5717085919634106, {'recall': 0.5717085919634106, 'fpr': 0.16942191190060582, 'f1score': 0.5417118093174431, 'precision': 0.5147058823529411, 'tpr': 0.5717085919634106}, 0), (0, 0, 1, 0.8114511352418559, {'recall': 0.8114511352418559, 'fpr': 0.12216849071010435, 'f1score': 0.5019847328244275, 'precision': 0.363395225464191, 'tpr': 0.8114511352418559}, 0), (0.7669423522023653, 0.0051666666666666675, 0.23822431446430148, 0.5166666666666667, {'recall': 0.5166666666666667, 'fpr': 0.1688911704312115, 'f1score': 0.5030225898822781, 'precision': 0.49008059516429014, 'tpr': 0.5166666666666667}, 0), (0.7669423522023653, 0.0051666666666666675, 0.23822431446430148, 0.5166666666666667, {'recall': 0.5166666666666667, 'fpr': 0.1688911704312115, 'f1score': 0.5030225898822781, 'precision': 0.49008059516429014, 'tpr': 0.5166666666666667}, 1), (0.7669423522023653, 0.0051666666666666675, 0.23822431446430148, 0.7196896217264791, {'recall': 0.7196896217264791, 'fpr': 0.31430028039765484, 'f1score': 0.2711988304093567, 'precision': 0.16707948660211663, 'tpr': 0.7196896217264791}, 2), (0.7669423522023653, 0.0051666666666666675, 0.23822431446430148, 0.8352941176470589, {'recall': 0.8352941176470589, 'fpr': 0.07758913412563667, 'f1score': 0.6116295764536971, 'precision': 0.4824462061155153, 'tpr': 0.8352941176470589}, 2)]
#     gen = 2
#     numgens = 20
#     numalphas = 50
#     myepsilon = 0.0001
#     mylambda = 0.01
#     final_payoff = 0.7669423522023653

#     rls = [(1, 0, 1, 0.5887758450935346, {'recall': 0.5887758450935346, 'fpr': 0.17820157900133293, 'f1score': 0.5453716370269038, 'precision': 0.5079275198187996, 'tpr': 0.5887758450935346}, 0), (0, 0, 1, 0.8250244379276638, {'recall': 0.8250244379276638, 'fpr': 0.138320455124395, 'f1score': 0.482837528604119, 'precision': 0.34128588758592804, 'tpr': 0.8250244379276638}, 0), (3.4820668328792945, 2.7661999348746336, 0.28413310199533903, 0.5532399869749267, {'recall': 0.5532399869749267, 'fpr': 0.1752492548052215, 'f1score': 0.5247876447876448, 'precision': 0.4991186839012926, 'tpr': 0.5532399869749267}, 0), (3.4189565263794734, 2.6940639269406392, 0.2751074005611658, 0.5388127853881278, {'recall': 0.5388127853881278, 'fpr': 0.17279638380932813, 'f1score': 0.51625, 'precision': 0.495500899820036, 'tpr': 0.5388127853881278}, 1), (3.361784726560024, 2.6949317738791425, 0.3331470473191187, 0.5389863547758285, {'recall': 0.5389863547758285, 'fpr': 0.17280394980456695, 'f1score': 0.5170640486208509, 'precision': 0.4968553459119497, 'tpr': 0.5389863547758285}, 2), (4.641854103128575, 4.292437520285621, 0.6505834171570459, 0.8584875040571243, {'recall': 0.8584875040571243, 'fpr': 0.2957094351270707, 'f1score': 0.6151162790697674, 'precision': 0.4792534879507157, 'tpr': 0.8584875040571243}, 3), (4.641854103128575, 4.292437520285621, 0.6505834171570459, 0.8584875040571243, {'recall': 0.8584875040571243, 'fpr': 0.2957094351270707, 'f1score': 0.6151162790697674, 'precision': 0.4792534879507157, 'tpr': 0.8584875040571243}, 4), (4.641854103128575, 4.292437520285621, 0.6505834171570459, 0.7409579667644184, {'recall': 0.7409579667644184, 'fpr': 0.26611191305086185, 'f1score': 0.30844354018311293, 'precision': 0.1947584789311408, 'tpr': 0.7409579667644184}, 5), (4.641854103128575, 4.292437520285621, 0.6505834171570459, 0.8571428571428571, {'recall': 0.8571428571428571, 'fpr': 0.09184192672998644, 'f1score': 0.584771573604061, 'precision': 0.4437596302003082, 'tpr': 0.8571428571428571}, 5)]
#     gen = 5
#     numgens = 20
#     numalphas = 50
#     myepsilon = 0.0001
#     mylambda = 5
#     final_payoff = 4.641854103128575

#     rls = [(1, 0, 1, 0.592156862745098, {'recall': 0.592156862745098, 'fpr': 0.17874743326488707, 'f1score': 0.5480114925147437, 'precision': 0.5099915564311849, 'tpr': 0.592156862745098}, 0), (0, 0, 1, 0.810126582278481, {'recall': 0.810126582278481, 'fpr': 0.12910897817038988, 'f1score': 0.49245338857650195, 'precision': 0.35374149659863946, 'tpr': 0.810126582278481}, 0), (0.8664487232624751, 0.10628238341968912, 0.23983366015721397, 0.5314119170984456, {'recall': 0.5314119170984456, 'fpr': 0.17030477759472817, 'f1score': 0.5141782860723798, 'precision': 0.49802731411229134, 'tpr': 0.5314119170984456}, 0), (0.8664487232624751, 0.10628238341968912, 0.23983366015721397, 0.5314119170984456, {'recall': 0.5314119170984456, 'fpr': 0.17030477759472817, 'f1score': 0.5141782860723798, 'precision': 0.49802731411229134, 'tpr': 0.5314119170984456}, 1), (0.8664487232624751, 0.10628238341968912, 0.23983366015721397, 0.7771260997067448, {'recall': 0.7771260997067448, 'fpr': 0.2864057060371911, 'f1score': 0.3062993642843383, 'precision': 0.19073896353166986, 'tpr': 0.7771260997067448}, 2), (0.8664487232624751, 0.10628238341968912, 0.23983366015721397, 0.842, {'recall': 0.842, 'fpr': 0.08237288135593221, 'f1score': 0.5984363894811656, 'precision': 0.46416758544652703, 'tpr': 0.842}, 2)]
#     gen = 2
#     numgens = 20
#     numalphas = 100
#     myepsilon = 0.0001
#     mylambda = 0.2
#     final_payoff = 0.8664487232624751
 
#     rls = [(1, 0, 1, 0.590715920235371, {'recall': 0.590715920235371, 'fpr': 0.18150087260034903, 'f1score': 0.5447693699125716, 'precision': 0.5054545454545455, 'tpr': 0.590715920235371}, 0), (0, 0, 1, 0.8017664376840039, {'recall': 0.8017664376840039, 'fpr': 0.1325014854426619, 'f1score': 0.4810126582278481, 'precision': 0.3435660218671152, 'tpr': 0.8017664376840039}, 0), (11.776053594301853, 11.06562703053931, 0.28957343623745757, 0.5532813515269656, {'recall': 0.5532813515269656, 'fpr': 0.1734211067681547, 'f1score': 0.526673882789547, 'precision': 0.5025081144880496, 'tpr': 0.5532813515269656}, 0), (11.776053594301853, 11.06562703053931, 0.28957343623745757, 0.5532813515269656, {'recall': 0.5532813515269656, 'fpr': 0.1734211067681547, 'f1score': 0.526673882789547, 'precision': 0.5025081144880496, 'tpr': 0.5532813515269656}, 1), (11.776053594301853, 11.06562703053931, 0.28957343623745757, 0.8490749756572541, {'recall': 0.8490749756572541, 'fpr': 0.1945978085449758, 'f1score': 0.4162291169451074, 'precision': 0.2756876383180525, 'tpr': 0.8490749756572541}, 2), (11.776053594301853, 11.06562703053931, 0.28957343623745757, 0.8435972629521017, {'recall': 0.8435972629521017, 'fpr': 0.0816846395516685, 'f1score': 0.6060393258426966, 'precision': 0.4728767123287671, 'tpr': 0.8435972629521017}, 2)]
#     gen = 2
#     numgens = 20
#     numalphas = 100
#     myepsilon = 0.0001
#     mylambda = 20
#     final_payoff = 11.776053594301853

#     rls = 
#     gen = 
#     numgens = 
#     numalphas = 
#     myepsilon = 
#     mylambda = 
#     final_payoff = 

# Following are results for experiment when error is 1-recall

#     rls = [(1, 0, 1, 0.586105675146771, {'recall': 0.586105675146771, 'fpr': 0.1776248202177933, 'f1score': 0.5452063106796117, 'precision': 0.5096426545660806, 'tpr': 0.586105675146771}, 0), (0, 0, 1, 0.8166828322017459, {'recall': 0.8166828322017459, 'fpr': 0.1325516186591894, 'f1score': 0.4905330614622779, 'precision': 0.350541215653622, 'tpr': 0.8166828322017459}, 0), (1.1780682070157824, 0.47693307342430147, 0.29886486640851917, 0.5230669265756985, {'recall': 0.5230669265756985, 'fpr': 0.16467804978399506, 'f1score': 0.5120050882493242, 'precision': 0.5014014325755216, 'tpr': 0.5230669265756985}, 0), (1.2807443361825106, 0.632952691680261, 0.3522083554977504, 0.367047308319739, {'recall': 0.367047308319739, 'fpr': 0.4611196712891628, 'f1score': 0.25924645696508813, 'precision': 0.20039187744923406, 'tpr': 0.367047308319739}, 1), (1.2807443361825106, 0.632952691680261, 0.3522083554977504, 0.367047308319739, {'recall': 0.367047308319739, 'fpr': 0.4611196712891628, 'f1score': 0.25924645696508813, 'precision': 0.20039187744923406, 'tpr': 0.367047308319739}, 2), (1.2807443361825106, 0.632952691680261, 0.3522083554977504, 0.7064579256360078, {'recall': 0.7064579256360078, 'fpr': 0.25921209033791814, 'f1score': 0.30102147175317906, 'precision': 0.19125827814569538, 'tpr': 0.7064579256360078}, 3), (1.2807443361825106, 0.632952691680261, 0.3522083554977504, 0.8462291870714985, {'recall': 0.8462291870714985, 'fpr': 0.07861448340266576, 'f1score': 0.6147278548559232, 'precision': 0.48268156424581005, 'tpr': 0.8462291870714985}, 3)]
#     gen = 3
#     numgens = 20 
#     numalphas = 10
#     myepsilon = 0.0001
#     mylambda = 1
#     final_payoff = 1.2807443361825106

#     rls = [(1, 0, 1, 0.5706840390879478, {'recall': 0.5706840390879478, 'fpr': 0.17800616649537512, 'f1score': 0.5346353371986573, 'precision': 0.5028702640642939, 'tpr': 0.5706840390879478}, 0), (0, 0, 1, 0.8305905130687319, {'recall': 0.8305905130687319, 'fpr': 0.10835387099515595, 'f1score': 0.542008843967151, 'precision': 0.4022503516174402, 'tpr': 0.8305905130687319}, 0), (5.576203915910264, 4.915254237288136, 0.33905032137787217, 0.5084745762711864, {'recall': 0.5084745762711864, 'fpr': 0.16337854500616522, 'f1score': 0.5017690575747829, 'precision': 0.49523809523809526, 'tpr': 0.5084745762711864}, 0), (8.439891588190555, 8.121349772874757, 0.6814581846842014, 0.18786502271252434, {'recall': 0.18786502271252434, 'fpr': 0.46213212595184194, 'f1score': 0.14205103042198233, 'precision': 0.11420118343195267, 'tpr': 0.18786502271252434}, 1), (8.439891588190555, 8.121349772874757, 0.6814581846842014, 0.18786502271252434, {'recall': 0.18786502271252434, 'fpr': 0.46213212595184194, 'f1score': 0.14205103042198233, 'precision': 0.11420118343195267, 'tpr': 0.18786502271252434}, 2), (8.439891588190555, 8.121349772874757, 0.6814581846842014, 0.6804619826756496, {'recall': 0.6804619826756496, 'fpr': 0.37785902559306184, 'f1score': 0.2284329563812601, 'precision': 0.13725490196078433, 'tpr': 0.6804619826756496}, 3), (8.439891588190555, 8.121349772874757, 0.6814581846842014, 0.8493150684931506, {'recall': 0.8493150684931506, 'fpr': 0.0748853795211411, 'f1score': 0.6262626262626263, 'precision': 0.496, 'tpr': 0.8493150684931506}, 3)]
#     gen = 3
#     numgens = 20
#     numalphas = 50
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 8.439891588190555
 
#     rls = [(1, 0, 1, 0.6, {'recall': 0.6, 'fpr': 0.176464542651593, 'f1score': 0.5557399306079348, 'precision': 0.5175611126720989, 'tpr': 0.6}, 0), (0, 0, 1, 0.8299516908212561, {'recall': 0.8299516908212561, 'fpr': 0.1317467063323417, 'f1score': 0.4988385598141696, 'precision': 0.35657949356579494, 'tpr': 0.8299516908212561}, 0), (10.632242406180278, 9.993485342019543, 0.3612429358392646, 0.5003257328990228, {'recall': 0.5003257328990228, 'fpr': 0.16073997944501542, 'f1score': 0.4978930307941653, 'precision': 0.49548387096774194, 'tpr': 0.5003257328990228}, 0), (17.317661081614002, 16.975169300225733, 0.6575082186117314, 0.15124153498871332, {'recall': 0.15124153498871332, 'fpr': 0.5523249819569028, 'f1score': 0.1050744931107875, 'precision': 0.0805012015104703, 'tpr': 0.15124153498871332}, 1), (14.284966059257641, 13.680760406424124, 0.39579434716648265, 0.31596197967879386, {'recall': 0.31596197967879386, 'fpr': 0.3541901733511129, 'f1score': 0.258168184252812, 'precision': 0.2182476794204211, 'tpr': 0.31596197967879386}, 2), (15.261417308524516, 14.947780678851174, 0.6863633703266583, 0.25261096605744127, {'recall': 0.25261096605744127, 'fpr': 0.5028759244042728, 'f1score': 0.17723837874971377, 'precision': 0.1365079365079365, 'tpr': 0.25261096605744127}, 3), (19.931919382044768, 19.49119373776908, 0.5592743557243125, 0.025440313111545987, {'recall': 0.025440313111545987, 'fpr': 0.6677624820217793, 'f1score': 0.016175860638739114, 'precision': 0.011857707509881422, 'tpr': 0.025440313111545987}, 4), (19.931919382044768, 19.49119373776908, 0.5592743557243125, 0.025440313111545987, {'recall': 0.025440313111545987, 'fpr': 0.6677624820217793, 'f1score': 0.016175860638739114, 'precision': 0.011857707509881422, 'tpr': 0.025440313111545987}, 5), (19.931919382044768, 19.49119373776908, 0.5592743557243125, 0.8334956183057449, {'recall': 0.8334956183057449, 'fpr': 0.07534188397179988, 'f1score': 0.6180505415162455, 'precision': 0.4911072862880092, 'tpr': 0.8334956183057449}, 6), (19.931919382044768, 19.49119373776908, 0.5592743557243125, 0.8468292682926829, {'recall': 0.8468292682926829, 'fpr': 0.08602972399150743, 'f1score': 0.5973847212663455, 'precision': 0.4614566719829878, 'tpr': 0.8468292682926829}, 6)]
#     gen = 6
#     numgens = 20
#     numalphas = 100
#     myepsilon = 0.0001
#     mylambda = 20
#     final_payoff = 19.931919382044768

#     rls = [(1, 0, 1, 0.6009174311926605, {'recall': 0.6009174311926605, 'fpr': 0.18516618793598688, 'f1score': 0.5481990733821551, 'precision': 0.5039846111569113, 'tpr': 0.6009174311926605}, 0), (0, 0, 1, 0.8181818181818182, {'recall': 0.8181818181818182, 'fpr': 0.12587115417304096, 'f1score': 0.5034216007140732, 'precision': 0.3635582294800172, 'tpr': 0.8181818181818182}, 0), (0.9222687909075138, 0.23448163795905103, 0.3122128470515373, 0.531036724081898, {'recall': 0.531036724081898, 'fpr': 0.17000925640234496, 'f1score': 0.5135135135135135, 'precision': 0.49710982658959535, 'tpr': 0.531036724081898}, 0), (0.8541820534283024, 0.24081967213114752, 0.3866376187028451, 0.518360655737705, {'recall': 0.518360655737705, 'fpr': 0.1722051282051282, 'f1score': 0.5011093502377179, 'precision': 0.4849693251533742, 'tpr': 0.518360655737705}, 1), (0.8320489630237852, 0.24812275546849494, 0.41607379244470966, 0.5037544890630101, {'recall': 0.5037544890630101, 'fpr': 0.19965081647324637, 'f1score': 0.47114503816793896, 'precision': 0.4425007169486665, 'tpr': 0.5037544890630101}, 2), (0.8320489630237852, 0.24812275546849494, 0.41607379244470966, 0.5037544890630101, {'recall': 0.5037544890630101, 'fpr': 0.19965081647324637, 'f1score': 0.47114503816793896, 'precision': 0.4425007169486665, 'tpr': 0.5037544890630101}, 3), (0.8320489630237852, 0.24812275546849494, 0.41607379244470966, 0.72265625, {'recall': 0.72265625, 'fpr': 0.2868546195652174, 'f1score': 0.28782574873590044, 'precision': 0.17969888295288974, 'tpr': 0.72265625}, 4), (0.8320489630237852, 0.24812275546849494, 0.41607379244470966, 0.8245264207377866, {'recall': 0.8245264207377866, 'fpr': 0.08307196744935152, 'f1score': 0.5886120996441281, 'precision': 0.45766463752075265, 'tpr': 0.8245264207377866}, 4)]
#     gen = 4
#     numgens = 20
#     numalphas = 20
#     myepsilon = 0.0001
#     mylambda = 0.5
#     final_payoff = 0.8320489630237852

#     rls = [(1, 0, 1, 0.6053577262332571, {'recall': 0.6053577262332571, 'fpr': 0.17999794640106787, 'f1score': 0.5558722063896805, 'precision': 0.5138657792567942, 'tpr': 0.6053577262332571}, 0), (0, 0, 1, 0.8316929133858267, {'recall': 0.8316929133858267, 'fpr': 0.1379837067209776, 'f1score': 0.48465729853742473, 'precision': 0.3419668150546338, 'tpr': 0.8316929133858267}, 0), (0.8284613089456938, 0.09125326370757181, 0.262791954761878, 0.543733681462141, {'recall': 0.543733681462141, 'fpr': 0.17142563681183237, 'f1score': 0.5207063603688076, 'precision': 0.49955022488755624, 'tpr': 0.543733681462141}, 0), (0.8284613089456938, 0.09125326370757181, 0.262791954761878, 0.543733681462141, {'recall': 0.543733681462141, 'fpr': 0.17142563681183237, 'f1score': 0.5207063603688076, 'precision': 0.49955022488755624, 'tpr': 0.543733681462141}, 1), (0.8284613089456938, 0.09125326370757181, 0.262791954761878, 0.7704280155642024, {'recall': 0.7704280155642024, 'fpr': 0.2610431532449881, 'f1score': 0.3237277743715512, 'precision': 0.20491591203104786, 'tpr': 0.7704280155642024}, 2), (0.8284613089456938, 0.09125326370757181, 0.262791954761878, 0.8446411012782694, {'recall': 0.8446411012782694, 'fpr': 0.09657981838241535, 'f1score': 0.5700066357000664, 'precision': 0.4301452178267401, 'tpr': 0.8446411012782694}, 2)]
#     gen = 2
#     numgens = 20
#     numalphas = 50
#     myepsilon = 0.0001
#     mylambda = 0.2
#     final_payoff = 0.8284613089456938 

#     rls = [(1, 0, 1, 0.6018246985988921, {'recall': 0.6018246985988921, 'fpr': 0.18518137909772892, 'f1score': 0.549866031557011, 'precision': 0.506166072896684, 'tpr': 0.6018246985988921}, 0), (0, 0, 1, 0.8091528724440117, {'recall': 0.8091528724440117, 'fpr': 0.1299583793425635, 'f1score': 0.49055489964580873, 'precision': 0.3519695044472681, 'tpr': 0.8091528724440117}, 0), (0.7672730381542716, 0.004607684856312561, 0.23733464670204096, 0.539231514368744, {'recall': 0.539231514368744, 'fpr': 0.17066886529939193, 'f1score': 0.5200062276194924, 'precision': 0.50210463018641, 'tpr': 0.539231514368744}, 0), (0.7543424797643027, 0.004323616115296429, 0.24998113635099373, 0.5676383884703571, {'recall': 0.5676383884703571, 'fpr': 0.2774186929311583, 'f1score': 0.46275033377837116, 'precision': 0.3905792201938247, 'tpr': 0.5676383884703571}, 1), (0.731421660653315, 0.004809791597750579, 0.2733881309444355, 0.5190208402249421, {'recall': 0.5190208402249421, 'fpr': 0.17070676076506086, 'f1score': 0.5011978917105894, 'precision': 0.4845583693638048, 'tpr': 0.5190208402249421}, 2), (0.744277083189356, 0.005, 0.26072291681064386, 0.5, {'recall': 0.5, 'fpr': 0.19691358024691358, 'f1score': 0.4713804713804714, 'precision': 0.445859872611465, 'tpr': 0.5}, 3), (0.731421660653315, 0.004809791597750579, 0.2733881309444355, 0.5190208402249421, {'recall': 0.5190208402249421, 'fpr': 0.17070676076506086, 'f1score': 0.5011978917105894, 'precision': 0.4845583693638048, 'tpr': 0.5190208402249421}, 4), (0.731421660653315, 0.004809791597750579, 0.2733881309444355, 0.5190208402249421, {'recall': 0.5190208402249421, 'fpr': 0.17070676076506086, 'f1score': 0.5011978917105894, 'precision': 0.4845583693638048, 'tpr': 0.5190208402249421}, 5), (0.731421660653315, 0.004809791597750579, 0.2733881309444355, 0.8226120857699805, {'recall': 0.8226120857699805, 'fpr': 0.2221844742653304, 'f1score': 0.3762817654926438, 'precision': 0.24393063583815028, 'tpr': 0.8226120857699805}, 6), (0.731421660653315, 0.004809791597750579, 0.2733881309444355, 0.8620019436345967, {'recall': 0.8620019436345967, 'fpr': 0.07569450344065924, 'f1score': 0.6319914499465622, 'precision': 0.49887514060742405, 'tpr': 0.8620019436345967}, 6)]
#     gen = 6
#     numgens = 20
#     numalphas = 50
#     myepsilon = 0.0001
#     mylambda = 0.01
#     final_payoff = 0.731421660653315

#     rls = [(1, 0, 1, 0.5846153846153846, {'recall': 0.5846153846153846, 'fpr': 0.1762955361723961, 'f1score': 0.5445952126848606, 'precision': 0.509703196347032, 'tpr': 0.5846153846153846}, 0), (0, 0, 1, 0.8163064833005894, {'recall': 0.8163064833005894, 'fpr': 0.12374809030724834, 'f1score': 0.5025703054127608, 'precision': 0.36304062909567497, 'tpr': 0.8163064833005894}, 0), (5.530996766216198, 4.839973873285435, 0.30897710706923665, 0.5160026126714565, {'recall': 0.5160026126714565, 'fpr': 0.1671801191209694, 'f1score': 0.5039872408293461, 'precision': 0.4925187032418953, 'tpr': 0.5160026126714565}, 0), (8.301517026209632, 7.812704649639817, 0.5111876234301835, 0.21872953503601833, {'recall': 0.21872953503601833, 'fpr': 0.46306176893084344, 'f1score': 0.16223436551305404, 'precision': 0.1289326384867786, 'tpr': 0.21872953503601833}, 1), (7.4670826745024055, 6.983349657198826, 0.5162669826964201, 0.30166503428011754, {'recall': 0.30166503428011754, 'fpr': 0.3636643730101674, 'f1score': 0.2454835281615303, 'precision': 0.20694288913773795, 'tpr': 0.30166503428011754}, 2), (7.898058462965916, 7.397975840679073, 0.4999173777131576, 0.2602024159320927, {'recall': 0.2602024159320927, 'fpr': 0.48166786484543495, 'f1score': 0.1864327485380117, 'precision': 0.14525241479861492, 'tpr': 0.2602024159320927}, 3), (7.898058462965916, 7.397975840679073, 0.4999173777131576, 0.2602024159320927, {'recall': 0.2602024159320927, 'fpr': 0.48166786484543495, 'f1score': 0.1864327485380117, 'precision': 0.14525241479861492, 'tpr': 0.2602024159320927}, 4), (7.898058462965916, 7.397975840679073, 0.4999173777131576, 0.733847637415622, {'recall': 0.733847637415622, 'fpr': 0.3433647878942447, 'f1score': 0.26075038547198903, 'precision': 0.15854166666666666, 'tpr': 0.733847637415622}, 5), (7.898058462965916, 7.397975840679073, 0.4999173777131576, 0.84106614017769, {'recall': 0.84106614017769, 'fpr': 0.07627046746415543, 'f1score': 0.6164978292329957, 'precision': 0.48657909765848084, 'tpr': 0.84106614017769}, 5)]
#     gen = 5
#     numgens = 20
#     numalphas = 100
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 7.898058462965916

#     rls = [(1, 0, 1, 0.5864217776320105, {'recall': 0.5864217776320105, 'fpr': 0.1755717362321813, 'f1score': 0.5460375629867156, 'precision': 0.5108571428571429, 'tpr': 0.5864217776320105}, 0), (0, 0, 1, 0.8212180746561886, {'recall': 0.8212180746561886, 'fpr': 0.13664912578509592, 'f1score': 0.48267898383371827, 'precision': 0.3417825020441537, 'tpr': 0.8212180746561886}, 0), (5.4084124530589985, 4.728808054563169, 0.32039560150417046, 0.5271191945436831, {'recall': 0.5271191945436831, 'fpr': 0.16623804135377018, 'f1score': 0.5137701804368471, 'precision': 0.5010805804260574, 'tpr': 0.5271191945436831}, 0), (7.056313129027419, 6.615434924787442, 0.5591217957600225, 0.3384565075212557, {'recall': 0.3384565075212557, 'fpr': 0.33781564360500926, 'f1score': 0.2803358613217768, 'precision': 0.239251040221914, 'tpr': 0.3384565075212557}, 1), (6.66867472800063, 6.280209013716524, 0.6115342857158943, 0.3719790986283475, {'recall': 0.3719790986283475, 'fpr': 0.2929759704251386, 'f1score': 0.3229373405160193, 'precision': 0.2853206412825651, 'tpr': 0.3719790986283475}, 2), (7.622312829417546, 7.157310704960835, 0.5349978755432891, 0.28426892950391647, {'recall': 0.28426892950391647, 'fpr': 0.39800739523418244, 'f1score': 0.22304737516005121, 'precision': 0.1835229667088074, 'tpr': 0.28426892950391647}, 3), (6.66867472800063, 6.280209013716524, 0.6115342857158943, 0.3719790986283475, {'recall': 0.3719790986283475, 'fpr': 0.2929759704251386, 'f1score': 0.3229373405160193, 'precision': 0.2853206412825651, 'tpr': 0.3719790986283475}, 4), (6.66867472800063, 6.280209013716524, 0.6115342857158943, 0.3719790986283475, {'recall': 0.3719790986283475, 'fpr': 0.2929759704251386, 'f1score': 0.3229373405160193, 'precision': 0.2853206412825651, 'tpr': 0.3719790986283475}, 5), (6.66867472800063, 6.280209013716524, 0.6115342857158943, 0.8382352941176471, {'recall': 0.8382352941176471, 'fpr': 0.21103565365025467, 'f1score': 0.39211190094015136, 'precision': 0.25591140377132593, 'tpr': 0.8382352941176471}, 6), (6.66867472800063, 6.280209013716524, 0.6115342857158943, 0.8458536585365853, {'recall': 0.8458536585365853, 'fpr': 0.07940552016985138, 'f1score': 0.6133710647329325, 'precision': 0.4811320754716981, 'tpr': 0.8458536585365853}, 6)]
#     gen = 6
#     numgens = 20
#     numalphas = 20
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 6.66867472800063

#     rls = [(1, 0, 1, 0.5872656755009696, {'recall': 0.5872656755009696, 'fpr': 0.17494333402019369, 'f1score': 0.5498562566197609, 'precision': 0.5169274537695591, 'tpr': 0.5872656755009696}, 0), (0, 0, 1, 0.841948310139165, {'recall': 0.841948310139165, 'fpr': 0.11446498219433611, 'f1score': 0.528879175772713, 'precision': 0.38552571688666365, 'tpr': 0.841948310139165}, 0), (5.613622059272161, 4.936211972522081, 0.3225899132499199, 0.5063788027477919, {'recall': 0.5063788027477919, 'fpr': 0.16463101714051115, 'f1score': 0.4986310194878402, 'precision': 0.49111675126903553, 'tpr': 0.5063788027477919}, 0), (5.41478418963845, 4.8249918220477594, 0.4102076324093096, 0.517500817795224, {'recall': 0.517500817795224, 'fpr': 0.16832597762496151, 'f1score': 0.5039018952062431, 'precision': 0.4909993792675357, 'tpr': 0.517500817795224}, 1), (6.391601202706889, 5.976408912188729, 0.58480770948184, 0.40235910878112713, {'recall': 0.40235910878112713, 'fpr': 0.3090890439064424, 'f1score': 0.3367612779377485, 'precision': 0.2895543503890592, 'tpr': 0.40235910878112713}, 2), (5.210716244515645, 4.779627815866797, 0.5689115713511521, 0.5220372184133203, {'recall': 0.5220372184133203, 'fpr': 0.16853240217726198, 'f1score': 0.5073774393146121, 'precision': 0.4935185185185185, 'tpr': 0.5220372184133203}, 3), (6.057424570435412, 5.702614379084967, 0.6451898086495547, 0.4297385620915033, {'recall': 0.4297385620915033, 'fpr': 0.2557494866529774, 'f1score': 0.3830468977570638, 'precision': 0.34550709406200736, 'tpr': 0.4297385620915033}, 4), (6.057424570435412, 5.702614379084967, 0.6451898086495547, 0.4297385620915033, {'recall': 0.4297385620915033, 'fpr': 0.2557494866529774, 'f1score': 0.3830468977570638, 'precision': 0.34550709406200736, 'tpr': 0.4297385620915033}, 5), (6.057424570435412, 5.702614379084967, 0.6451898086495547, 0.8442703232125367, {'recall': 0.8442703232125367, 'fpr': 0.09848034637914933, 'f1score': 0.5665461715412422, 'precision': 0.42631058358061324, 'tpr': 0.8442703232125367}, 6), (6.057424570435412, 5.702614379084967, 0.6451898086495547, 0.8381046396841066, {'recall': 0.8381046396841066, 'fpr': 0.0749130397895987, 'f1score': 0.6185792349726776, 'precision': 0.49018475750577367, 'tpr': 0.8381046396841066}, 6)]
#     gen = 6
#     numgens = 20
#     numalphas = 10
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 6.057424570435412

#     rls = [(1, 0, 1, 0.6139717940308298, {'recall': 0.6139717940308298, 'fpr': 0.18264793354527742, 'f1score': 0.55863921217547, 'precision': 0.5124555160142349, 'tpr': 0.6139717940308298}, 0), (0, 0, 1, 0.8214285714285714, {'recall': 0.8214285714285714, 'fpr': 0.14187351241074464, 'f1score': 0.47862767154105734, 'precision': 0.3376984126984127, 'tpr': 0.8214285714285714}, 0), (1.004525986978824, 0.23230668414154654, 0.22778069716272253, 0.5353866317169069, {'recall': 0.5353866317169069, 'fpr': 0.17336889618383258, 'f1score': 0.5125470514429109, 'precision': 0.4915764139590854, 'tpr': 0.5353866317169069}, 0), (0.9979098447629909, 0.22866839043309634, 0.23075854567010545, 0.5426632191338073, {'recall': 0.5426632191338073, 'fpr': 0.17113125901504225, 'f1score': 0.5219148274790177, 'precision': 0.5026946107784431, 'tpr': 0.5426632191338073}, 1), (0.9976697759933637, 0.30346631785480704, 0.30579654186144345, 0.39306736429038586, {'recall': 0.39306736429038586, 'fpr': 0.2762266475056457, 'f1score': 0.3458495180549561, 'precision': 0.30875931158489595, 'tpr': 0.39306736429038586}, 2), (0.9982853407607597, 0.24886141834743009, 0.25057607758667033, 0.5022771633051398, {'recall': 0.5022771633051398, 'fpr': 0.18846391116594693, 'f1score': 0.4786854751201364, 'precision': 0.45721054190109567, 'tpr': 0.5022771633051398}, 3), (1.053429735573995, 0.4550653594771242, 0.4016356239031291, 0.08986928104575163, {'recall': 0.08986928104575163, 'fpr': 0.6237166324435318, 'f1score': 0.05844845908607864, 'precision': 0.04330708661417323, 'tpr': 0.08986928104575163}, 4), (1.053429735573995, 0.4550653594771242, 0.4016356239031291, 0.08986928104575163, {'recall': 0.08986928104575163, 'fpr': 0.6237166324435318, 'f1score': 0.05844845908607864, 'precision': 0.04330708661417323, 'tpr': 0.08986928104575163}, 5), (1.053429735573995, 0.4550653594771242, 0.4016356239031291, 0.7573385518590998, {'recall': 0.7573385518590998, 'fpr': 0.31796569876040076, 'f1score': 0.2793719545208446, 'precision': 0.1712768311573357, 'tpr': 0.7573385518590998}, 6), (1.053429735573995, 0.4550653594771242, 0.4016356239031291, 0.8501945525291829, {'recall': 0.8501945525291829, 'fpr': 0.07628270472307169, 'f1score': 0.6242857142857143, 'precision': 0.4932279909706546, 'tpr': 0.8501945525291829}, 6)]
#     gen = 6
#     numgens = 20
#     numalphas = 100
#     myepsilon = 0.0001
#     mylambda = 0.5
#     final_payoff = 1.053429735573995

#     rls = [(1, 0, 1, 0.6066536203522505, {'recall': 0.6066536203522505, 'fpr': 0.181631395109924, 'f1score': 0.5557215416791156, 'precision': 0.5126791620727673, 'tpr': 0.6066536203522505}, 0), (0, 0, 1, 0.8287937743190662, {'recall': 0.8287937743190662, 'fpr': 0.13685015290519878, 'f1score': 0.48811228874248064, 'precision': 0.3459196102314251, 'tpr': 0.8287937743190662}, 0), (1.179715160662358, 0.43461160275319566, 0.2548964420908377, 0.5653883972468043, {'recall': 0.5653883972468043, 'fpr': 0.17488973228023388, 'f1score': 0.5323252584477705, 'precision': 0.5029154518950437, 'tpr': 0.5653883972468043}, 0), (1.1363456471017066, 0.46028645833333337, 0.3239408112316269, 0.5397135416666666, {'recall': 0.5397135416666666, 'fpr': 0.17321134868421054, 'f1score': 0.5169134840218238, 'precision': 0.4959617110379898, 'tpr': 0.5397135416666666}, 1), (1.1363456471017066, 0.46028645833333337, 0.3239408112316269, 0.5397135416666666, {'recall': 0.5397135416666666, 'fpr': 0.17321134868421054, 'f1score': 0.5169134840218238, 'precision': 0.4959617110379898, 'tpr': 0.5397135416666666}, 2), (1.1363456471017066, 0.46028645833333337, 0.3239408112316269, 0.81648675171737, {'recall': 0.81648675171737, 'fpr': 0.1817332993803582, 'f1score': 0.4168336673346693, 'precision': 0.2798520013454423, 'tpr': 0.81648675171737}, 3), (1.1363456471017066, 0.46028645833333337, 0.3239408112316269, 0.8526829268292683, {'recall': 0.8526829268292683, 'fpr': 0.08008492569002124, 'f1score': 0.6150598170302604, 'precision': 0.4810126582278481, 'tpr': 0.8526829268292683}, 3)]
#     gen = 3
#     numgens = 20
#     numalphas = 10
#     myepsilon = 0.0001
#     mylambda = 1
#     final_payoff = 1.1363456471017066
    

# Following are results for experiment with handwritten digits data
    
    # 7 and 9
#     rls = [(1, 0, 1, 0.86, {'recall': 0.86, 'fpr': 0.0942, 'f1score': 0.7787, 'precision': 0.7115, 'tpr': 0.86}, 0), (0, 0, 1, 0.8754, {'recall': 0.8754, 'fpr': 0.1005, 'f1score': 0.7794, 'precision': 0.7024, 'tpr': 0.8754}, 0), (2.2693, 1.5713, 0.302, 0.8429, {'recall': 0.8429, 'fpr': 0.3107, 'f1score': 0.5653, 'precision': 0.4252, 'tpr': 0.8429}, 0), (2.2693, 1.5713, 0.302, 0.8429, {'recall': 0.8429, 'fpr': 0.3107, 'f1score': 0.5653, 'precision': 0.4252, 'tpr': 0.8429}, 1), (2.2693, 1.5713, 0.302, 0.9956, {'recall': 0.9956, 'fpr': 0.0018, 'f1score': 0.9945, 'precision': 0.9934, 'tpr': 0.9956}, 2), (2.2693, 1.5713, 0.302, 0.8494, {'recall': 0.8494, 'fpr': 0.3123, 'f1score': 0.5673, 'precision': 0.4259, 'tpr': 0.8494}, 2)]
#     gen = 13
#     numgens = 20
#     numalphas = 1000
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 1.1426

#     # 1 and 4
#     rls = [(1, 0, 1, 0.9845, {'recall': 0.9845, 'fpr': 0.0091, 'f1score': 0.9734, 'precision': 0.9626, 'tpr': 0.9845}, 0), (0, 0, 1, 0.9854, {'recall': 0.9854, 'fpr': 0.0081, 'f1score': 0.9758, 'precision': 0.9665, 'tpr': 0.9854}, 0), (1.0797, 0.2803, 0.2006, 0.972, {'recall': 0.972, 'fpr': 0.3742, 'f1score': 0.5487, 'precision': 0.3822, 'tpr': 0.972}, 0), (4.3055, 3.5586, 0.2531, 0.6441, {'recall': 0.6441, 'fpr': 0.0824, 'f1score': 0.647, 'precision': 0.65, 'tpr': 0.6441}, 1), (4.2859, 3.5222, 0.2363, 0.6478, {'recall': 0.6478, 'fpr': 0.0845, 'f1score': 0.6465, 'precision': 0.6451, 'tpr': 0.6478}, 2), (4.0694, 3.3617, 0.2923, 0.6638, {'recall': 0.6638, 'fpr': 0.0851, 'f1score': 0.6572, 'precision': 0.6506, 'tpr': 0.6638}, 3), (1.056, 0.2693, 0.2133, 0.9731, {'recall': 0.9731, 'fpr': 0.3799, 'f1score': 0.544, 'precision': 0.3776, 'tpr': 0.9731}, 4), (4.2485, 3.4961, 0.2476, 0.6504, {'recall': 0.6504, 'fpr': 0.0798, 'f1score': 0.6549, 'precision': 0.6595, 'tpr': 0.6504}, 5), (4.1554, 3.5356, 0.3802, 0.6464, {'recall': 0.6464, 'fpr': 0.0798, 'f1score': 0.652, 'precision': 0.6577, 'tpr': 0.6464}, 6), (3.7917, 3.257, 0.4653, 0.6743, {'recall': 0.6743, 'fpr': 0.086, 'f1score': 0.6617, 'precision': 0.6496, 'tpr': 0.6743}, 7), (0.8328, 0.2638, 0.431, 0.9736, {'recall': 0.9736, 'fpr': 0.3804, 'f1score': 0.5455, 'precision': 0.3789, 'tpr': 0.9736}, 8), (0.8328, 0.2638, 0.431, 0.9736, {'recall': 0.9736, 'fpr': 0.3804, 'f1score': 0.5455, 'precision': 0.3789, 'tpr': 0.9736}, 9), (0.8328, 0.2638, 0.431, 0.9976, {'recall': 0.9976, 'fpr': 0.0004, 'f1score': 0.998, 'precision': 0.9984, 'tpr': 0.9976}, 10), (0.8328, 0.2638, 0.431, 0.974, {'recall': 0.974, 'fpr': 0.3806, 'f1score': 0.5458, 'precision': 0.3792, 'tpr': 0.974}, 10)]
#     gen = 10
#     numgens = 20
#     numalphas = 1000
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 0.8328
 
#     # 4 and 9
#     rls = [(1, 0, 1, 0.9738, {'recall': 0.9738, 'fpr': 0.2073, 'f1score': 0.7301, 'precision': 0.5839, 'tpr': 0.9738}, 0), (0, 0, 1, 0.9773, {'recall': 0.9773, 'fpr': 0.2111, 'f1score': 0.7293, 'precision': 0.5817, 'tpr': 0.9773}, 0), (1.123, 0.3449, 0.2219, 0.9655, {'recall': 0.9655, 'fpr': 0.3193, 'f1score': 0.6376, 'precision': 0.476, 'tpr': 0.9655}, 0), (1.9423, 1.1765, 0.2342, 0.8824, {'recall': 0.8824, 'fpr': 0.0438, 'f1score': 0.8696, 'precision': 0.8573, 'tpr': 0.8824}, 1), (1.8907, 1.1636, 0.2729, 0.8836, {'recall': 0.8836, 'fpr': 0.0363, 'f1score': 0.8819, 'precision': 0.8801, 'tpr': 0.8836}, 2), (1.8722, 1.1377, 0.2655, 0.8862, {'recall': 0.8862, 'fpr': 0.0374, 'f1score': 0.8818, 'precision': 0.8774, 'tpr': 0.8862}, 3), (1.833, 1.1258, 0.2928, 0.8874, {'recall': 0.8874, 'fpr': 0.0405, 'f1score': 0.8775, 'precision': 0.8677, 'tpr': 0.8874}, 4), (1.7894, 1.1922, 0.4028, 0.8808, {'recall': 0.8808, 'fpr': 0.1111, 'f1score': 0.7829, 'precision': 0.7047, 'tpr': 0.8808}, 5), (1.7894, 1.1922, 0.4028, 0.8808, {'recall': 0.8808, 'fpr': 0.1111, 'f1score': 0.7829, 'precision': 0.7047, 'tpr': 0.8808}, 6), (1.7894, 1.1922, 0.4028, 0.9912, {'recall': 0.9912, 'fpr': 0.0021, 'f1score': 0.992, 'precision': 0.9929, 'tpr': 0.9912}, 7), (1.7894, 1.1922, 0.4028, 0.9754, {'recall': 0.9754, 'fpr': 0.3109, 'f1score': 0.6489, 'precision': 0.4862, 'tpr': 0.9754}, 7)]
#     gen = 7
#     numgens = 20
#     numalphas = 1000
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 1.7894
#  
#     # 2 and 6
#     rls = [(1, 0, 1, 0.9123, {'recall': 0.9123, 'fpr': 0.0514, 'f1score': 0.8731, 'precision': 0.8371, 'tpr': 0.9123}, 0), (0, 0, 1, 0.9177, {'recall': 0.9177, 'fpr': 0.0548, 'f1score': 0.8709, 'precision': 0.8286, 'tpr': 0.9177}, 0), (1.744, 0.9718, 0.2278, 0.9028, {'recall': 0.9028, 'fpr': 0.0879, 'f1score': 0.8182, 'precision': 0.7481, 'tpr': 0.9028}, 0), (1.744, 0.9718, 0.2278, 0.9028, {'recall': 0.9028, 'fpr': 0.0879, 'f1score': 0.8182, 'precision': 0.7481, 'tpr': 0.9028}, 1), (1.744, 0.9718, 0.2278, 0.9311, {'recall': 0.9311, 'fpr': 0.0499, 'f1score': 0.8849, 'precision': 0.843, 'tpr': 0.9311}, 2), (1.744, 0.9718, 0.2278, 0.9213, {'recall': 0.9213, 'fpr': 0.1022, 'f1score': 0.8106, 'precision': 0.7237, 'tpr': 0.9213}, 2)]
#     gen = 2
#     numgens = 20
#     numalphas = 1000
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 1.744
#      
#     # 5 and 8
#     rls = [(1, 0, 1, 0.9388, {'recall': 0.9388, 'fpr': 0.0916, 'f1score': 0.8504, 'precision': 0.7772, 'tpr': 0.9388}, 0), (0, 0, 1, 0.9406, {'recall': 0.9406, 'fpr': 0.0929, 'f1score': 0.8491, 'precision': 0.7738, 'tpr': 0.9406}, 0), (1.4509, 0.692, 0.2411, 0.9308, {'recall': 0.9308, 'fpr': 0.325, 'f1score': 0.6439, 'precision': 0.4922, 'tpr': 0.9308}, 0), (1.895, 1.1732, 0.2782, 0.8827, {'recall': 0.8827, 'fpr': 0.0427, 'f1score': 0.8789, 'precision': 0.8751, 'tpr': 0.8827}, 1), (1.8428, 1.1783, 0.3355, 0.8822, {'recall': 0.8822, 'fpr': 0.0354, 'f1score': 0.8882, 'precision': 0.8943, 'tpr': 0.8822}, 2), (1.8428, 1.1783, 0.3355, 0.8822, {'recall': 0.8822, 'fpr': 0.0354, 'f1score': 0.8882, 'precision': 0.8943, 'tpr': 0.8822}, 3), (1.8428, 1.1783, 0.3355, 0.9932, {'recall': 0.9932, 'fpr': 0.0076, 'f1score': 0.9855, 'precision': 0.9778, 'tpr': 0.9932}, 4), (1.8428, 1.1783, 0.3355, 0.9408, {'recall': 0.9408, 'fpr': 0.3471, 'f1score': 0.6347, 'precision': 0.4789, 'tpr': 0.9408}, 4)]
#     gen = 4
#     numgens = 20
#     numalphas = 1000
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 1.8428
#       
#     # 2 and 8
#     rls = [(1, 0, 1, 0.9142, {'recall': 0.9142, 'fpr': 0.0657, 'f1score': 0.8542, 'precision': 0.8015, 'tpr': 0.9142}, 0), (0, 0, 1, 0.912, {'recall': 0.912, 'fpr': 0.0701, 'f1score': 0.8467, 'precision': 0.7902, 'tpr': 0.912}, 0), (1.7607, 1.0708, 0.3101, 0.8929, {'recall': 0.8929, 'fpr': 0.1417, 'f1score': 0.7491, 'precision': 0.6452, 'tpr': 0.8929}, 0), (1.9057, 1.2001, 0.2944, 0.88, {'recall': 0.88, 'fpr': 0.1176, 'f1score': 0.7704, 'precision': 0.6851, 'tpr': 0.88}, 1), (1.9057, 1.2001, 0.2944, 0.88, {'recall': 0.88, 'fpr': 0.1176, 'f1score': 0.7704, 'precision': 0.6851, 'tpr': 0.88}, 2), (1.9057, 1.2001, 0.2944, 0.9958, {'recall': 0.9958, 'fpr': 0.0174, 'f1score': 0.9688, 'precision': 0.9432, 'tpr': 0.9958}, 3), (1.9057, 1.2001, 0.2944, 0.9157, {'recall': 0.9157, 'fpr': 0.26, 'f1score': 0.6504, 'precision': 0.5043, 'tpr': 0.9157}, 3)]
#     gen = 3
#     numgens = 20
#     numalphas = 1000
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 1.9057
      
    # 3 and 8
#     rls = [(1, 0, 1, 0.9431, {'recall': 0.9431, 'fpr': 0.074, 'f1score': 0.8551, 'precision': 0.7821, 'tpr': 0.9431}, 0), (0, 0, 1, 0.9443, {'recall': 0.9443, 'fpr': 0.0699, 'f1score': 0.8617, 'precision': 0.7923, 'tpr': 0.9443}, 0), (1.4512, 0.6806, 0.2294, 0.9319, {'recall': 0.9319, 'fpr': 0.2977, 'f1score': 0.6244, 'precision': 0.4695, 'tpr': 0.9319}, 0), (3.3545, 2.5946, 0.2401, 0.7405, {'recall': 0.7405, 'fpr': 0.0728, 'f1score': 0.7416, 'precision': 0.7426, 'tpr': 0.7405}, 1), (3.3068, 2.5689, 0.2621, 0.7431, {'recall': 0.7431, 'fpr': 0.0727, 'f1score': 0.7434, 'precision': 0.7436, 'tpr': 0.7431}, 2), (3.2518, 2.7112, 0.4594, 0.7289, {'recall': 0.7289, 'fpr': 0.0671, 'f1score': 0.7417, 'precision': 0.755, 'tpr': 0.7289}, 3), (3.1813, 2.5354, 0.3541, 0.7465, {'recall': 0.7465, 'fpr': 0.0738, 'f1score': 0.7438, 'precision': 0.7412, 'tpr': 0.7465}, 4), (2.8082, 2.4389, 0.6307, 0.7561, {'recall': 0.7561, 'fpr': 0.0761, 'f1score': 0.7467, 'precision': 0.7376, 'tpr': 0.7561}, 5), (2.8082, 2.4389, 0.6307, 0.7561, {'recall': 0.7561, 'fpr': 0.0761, 'f1score': 0.7467, 'precision': 0.7376, 'tpr': 0.7561}, 6), (2.8082, 2.4389, 0.6307, 0.9972, {'recall': 0.9972, 'fpr': 0.0007, 'f1score': 0.9973, 'precision': 0.9975, 'tpr': 0.9972}, 7), (2.8082, 2.4389, 0.6307, 0.9398, {'recall': 0.9398, 'fpr': 0.3579, 'f1score': 0.5864, 'precision': 0.4262, 'tpr': 0.9398}, 7)]
#     gen = 7
#     numgens = 20
#     numalphas = 1000
#     myepsilon = 0.0001
#     mylambda = 10
#     final_payoff = 2.8082
















    # (7,9)
    
    # 7 and 9 for delta from 10 to 100 in steps of 10. default is 20.


#     rls = [(1, 0, 1, 0.9669, {'recall': 0.9669, 'fpr': 0.0978, 'f1score': 0.8318, 'precision': 0.7299, 'tpr': 0.9669}, 0), (0, 0, 1, 0.9618, {'recall': 0.9618, 'fpr': 0.0939, 'f1score': 0.8331, 'precision': 0.7347, 'tpr': 0.9618}, 0), (0.7545, 0.0428, 0.2883, 0.9572, {'recall': 0.9572, 'fpr': 0.2166, 'f1score': 0.6947, 'precision': 0.5452, 'tpr': 0.9572}, 0), (0.7545, 0.0428, 0.2883, 0.9937, {'recall': 0.9937, 'fpr': 0.0027, 'f1score': 0.9919, 'precision': 0.9901, 'tpr': 0.9937}, 1), (0.7545, 0.0428, 0.2883, 0.9619, {'recall': 0.9619, 'fpr': 0.2111, 'f1score': 0.7018, 'precision': 0.5524, 'tpr': 0.9619}, 1)]
#     gen = 1
#     TempMax = 1000
#     TempMin = 5
#     SampleSize = 50
#     ReductionRate = 0.6
#     eta = 2
#     delta = 10
#     max_steps = 3000


#     rls = [(1, 0, 1, 0.9265, {'recall': 0.9265, 'fpr': 0.0982, 'f1score': 0.8097, 'precision': 0.7191, 'tpr': 0.9265}, 0), (0, 0, 1, 0.94, {'recall': 0.94, 'fpr': 0.0908, 'f1score': 0.8266, 'precision': 0.7377, 'tpr': 0.94}, 0), (0.6629, 0.0784, 0.4155, 0.9216, {'recall': 0.9216, 'fpr': 0.1523, 'f1score': 0.7423, 'precision': 0.6213, 'tpr': 0.9216}, 0), (0.6629, 0.0784, 0.4155, 0.9216, {'recall': 0.9216, 'fpr': 0.1523, 'f1score': 0.7423, 'precision': 0.6213, 'tpr': 0.9216}, 1), (0.6629, 0.0784, 0.4155, 0.9872, {'recall': 0.9872, 'fpr': 0.0093, 'f1score': 0.9767, 'precision': 0.9664, 'tpr': 0.9872}, 2), (0.6629, 0.0784, 0.4155, 0.9419, {'recall': 0.9419, 'fpr': 0.1591, 'f1score': 0.7456, 'precision': 0.617, 'tpr': 0.9419}, 2)]
#     gen = 2
#     TempMax = 1000
#     TempMin = 5
#     SampleSize = 50
#     ReductionRate = 0.6
#     eta = 2
#     delta = 20
#     max_steps = 3000

#     rls = [(1, 0, 1, 0.9159, {'recall': 0.9159, 'fpr': 0.1012, 'f1score': 0.8004, 'precision': 0.7108, 'tpr': 0.9159}, 0), (0, 0, 1, 0.9247, {'recall': 0.9247, 'fpr': 0.0969, 'f1score': 0.8107, 'precision': 0.7217, 'tpr': 0.9247}, 0), (0.7875, 0.0956, 0.3081, 0.9044, {'recall': 0.9044, 'fpr': 0.2016, 'f1score': 0.6822, 'precision': 0.5476, 'tpr': 0.9044}, 0), (0.7875, 0.0956, 0.3081, 0.9044, {'recall': 0.9044, 'fpr': 0.2016, 'f1score': 0.6822, 'precision': 0.5476, 'tpr': 0.9044}, 1), (0.7875, 0.0956, 0.3081, 0.9719, {'recall': 0.9719, 'fpr': 0.087, 'f1score': 0.8486, 'precision': 0.753, 'tpr': 0.9719}, 2), (0.7875, 0.0956, 0.3081, 0.9223, {'recall': 0.9223, 'fpr': 0.2068, 'f1score': 0.6868, 'precision': 0.5471, 'tpr': 0.9223}, 2)]
#     gen = 2
#     TempMax = 1000
#     TempMin = 5
#     SampleSize = 50
#     ReductionRate = 0.6
#     eta = 2
#     delta = 30
#     max_steps = 3000

#     rls = [(1, 0, 1, 0.9519, {'recall': 0.9519, 'fpr': 0.1021, 'f1score': 0.8184, 'precision': 0.7177, 'tpr': 0.9519}, 0), (0, 0, 1, 0.9544, {'recall': 0.9544, 'fpr': 0.0997, 'f1score': 0.8226, 'precision': 0.7228, 'tpr': 0.9544}, 0), (0.6602, 0.0606, 0.4004, 0.9394, {'recall': 0.9394, 'fpr': 0.3505, 'f1score': 0.5824, 'precision': 0.422, 'tpr': 0.9394}, 0), (0.6602, 0.0606, 0.4004, 0.9394, {'recall': 0.9394, 'fpr': 0.3505, 'f1score': 0.5824, 'precision': 0.422, 'tpr': 0.9394}, 1), (0.6602, 0.0606, 0.4004, 0.9989, {'recall': 0.9989, 'fpr': 0.0002, 'f1score': 0.9991, 'precision': 0.9993, 'tpr': 0.9989}, 2), (0.6602, 0.0606, 0.4004, 0.9523, {'recall': 0.9523, 'fpr': 0.3458, 'f1score': 0.5895, 'precision': 0.4269, 'tpr': 0.9523}, 2)]
#     gen = 2
#     TempMax = 1000
#     TempMin = 5
#     SampleSize = 50
#     ReductionRate = 0.6
#     eta = 2
#     delta = 40
#     max_steps = 3000

#     rls = [(1, 0, 1, 0.9584, {'recall': 0.9584, 'fpr': 0.1091, 'f1score': 0.8125, 'precision': 0.7052, 'tpr': 0.9584}, 0), (0, 0, 1, 0.9599, {'recall': 0.9599, 'fpr': 0.1066, 'f1score': 0.8151, 'precision': 0.7082, 'tpr': 0.9599}, 0), (0.5113, 0.0423, 0.531, 0.9577, {'recall': 0.9577, 'fpr': 0.2956, 'f1score': 0.6297, 'precision': 0.469, 'tpr': 0.9577}, 0), (0.5113, 0.0423, 0.531, 0.9577, {'recall': 0.9577, 'fpr': 0.2956, 'f1score': 0.6297, 'precision': 0.469, 'tpr': 0.9577}, 1), (0.5113, 0.0423, 0.531, 1.0, {'recall': 1.0, 'fpr': 0.0001, 'f1score': 0.9998, 'precision': 0.9996, 'tpr': 1.0}, 2), (0.5113, 0.0423, 0.531, 0.9501, {'recall': 0.9501, 'fpr': 0.3132, 'f1score': 0.6117, 'precision': 0.451, 'tpr': 0.9501}, 2)]
#     gen = 2
#     TempMax = 1000
#     TempMin = 5
#     SampleSize = 50
#     ReductionRate = 0.6
#     eta = 2
#     delta = 50
#     max_steps = 3000

#     rls = [(1, 0, 1, 0.9387, {'recall': 0.9387, 'fpr': 0.1071, 'f1score': 0.8042, 'precision': 0.7034, 'tpr': 0.9387}, 0), (0, 0, 1, 0.9475, {'recall': 0.9475, 'fpr': 0.1011, 'f1score': 0.8185, 'precision': 0.7204, 'tpr': 0.9475}, 0), (0.6391, 0.0692, 0.4301, 0.9308, {'recall': 0.9308, 'fpr': 0.3217, 'f1score': 0.5986, 'precision': 0.4412, 'tpr': 0.9308}, 0), (0.6391, 0.0692, 0.4301, 0.9308, {'recall': 0.9308, 'fpr': 0.3217, 'f1score': 0.5986, 'precision': 0.4412, 'tpr': 0.9308}, 1), (0.6391, 0.0692, 0.4301, 0.9993, {'recall': 0.9993, 'fpr': 0.0001, 'f1score': 0.9995, 'precision': 0.9996, 'tpr': 0.9993}, 2), (0.6391, 0.0692, 0.4301, 0.9444, {'recall': 0.9444, 'fpr': 0.34, 'f1score': 0.5911, 'precision': 0.4301, 'tpr': 0.9444}, 2)]
#     gen = 2
#     TempMax = 1000
#     TempMin = 5
#     SampleSize = 50
#     ReductionRate = 0.6
#     eta = 2
#     delta = 60
#     max_steps = 3000

#     rls = [(1, 0, 1, 0.9379, {'recall': 0.9379, 'fpr': 0.1085, 'f1score': 0.8016, 'precision': 0.6999, 'tpr': 0.9379}, 0), (0, 0, 1, 0.9472, {'recall': 0.9472, 'fpr': 0.1072, 'f1score': 0.8085, 'precision': 0.7052, 'tpr': 0.9472}, 0), (0.6594, 0.0599, 0.4005, 0.9401, {'recall': 0.9401, 'fpr': 0.2951, 'f1score': 0.6217, 'precision': 0.4644, 'tpr': 0.9401}, 0), (0.6594, 0.0599, 0.4005, 0.9993, {'recall': 0.9993, 'fpr': 0.0001, 'f1score': 0.9995, 'precision': 0.9996, 'tpr': 0.9993}, 1), (0.6594, 0.0599, 0.4005, 0.9428, {'recall': 0.9428, 'fpr': 0.2813, 'f1score': 0.6343, 'precision': 0.4779, 'tpr': 0.9428}, 1)]
#     gen = 1
#     TempMax = 1000
#     TempMin = 5
#     SampleSize = 50
#     ReductionRate = 0.6
#     eta = 2
#     delta = 70
#     max_steps = 3000

    rls = [(1, 0, 1, 0.926, {'recall': 0.926, 'fpr': 0.1025, 'f1score': 0.8039, 'precision': 0.7102, 'tpr': 0.926}, 0), (0, 0, 1, 0.9367, {'recall': 0.9367, 'fpr': 0.1007, 'f1score': 0.8118, 'precision': 0.7163, 'tpr': 0.9367}, 0), (0.5938, 0.0719, 0.4781, 0.9281, {'recall': 0.9281, 'fpr': 0.2123, 'f1score': 0.6855, 'precision': 0.5434, 'tpr': 0.9281}, 0), (0.5938, 0.0719, 0.4781, 0.9281, {'recall': 0.9281, 'fpr': 0.2123, 'f1score': 0.6855, 'precision': 0.5434, 'tpr': 0.9281}, 1), (0.5938, 0.0719, 0.4781, 0.996, {'recall': 0.996, 'fpr': 0.0013, 'f1score': 0.9956, 'precision': 0.9953, 'tpr': 0.996}, 2), (0.5938, 0.0719, 0.4781, 0.931, {'recall': 0.931, 'fpr': 0.2274, 'f1score': 0.6719, 'precision': 0.5256, 'tpr': 0.931}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 80
    max_steps = 3000

    rls = [(1, 0, 1, 0.9632, {'recall': 0.9632, 'fpr': 0.1039, 'f1score': 0.8218, 'precision': 0.7166, 'tpr': 0.9632}, 0), (0, 0, 1, 0.9647, {'recall': 0.9647, 'fpr': 0.103, 'f1score': 0.824, 'precision': 0.7191, 'tpr': 0.9647}, 0), (0.5274, 0.0389, 0.5115, 0.9611, {'recall': 0.9611, 'fpr': 0.1143, 'f1score': 0.8066, 'precision': 0.6949, 'tpr': 0.9611}, 0), (0.5274, 0.0389, 0.5115, 0.9611, {'recall': 0.9611, 'fpr': 0.1143, 'f1score': 0.8066, 'precision': 0.6949, 'tpr': 0.9611}, 1), (0.5274, 0.0389, 0.5115, 0.9996, {'recall': 0.9996, 'fpr': 0.0002, 'f1score': 0.9995, 'precision': 0.9993, 'tpr': 0.9996}, 2), (0.5274, 0.0389, 0.5115, 0.9611, {'recall': 0.9611, 'fpr': 0.2723, 'f1score': 0.6475, 'precision': 0.4882, 'tpr': 0.9611}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 90
    max_steps = 3000


#     rls = [(1, 0, 1, 0.9637, {'recall': 0.9637, 'fpr': 0.1066, 'f1score': 0.8196, 'precision': 0.713, 'tpr': 0.9637}, 0), (0, 0, 1, 0.9624, {'recall': 0.9624, 'fpr': 0.1024, 'f1score': 0.8231, 'precision': 0.719, 'tpr': 0.9624}, 0), (0.5484, 0.0426, 0.4942, 0.9574, {'recall': 0.9574, 'fpr': 0.2985, 'f1score': 0.6277, 'precision': 0.4669, 'tpr': 0.9574}, 0), (0.5484, 0.0426, 0.4942, 0.9574, {'recall': 0.9574, 'fpr': 0.2985, 'f1score': 0.6277, 'precision': 0.4669, 'tpr': 0.9574}, 1), (0.5484, 0.0426, 0.4942, 0.9996, {'recall': 0.9996, 'fpr': 0.0, 'f1score': 0.9998, 'precision': 1.0, 'tpr': 0.9996}, 2), (0.5484, 0.0426, 0.4942, 0.9619, {'recall': 0.9619, 'fpr': 0.3353, 'f1score': 0.6011, 'precision': 0.4372, 'tpr': 0.9619}, 2)]
#     gen = 2
#     TempMax = 1000
#     TempMin = 5
#     SampleSize = 50
#     ReductionRate = 0.6
#     eta = 2
#     delta = 100
#     max_steps = 3000

    # 7 and 9 for eta from 2 to 10 in steps of 1. default is 2.

    rls = [(1, 0, 1, 0.9159, {'recall': 0.9159, 'fpr': 0.1012, 'f1score': 0.8004, 'precision': 0.7108, 'tpr': 0.9159}, 0), (0, 0, 1, 0.9247, {'recall': 0.9247, 'fpr': 0.0969, 'f1score': 0.8107, 'precision': 0.7217, 'tpr': 0.9247}, 0), (0.7875, 0.0956, 0.3081, 0.9044, {'recall': 0.9044, 'fpr': 0.2016, 'f1score': 0.6822, 'precision': 0.5476, 'tpr': 0.9044}, 0), (0.7875, 0.0956, 0.3081, 0.9044, {'recall': 0.9044, 'fpr': 0.2016, 'f1score': 0.6822, 'precision': 0.5476, 'tpr': 0.9044}, 1), (0.7875, 0.0956, 0.3081, 0.9719, {'recall': 0.9719, 'fpr': 0.087, 'f1score': 0.8486, 'precision': 0.753, 'tpr': 0.9719}, 2), (0.7875, 0.0956, 0.3081, 0.9223, {'recall': 0.9223, 'fpr': 0.2068, 'f1score': 0.6868, 'precision': 0.5471, 'tpr': 0.9223}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000



    rls = [(1, 0, 1, 0.9599, {'recall': 0.9599, 'fpr': 0.0932, 'f1score': 0.8339, 'precision': 0.7371, 'tpr': 0.9599}, 0), (0, 0, 1, 0.9571, {'recall': 0.9571, 'fpr': 0.093, 'f1score': 0.8319, 'precision': 0.7357, 'tpr': 0.9571}, 0), (0.4891, 0.0394, 0.5503, 0.9606, {'recall': 0.9606, 'fpr': 0.0224, 'f1score': 0.9405, 'precision': 0.9213, 'tpr': 0.9606}, 0), (0.4891, 0.0394, 0.5503, 0.9606, {'recall': 0.9606, 'fpr': 0.0224, 'f1score': 0.9405, 'precision': 0.9213, 'tpr': 0.9606}, 1), (0.4891, 0.0394, 0.5503, 0.9996, {'recall': 0.9996, 'fpr': 0.0, 'f1score': 0.9998, 'precision': 1.0, 'tpr': 0.9996}, 2), (0.4891, 0.0394, 0.5503, 0.9623, {'recall': 0.9623, 'fpr': 0.0217, 'f1score': 0.9425, 'precision': 0.9235, 'tpr': 0.9623}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 3
    delta = 20
    max_steps = 3000

    
    rls = [(1, 0, 1, 0.9675, {'recall': 0.9675, 'fpr': 0.1225, 'f1score': 0.8001, 'precision': 0.6821, 'tpr': 0.9675}, 0), (0, 0, 1, 0.9653, {'recall': 0.9653, 'fpr': 0.1224, 'f1score': 0.7975, 'precision': 0.6794, 'tpr': 0.9653}, 0), (0.6934, 0.0348, 0.3414, 0.9652, {'recall': 0.9652, 'fpr': 0.1902, 'f1score': 0.724, 'precision': 0.5792, 'tpr': 0.9652}, 0), (0.6934, 0.0348, 0.3414, 0.9974, {'recall': 0.9974, 'fpr': 0.0006, 'f1score': 0.9976, 'precision': 0.9978, 'tpr': 0.9974}, 1), (0.6934, 0.0348, 0.3414, 0.9663, {'recall': 0.9663, 'fpr': 0.1871, 'f1score': 0.7275, 'precision': 0.5834, 'tpr': 0.9663}, 1)]
    gen = 1
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 4
    delta = 20
    max_steps = 3000


    rls = [(1, 0, 1, 0.9467, {'recall': 0.9467, 'fpr': 0.1051, 'f1score': 0.8115, 'precision': 0.7101, 'tpr': 0.9467}, 0), (0, 0, 1, 0.9563, {'recall': 0.9563, 'fpr': 0.1044, 'f1score': 0.8181, 'precision': 0.7147, 'tpr': 0.9563}, 0), (0.5131, 0.052, 0.5389, 0.948, {'recall': 0.948, 'fpr': 0.092, 'f1score': 0.83, 'precision': 0.7381, 'tpr': 0.948}, 0), (0.5131, 0.052, 0.5389, 0.948, {'recall': 0.948, 'fpr': 0.092, 'f1score': 0.83, 'precision': 0.7381, 'tpr': 0.948}, 1), (0.5131, 0.052, 0.5389, 1.0, {'recall': 1.0, 'fpr': 0.0003, 'f1score': 0.9995, 'precision': 0.9989, 'tpr': 1.0}, 2), (0.5131, 0.052, 0.5389, 0.9484, {'recall': 0.9484, 'fpr': 0.0995, 'f1score': 0.8192, 'precision': 0.721, 'tpr': 0.9484}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 5
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9399, {'recall': 0.9399, 'fpr': 0.1113, 'f1score': 0.7998, 'precision': 0.696, 'tpr': 0.9399}, 0), (0, 0, 1, 0.9396, {'recall': 0.9396, 'fpr': 0.1069, 'f1score': 0.8054, 'precision': 0.7047, 'tpr': 0.9396}, 0), (0.5154, 0.0769, 0.5615, 0.9231, {'recall': 0.9231, 'fpr': 0.3181, 'f1score': 0.5964, 'precision': 0.4405, 'tpr': 0.9231}, 0), (0.5154, 0.0769, 0.5615, 0.9231, {'recall': 0.9231, 'fpr': 0.3181, 'f1score': 0.5964, 'precision': 0.4405, 'tpr': 0.9231}, 1), (0.5154, 0.0769, 0.5615, 1.0, {'recall': 1.0, 'fpr': 0.0002, 'f1score': 0.9996, 'precision': 0.9993, 'tpr': 1.0}, 2), (0.5154, 0.0769, 0.5615, 0.935, {'recall': 0.935, 'fpr': 0.3266, 'f1score': 0.5966, 'precision': 0.4381, 'tpr': 0.935}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 6
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9318, {'recall': 0.9318, 'fpr': 0.101, 'f1score': 0.8105, 'precision': 0.7171, 'tpr': 0.9318}, 0), (0, 0, 1, 0.942, {'recall': 0.942, 'fpr': 0.1007, 'f1score': 0.814, 'precision': 0.7166, 'tpr': 0.942}, 0), (0.6506, 0.0763, 0.4257, 0.9237, {'recall': 0.9237, 'fpr': 0.1987, 'f1score': 0.6949, 'precision': 0.557, 'tpr': 0.9237}, 0), (0.6506, 0.0763, 0.4257, 0.9237, {'recall': 0.9237, 'fpr': 0.1987, 'f1score': 0.6949, 'precision': 0.557, 'tpr': 0.9237}, 1), (0.6506, 0.0763, 0.4257, 0.993, {'recall': 0.993, 'fpr': 0.0012, 'f1score': 0.9943, 'precision': 0.9956, 'tpr': 0.993}, 2), (0.6506, 0.0763, 0.4257, 0.9433, {'recall': 0.9433, 'fpr': 0.1993, 'f1score': 0.7033, 'precision': 0.5607, 'tpr': 0.9433}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 7
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9311, {'recall': 0.9311, 'fpr': 0.102, 'f1score': 0.8079, 'precision': 0.7135, 'tpr': 0.9311}, 0), (0, 0, 1, 0.9298, {'recall': 0.9298, 'fpr': 0.1022, 'f1score': 0.8064, 'precision': 0.7119, 'tpr': 0.9298}, 0), (0.6966, 0.0729, 0.3763, 0.9271, {'recall': 0.9271, 'fpr': 0.2147, 'f1score': 0.6818, 'precision': 0.5391, 'tpr': 0.9271}, 0), (0.6966, 0.0729, 0.3763, 0.9271, {'recall': 0.9271, 'fpr': 0.2147, 'f1score': 0.6818, 'precision': 0.5391, 'tpr': 0.9271}, 1), (0.6966, 0.0729, 0.3763, 0.9289, {'recall': 0.9289, 'fpr': 0.0929, 'f1score': 0.8179, 'precision': 0.7306, 'tpr': 0.9289}, 2), (0.6966, 0.0729, 0.3763, 0.9329, {'recall': 0.9329, 'fpr': 0.2184, 'f1score': 0.6811, 'precision': 0.5364, 'tpr': 0.9329}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 8
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9367, {'recall': 0.9367, 'fpr': 0.1089, 'f1score': 0.8014, 'precision': 0.7002, 'tpr': 0.9367}, 0), (0, 0, 1, 0.944, {'recall': 0.944, 'fpr': 0.1042, 'f1score': 0.811, 'precision': 0.7109, 'tpr': 0.944}, 0), (0.5767, 0.0697, 0.493, 0.9303, {'recall': 0.9303, 'fpr': 0.2642, 'f1score': 0.643, 'precision': 0.4913, 'tpr': 0.9303}, 0), (0.5767, 0.0697, 0.493, 0.9985, {'recall': 0.9985, 'fpr': 0.0008, 'f1score': 0.9978, 'precision': 0.9971, 'tpr': 0.9985}, 1), (0.5767, 0.0697, 0.493, 0.9418, {'recall': 0.9418, 'fpr': 0.2598, 'f1score': 0.6515, 'precision': 0.498, 'tpr': 0.9418}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 9
    delta = 20
    max_steps = 3000


    # 7 and 9 for ReductionRate from 0.5 to 0.9 in steps of 0.1. default is 0.6.

    rls = [(1, 0, 1, 0.9324, {'recall': 0.9324, 'fpr': 0.0926, 'f1score': 0.8205, 'precision': 0.7326, 'tpr': 0.9324}, 0), (0, 0, 1, 0.9437, {'recall': 0.9437, 'fpr': 0.0926, 'f1score': 0.8262, 'precision': 0.7348, 'tpr': 0.9437}, 0), (0.587, 0.0686, 0.4816, 0.9314, {'recall': 0.9314, 'fpr': 0.3143, 'f1score': 0.6023, 'precision': 0.445, 'tpr': 0.9314}, 0), (0.587, 0.0686, 0.4816, 0.9314, {'recall': 0.9314, 'fpr': 0.3143, 'f1score': 0.6023, 'precision': 0.445, 'tpr': 0.9314}, 1), (0.587, 0.0686, 0.4816, 0.9996, {'recall': 0.9996, 'fpr': 0.0004, 'f1score': 0.9991, 'precision': 0.9985, 'tpr': 0.9996}, 2), (0.587, 0.0686, 0.4816, 0.9395, {'recall': 0.9395, 'fpr': 0.3151, 'f1score': 0.607, 'precision': 0.4484, 'tpr': 0.9395}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.5
    eta = 2
    delta = 20
    max_steps = 3000


    rls = [(1, 0, 1, 0.9461, {'recall': 0.9461, 'fpr': 0.0977, 'f1score': 0.8202, 'precision': 0.7238, 'tpr': 0.9461}, 0), (0, 0, 1, 0.9467, {'recall': 0.9467, 'fpr': 0.0973, 'f1score': 0.8219, 'precision': 0.7261, 'tpr': 0.9467}, 0), (0.512, 0.0697, 0.5577, 0.9303, {'recall': 0.9303, 'fpr': 0.3473, 'f1score': 0.582, 'precision': 0.4235, 'tpr': 0.9303}, 0), (0.512, 0.0697, 0.5577, 0.9303, {'recall': 0.9303, 'fpr': 0.3473, 'f1score': 0.582, 'precision': 0.4235, 'tpr': 0.9303}, 1), (0.512, 0.0697, 0.5577, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 2), (0.512, 0.0697, 0.5577, 0.9449, {'recall': 0.9449, 'fpr': 0.3541, 'f1score': 0.5826, 'precision': 0.4211, 'tpr': 0.9449}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000


    rls = [(1, 0, 1, 0.9221, {'recall': 0.9221, 'fpr': 0.0944, 'f1score': 0.8133, 'precision': 0.7275, 'tpr': 0.9221}, 0), (0, 0, 1, 0.9207, {'recall': 0.9207, 'fpr': 0.0926, 'f1score': 0.8149, 'precision': 0.731, 'tpr': 0.9207}, 0), (0.8565, 0.0902, 0.2337, 0.9098, {'recall': 0.9098, 'fpr': 0.2456, 'f1score': 0.647, 'precision': 0.502, 'tpr': 0.9098}, 0), (0.8565, 0.0902, 0.2337, 0.9098, {'recall': 0.9098, 'fpr': 0.2456, 'f1score': 0.647, 'precision': 0.502, 'tpr': 0.9098}, 1), (0.8565, 0.0902, 0.2337, 0.9744, {'recall': 0.9744, 'fpr': 0.1152, 'f1score': 0.8124, 'precision': 0.6966, 'tpr': 0.9744}, 2), (0.8565, 0.0902, 0.2337, 0.9213, {'recall': 0.9213, 'fpr': 0.2527, 'f1score': 0.6483, 'precision': 0.5001, 'tpr': 0.9213}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.7
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9427, {'recall': 0.9427, 'fpr': 0.1021, 'f1score': 0.8135, 'precision': 0.7154, 'tpr': 0.9427}, 0), (0, 0, 1, 0.9404, {'recall': 0.9404, 'fpr': 0.1028, 'f1score': 0.8102, 'precision': 0.7117, 'tpr': 0.9404}, 0), (0.6241, 0.0683, 0.4442, 0.9317, {'recall': 0.9317, 'fpr': 0.2392, 'f1score': 0.6629, 'precision': 0.5145, 'tpr': 0.9317}, 0), (0.6241, 0.0683, 0.4442, 0.9317, {'recall': 0.9317, 'fpr': 0.2392, 'f1score': 0.6629, 'precision': 0.5145, 'tpr': 0.9317}, 1), (0.6241, 0.0683, 0.4442, 0.9744, {'recall': 0.9744, 'fpr': 0.0459, 'f1score': 0.9091, 'precision': 0.852, 'tpr': 0.9744}, 2), (0.6241, 0.0683, 0.4442, 0.9426, {'recall': 0.9426, 'fpr': 0.2418, 'f1score': 0.6657, 'precision': 0.5146, 'tpr': 0.9426}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.948, {'recall': 0.948, 'fpr': 0.0971, 'f1score': 0.8222, 'precision': 0.7259, 'tpr': 0.948}, 0), (0, 0, 1, 0.9437, {'recall': 0.9437, 'fpr': 0.0964, 'f1score': 0.8212, 'precision': 0.7269, 'tpr': 0.9437}, 0), (0.7982, 0.0666, 0.2684, 0.9334, {'recall': 0.9334, 'fpr': 0.26, 'f1score': 0.6458, 'precision': 0.4937, 'tpr': 0.9334}, 0), (0.7982, 0.0666, 0.2684, 0.9334, {'recall': 0.9334, 'fpr': 0.26, 'f1score': 0.6458, 'precision': 0.4937, 'tpr': 0.9334}, 1), (0.7982, 0.0666, 0.2684, 0.9967, {'recall': 0.9967, 'fpr': 0.0007, 'f1score': 0.9971, 'precision': 0.9974, 'tpr': 0.9967}, 2), (0.7982, 0.0666, 0.2684, 0.935, {'recall': 0.935, 'fpr': 0.2678, 'f1score': 0.6405, 'precision': 0.4871, 'tpr': 0.935}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.9
    eta = 2
    delta = 20
    max_steps = 3000
    
    # 7 and 9 for SampleSize from 10 to 100 in steps of 10. default is 50.

    rls = [(1, 0, 1, 0.9147, {'recall': 0.9147, 'fpr': 0.091, 'f1score': 0.8131, 'precision': 0.7319, 'tpr': 0.9147}, 0), (0, 0, 1, 0.9287, {'recall': 0.9287, 'fpr': 0.0952, 'f1score': 0.8158, 'precision': 0.7274, 'tpr': 0.9287}, 0), (0.6432, 0.0939, 0.4507, 0.9061, {'recall': 0.9061, 'fpr': 0.3176, 'f1score': 0.5908, 'precision': 0.4383, 'tpr': 0.9061}, 0), (0.6432, 0.0939, 0.4507, 0.9061, {'recall': 0.9061, 'fpr': 0.3176, 'f1score': 0.5908, 'precision': 0.4383, 'tpr': 0.9061}, 1), (0.6432, 0.0939, 0.4507, 0.9993, {'recall': 0.9993, 'fpr': 0.0001, 'f1score': 0.9995, 'precision': 0.9996, 'tpr': 0.9993}, 2), (0.6432, 0.0939, 0.4507, 0.9085, {'recall': 0.9085, 'fpr': 0.3204, 'f1score': 0.5894, 'precision': 0.4362, 'tpr': 0.9085}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 10
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9535, {'recall': 0.9535, 'fpr': 0.1081, 'f1score': 0.811, 'precision': 0.7055, 'tpr': 0.9535}, 0), (0, 0, 1, 0.9616, {'recall': 0.9616, 'fpr': 0.1135, 'f1score': 0.8081, 'precision': 0.6968, 'tpr': 0.9616}, 0), (0.8208, 0.049, 0.2282, 0.951, {'recall': 0.951, 'fpr': 0.1948, 'f1score': 0.7131, 'precision': 0.5704, 'tpr': 0.951}, 0), (0.8208, 0.049, 0.2282, 0.951, {'recall': 0.951, 'fpr': 0.1948, 'f1score': 0.7131, 'precision': 0.5704, 'tpr': 0.951}, 1), (0.8208, 0.049, 0.2282, 0.9644, {'recall': 0.9644, 'fpr': 0.0678, 'f1score': 0.8709, 'precision': 0.7939, 'tpr': 0.9644}, 2), (0.8208, 0.049, 0.2282, 0.96, {'recall': 0.96, 'fpr': 0.2065, 'f1score': 0.705, 'precision': 0.5571, 'tpr': 0.96}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 20
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

#     rls = [(1, 0, 1, 0.9254, {'recall': 0.9254, 'fpr': 0.0964, 'f1score': 0.8117, 'precision': 0.7229, 'tpr': 0.9254}, 0), (0, 0, 1, 0.925, {'recall': 0.925, 'fpr': 0.0942, 'f1score': 0.8144, 'precision': 0.7274, 'tpr': 0.925}, 0), (0.809, 0.0804, 0.2714, 0.9196, {'recall': 0.9196, 'fpr': 0.2234, 'f1score': 0.671, 'precision': 0.5282, 'tpr': 0.9196}, 0), (0.809, 0.0804, 0.2714, 0.9196, {'recall': 0.9196, 'fpr': 0.2234, 'f1score': 0.671, 'precision': 0.5282, 'tpr': 0.9196}, 1), (0.809, 0.0804, 0.2714, 0.9971, {'recall': 0.9971, 'fpr': 0.0, 'f1score': 0.9985, 'precision': 1.0, 'tpr': 0.9971}, 2), (0.809, 0.0804, 0.2714, 0.9287, {'recall': 0.9287, 'fpr': 0.2166, 'f1score': 0.6813, 'precision': 0.538, 'tpr': 0.9287}, 2)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 30
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9421, {'recall': 0.9421, 'fpr': 0.1045, 'f1score': 0.8095, 'precision': 0.7096, 'tpr': 0.9421}, 0), (0, 0, 1, 0.9489, {'recall': 0.9489, 'fpr': 0.1034, 'f1score': 0.8139, 'precision': 0.7125, 'tpr': 0.9489}, 0), (0.7155, 0.0664, 0.3509, 0.9336, {'recall': 0.9336, 'fpr': 0.2902, 'f1score': 0.6229, 'precision': 0.4673, 'tpr': 0.9336}, 0), (0.7155, 0.0664, 0.3509, 0.9336, {'recall': 0.9336, 'fpr': 0.2902, 'f1score': 0.6229, 'precision': 0.4673, 'tpr': 0.9336}, 1), (0.7155, 0.0664, 0.3509, 0.9949, {'recall': 0.9949, 'fpr': 0.0016, 'f1score': 0.9945, 'precision': 0.9942, 'tpr': 0.9949}, 2), (0.7155, 0.0664, 0.3509, 0.939, {'recall': 0.939, 'fpr': 0.289, 'f1score': 0.6256, 'precision': 0.4691, 'tpr': 0.939}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 40
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9342, {'recall': 0.9342, 'fpr': 0.1015, 'f1score': 0.8095, 'precision': 0.7142, 'tpr': 0.9342}, 0), (0, 0, 1, 0.9492, {'recall': 0.9492, 'fpr': 0.1022, 'f1score': 0.8166, 'precision': 0.7165, 'tpr': 0.9492}, 0), (0.6213, 0.0692, 0.4479, 0.9308, {'recall': 0.9308, 'fpr': 0.2621, 'f1score': 0.6426, 'precision': 0.4906, 'tpr': 0.9308}, 0), (0.6213, 0.0692, 0.4479, 0.9308, {'recall': 0.9308, 'fpr': 0.2621, 'f1score': 0.6426, 'precision': 0.4906, 'tpr': 0.9308}, 1), (0.6213, 0.0692, 0.4479, 0.9971, {'recall': 0.9971, 'fpr': 0.0007, 'f1score': 0.9973, 'precision': 0.9974, 'tpr': 0.9971}, 2), (0.6213, 0.0692, 0.4479, 0.9447, {'recall': 0.9447, 'fpr': 0.2462, 'f1score': 0.6639, 'precision': 0.5118, 'tpr': 0.9447}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    
    rls = [(1, 0, 1, 0.9499, {'recall': 0.9499, 'fpr': 0.0895, 'f1score': 0.8336, 'precision': 0.7426, 'tpr': 0.9499}, 0), (0, 0, 1, 0.95, {'recall': 0.95, 'fpr': 0.0896, 'f1score': 0.8327, 'precision': 0.7412, 'tpr': 0.95}, 0), (0.7665, 0.0601, 0.2936, 0.9399, {'recall': 0.9399, 'fpr': 0.2382, 'f1score': 0.6686, 'precision': 0.5188, 'tpr': 0.9399}, 0), (0.7665, 0.0601, 0.2936, 0.9399, {'recall': 0.9399, 'fpr': 0.2382, 'f1score': 0.6686, 'precision': 0.5188, 'tpr': 0.9399}, 1), (0.7665, 0.0601, 0.2936, 0.9952, {'recall': 0.9952, 'fpr': 0.002, 'f1score': 0.994, 'precision': 0.9927, 'tpr': 0.9952}, 2), (0.7665, 0.0601, 0.2936, 0.9443, {'recall': 0.9443, 'fpr': 0.2471, 'f1score': 0.663, 'precision': 0.5108, 'tpr': 0.9443}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 60
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9428, {'recall': 0.9428, 'fpr': 0.1046, 'f1score': 0.8096, 'precision': 0.7093, 'tpr': 0.9428}, 0), (0, 0, 1, 0.9444, {'recall': 0.9444, 'fpr': 0.1001, 'f1score': 0.8165, 'precision': 0.7191, 'tpr': 0.9444}, 0), (0.7118, 0.0581, 0.3463, 0.9419, {'recall': 0.9419, 'fpr': 0.2704, 'f1score': 0.6417, 'precision': 0.4866, 'tpr': 0.9419}, 0), (0.7118, 0.0581, 0.3463, 0.9978, {'recall': 0.9978, 'fpr': 0.0002, 'f1score': 0.9985, 'precision': 0.9993, 'tpr': 0.9978}, 1), (0.7118, 0.0581, 0.3463, 0.9434, {'recall': 0.9434, 'fpr': 0.2855, 'f1score': 0.6305, 'precision': 0.4734, 'tpr': 0.9434}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 70
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9539, {'recall': 0.9539, 'fpr': 0.1077, 'f1score': 0.8128, 'precision': 0.7081, 'tpr': 0.9539}, 0), (0, 0, 1, 0.9592, {'recall': 0.9592, 'fpr': 0.1074, 'f1score': 0.8155, 'precision': 0.7092, 'tpr': 0.9592}, 0), (0.8481, 0.0586, 0.2105, 0.9414, {'recall': 0.9414, 'fpr': 0.2411, 'f1score': 0.6667, 'precision': 0.5161, 'tpr': 0.9414}, 0), (0.8736, 0.0828, 0.2092, 0.9172, {'recall': 0.9172, 'fpr': 0.153, 'f1score': 0.7393, 'precision': 0.6191, 'tpr': 0.9172}, 1), (0.8736, 0.0828, 0.2092, 0.9172, {'recall': 0.9172, 'fpr': 0.153, 'f1score': 0.7393, 'precision': 0.6191, 'tpr': 0.9172}, 2), (0.8736, 0.0828, 0.2092, 0.9455, {'recall': 0.9455, 'fpr': 0.1536, 'f1score': 0.753, 'precision': 0.6256, 'tpr': 0.9455}, 3), (0.8736, 0.0828, 0.2092, 0.9519, {'recall': 0.9519, 'fpr': 0.2028, 'f1score': 0.7048, 'precision': 0.5595, 'tpr': 0.9519}, 3)]
    gen = 3
    TempMin = 5
    TempMax = 1000
    SampleSize = 80
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9433, {'recall': 0.9433, 'fpr': 0.0942, 'f1score': 0.825, 'precision': 0.733, 'tpr': 0.9433}, 0), (0, 0, 1, 0.9456, {'recall': 0.9456, 'fpr': 0.0971, 'f1score': 0.8226, 'precision': 0.728, 'tpr': 0.9456}, 0), (0.805, 0.0685, 0.2635, 0.9315, {'recall': 0.9315, 'fpr': 0.2395, 'f1score': 0.6619, 'precision': 0.5133, 'tpr': 0.9315}, 0), (0.805, 0.0685, 0.2635, 0.9315, {'recall': 0.9315, 'fpr': 0.2395, 'f1score': 0.6619, 'precision': 0.5133, 'tpr': 0.9315}, 1), (0.805, 0.0685, 0.2635, 0.965, {'recall': 0.965, 'fpr': 0.1476, 'f1score': 0.7698, 'precision': 0.6403, 'tpr': 0.965}, 2), (0.805, 0.0685, 0.2635, 0.9396, {'recall': 0.9396, 'fpr': 0.2703, 'f1score': 0.6416, 'precision': 0.4872, 'tpr': 0.9396}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 90
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

#     rls = [(1, 0, 1, 0.9358, {'recall': 0.9358, 'fpr': 0.1121, 'f1score': 0.7973, 'precision': 0.6946, 'tpr': 0.9358}, 0), (0, 0, 1, 0.938, {'recall': 0.938, 'fpr': 0.1091, 'f1score': 0.8014, 'precision': 0.6996, 'tpr': 0.938}, 0), (0.792, 0.0749, 0.2829, 0.9251, {'recall': 0.9251, 'fpr': 0.2323, 'f1score': 0.6657, 'precision': 0.5199, 'tpr': 0.9251}, 0), (0.792, 0.0749, 0.2829, 0.9251, {'recall': 0.9251, 'fpr': 0.2323, 'f1score': 0.6657, 'precision': 0.5199, 'tpr': 0.9251}, 1), (0.792, 0.0749, 0.2829, 0.9857, {'recall': 0.9857, 'fpr': 0.1504, 'f1score': 0.7765, 'precision': 0.6405, 'tpr': 0.9857}, 2), (0.792, 0.0749, 0.2829, 0.9401, {'recall': 0.9401, 'fpr': 0.2446, 'f1score': 0.6608, 'precision': 0.5095, 'tpr': 0.9401}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 100
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    # 7 and 9 for lambda from 1 to 20 in steps of 2. default is 1.

    rls = [(1, 0, 1, 0.9401, {'recall': 0.9401, 'fpr': 0.0965, 'f1score': 0.8192, 'precision': 0.7259, 'tpr': 0.9401}, 0), (0, 0, 1, 0.9421, {'recall': 0.9421, 'fpr': 0.0968, 'f1score': 0.8195, 'precision': 0.7251, 'tpr': 0.9421}, 0), (0.4848, 0.0675, 0.5827, 0.9325, {'recall': 0.9325, 'fpr': 0.1445, 'f1score': 0.7571, 'precision': 0.6373, 'tpr': 0.9325}, 0), (0.4848, 0.0675, 0.5827, 0.9325, {'recall': 0.9325, 'fpr': 0.1445, 'f1score': 0.7571, 'precision': 0.6373, 'tpr': 0.9325}, 1), (0.4848, 0.0675, 0.5827, 0.9993, {'recall': 0.9993, 'fpr': 0.0003, 'f1score': 0.9991, 'precision': 0.9989, 'tpr': 0.9993}, 2), (0.4848, 0.0675, 0.5827, 0.9447, {'recall': 0.9447, 'fpr': 0.1362, 'f1score': 0.7734, 'precision': 0.6547, 'tpr': 0.9447}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 1
    
    rls = [(1, 0, 1, 0.9409, {'recall': 0.9409, 'fpr': 0.1103, 'f1score': 0.8012, 'precision': 0.6976, 'tpr': 0.9409}, 0), (0, 0, 1, 0.9452, {'recall': 0.9452, 'fpr': 0.1042, 'f1score': 0.8109, 'precision': 0.7099, 'tpr': 0.9452}, 0), (0.7466, 0.1957, 0.4491, 0.9348, {'recall': 0.9348, 'fpr': 0.3095, 'f1score': 0.6076, 'precision': 0.4501, 'tpr': 0.9348}, 0), (0.7466, 0.1957, 0.4491, 0.9348, {'recall': 0.9348, 'fpr': 0.3095, 'f1score': 0.6076, 'precision': 0.4501, 'tpr': 0.9348}, 1), (0.7466, 0.1957, 0.4491, 0.9978, {'recall': 0.9978, 'fpr': 0.0003, 'f1score': 0.9984, 'precision': 0.9989, 'tpr': 0.9978}, 2), (0.7466, 0.1957, 0.4491, 0.9438, {'recall': 0.9438, 'fpr': 0.3142, 'f1score': 0.6076, 'precision': 0.448, 'tpr': 0.9438}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 3
     
    rls = [(1, 0, 1, 0.9491, {'recall': 0.9491, 'fpr': 0.1017, 'f1score': 0.8178, 'precision': 0.7185, 'tpr': 0.9491}, 0), (0, 0, 1, 0.9427, {'recall': 0.9427, 'fpr': 0.0992, 'f1score': 0.8162, 'precision': 0.7197, 'tpr': 0.9427}, 0), (1.0495, 0.3314, 0.2819, 0.9337, {'recall': 0.9337, 'fpr': 0.2347, 'f1score': 0.6672, 'precision': 0.519, 'tpr': 0.9337}, 0), (1.0495, 0.3314, 0.2819, 0.9337, {'recall': 0.9337, 'fpr': 0.2347, 'f1score': 0.6672, 'precision': 0.519, 'tpr': 0.9337}, 1), (1.0495, 0.3314, 0.2819, 0.972, {'recall': 0.972, 'fpr': 0.1718, 'f1score': 0.7474, 'precision': 0.6071, 'tpr': 0.972}, 2), (1.0495, 0.3314, 0.2819, 0.9435, {'recall': 0.9435, 'fpr': 0.2259, 'f1score': 0.6794, 'precision': 0.5308, 'tpr': 0.9435}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 5
    

    rls = [(1, 0, 1, 0.9453, {'recall': 0.9453, 'fpr': 0.1102, 'f1score': 0.8047, 'precision': 0.7005, 'tpr': 0.9453}, 0), (0, 0, 1, 0.9577, {'recall': 0.9577, 'fpr': 0.1109, 'f1score': 0.8099, 'precision': 0.7016, 'tpr': 0.9577}, 0), (0.9955, 0.4385, 0.443, 0.9374, {'recall': 0.9374, 'fpr': 0.2889, 'f1score': 0.6259, 'precision': 0.4698, 'tpr': 0.9374}, 0), (0.9955, 0.4385, 0.443, 0.9374, {'recall': 0.9374, 'fpr': 0.2889, 'f1score': 0.6259, 'precision': 0.4698, 'tpr': 0.9374}, 1), (0.9955, 0.4385, 0.443, 0.9942, {'recall': 0.9942, 'fpr': 0.002, 'f1score': 0.9934, 'precision': 0.9927, 'tpr': 0.9942}, 2), (0.9955, 0.4385, 0.443, 0.9549, {'recall': 0.9549, 'fpr': 0.2783, 'f1score': 0.6423, 'precision': 0.4839, 'tpr': 0.9549}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 7

    rls = [(1, 0, 1, 0.961, {'recall': 0.961, 'fpr': 0.0964, 'f1score': 0.8306, 'precision': 0.7314, 'tpr': 0.961}, 0), (0, 0, 1, 0.9645, {'recall': 0.9645, 'fpr': 0.0994, 'f1score': 0.8275, 'precision': 0.7245, 'tpr': 0.9645}, 0), (1.0734, 0.4451, 0.3717, 0.9505, {'recall': 0.9505, 'fpr': 0.2541, 'f1score': 0.6583, 'precision': 0.5035, 'tpr': 0.9505}, 0), (1.0734, 0.4451, 0.3717, 0.9505, {'recall': 0.9505, 'fpr': 0.2541, 'f1score': 0.6583, 'precision': 0.5035, 'tpr': 0.9505}, 1), (1.0734, 0.4451, 0.3717, 0.9989, {'recall': 0.9989, 'fpr': 0.0, 'f1score': 0.9995, 'precision': 1.0, 'tpr': 0.9989}, 2), (1.0734, 0.4451, 0.3717, 0.9553, {'recall': 0.9553, 'fpr': 0.2647, 'f1score': 0.6516, 'precision': 0.4944, 'tpr': 0.9553}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 9

    rls = ('finalresults', [(1, 0, 1, 0.9511, {'recall': 0.9511, 'fpr': 0.0969, 'f1score': 0.8245, 'precision': 0.7277, 'tpr': 0.9511}, 0), (0, 0, 1, 0.9487, {'recall': 0.9487, 'fpr': 0.0949, 'f1score': 0.8263, 'precision': 0.7319, 'tpr': 0.9487}, 0), (1.1447, 0.6978, 0.5531, 0.9366, {'recall': 0.9366, 'fpr': 0.3563, 'f1score': 0.5776, 'precision': 0.4176, 'tpr': 0.9366}, 0), (1.1447, 0.6978, 0.5531, 0.9366, {'recall': 0.9366, 'fpr': 0.3563, 'f1score': 0.5776, 'precision': 0.4176, 'tpr': 0.9366}, 1), (1.1447, 0.6978, 0.5531, 0.9996, {'recall': 0.9996, 'fpr': 0.0003, 'f1score': 0.9993, 'precision': 0.9989, 'tpr': 0.9996}, 2), (1.1447, 0.6978, 0.5531, 0.9479, {'recall': 0.9479, 'fpr': 0.3548, 'f1score': 0.5819, 'precision': 0.4198, 'tpr': 0.9479}, 2)])
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 11

    rls = ('finalresults', [(1, 0, 1, 0.956, {'recall': 0.956, 'fpr': 0.0912, 'f1score': 0.8341, 'precision': 0.7398, 'tpr': 0.956}, 0), (0, 0, 1, 0.957, {'recall': 0.957, 'fpr': 0.0912, 'f1score': 0.8355, 'precision': 0.7414, 'tpr': 0.957}, 0), (1.4173, 0.8241, 0.4068, 0.9411, {'recall': 0.9411, 'fpr': 0.2753, 'f1score': 0.6371, 'precision': 0.4816, 'tpr': 0.9411}, 0), (1.4173, 0.8241, 0.4068, 0.9411, {'recall': 0.9411, 'fpr': 0.2753, 'f1score': 0.6371, 'precision': 0.4816, 'tpr': 0.9411}, 1), (1.4173, 0.8241, 0.4068, 0.9934, {'recall': 0.9934, 'fpr': 0.0137, 'f1score': 0.9721, 'precision': 0.9517, 'tpr': 0.9934}, 2), (1.4173, 0.8241, 0.4068, 0.9525, {'recall': 0.9525, 'fpr': 0.2777, 'f1score': 0.6387, 'precision': 0.4804, 'tpr': 0.9525}, 2)])
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 14

    rls = ('finalresults', [(1, 0, 1, 0.9447, {'recall': 0.9447, 'fpr': 0.106, 'f1score': 0.8092, 'precision': 0.7076, 'tpr': 0.9447}, 0), (0, 0, 1, 0.9444, {'recall': 0.9444, 'fpr': 0.1031, 'f1score': 0.8128, 'precision': 0.7134, 'tpr': 0.9444}, 0), (1.8265, 1.1387, 0.3122, 0.933, {'recall': 0.933, 'fpr': 0.1848, 'f1score': 0.7151, 'precision': 0.5797, 'tpr': 0.933}, 0), (1.8265, 1.1387, 0.3122, 0.933, {'recall': 0.933, 'fpr': 0.1848, 'f1score': 0.7151, 'precision': 0.5797, 'tpr': 0.933}, 1), (1.8265, 1.1387, 0.3122, 0.971, {'recall': 0.971, 'fpr': 0.0481, 'f1score': 0.9037, 'precision': 0.845, 'tpr': 0.971}, 2), (1.8265, 1.1387, 0.3122, 0.9447, {'recall': 0.9447, 'fpr': 0.1888, 'f1score': 0.717, 'precision': 0.5778, 'tpr': 0.9447}, 2)])
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 17

    rls = ('finalresults', [(1, 0, 1, 0.9505, {'recall': 0.9505, 'fpr': 0.097, 'f1score': 0.8234, 'precision': 0.7263, 'tpr': 0.9505}, 0), (0, 0, 1, 0.954, {'recall': 0.954, 'fpr': 0.0951, 'f1score': 0.8283, 'precision': 0.7319, 'tpr': 0.954}, 0), (1.8078, 1.2924, 0.4846, 0.9354, {'recall': 0.9354, 'fpr': 0.3395, 'f1score': 0.5878, 'precision': 0.4286, 'tpr': 0.9354}, 0), (1.8078, 1.2924, 0.4846, 0.9354, {'recall': 0.9354, 'fpr': 0.3395, 'f1score': 0.5878, 'precision': 0.4286, 'tpr': 0.9354}, 1), (1.8078, 1.2924, 0.4846, 0.9985, {'recall': 0.9985, 'fpr': 0.0012, 'f1score': 0.9971, 'precision': 0.9956, 'tpr': 0.9985}, 2), (1.8078, 1.2924, 0.4846, 0.9493, {'recall': 0.9493, 'fpr': 0.3406, 'f1score': 0.5935, 'precision': 0.4317, 'tpr': 0.9493}, 2)])
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 20



    
    # 7 and 9 for lambda from 0.1 to 10 in steps of 10. default is 1.
    rls = [(1, 0, 1, 0.9597, {'recall': 0.9597, 'fpr': 0.1001, 'f1score': 0.824, 'precision': 0.722, 'tpr': 0.9597}, 0), (0, 0, 1, 0.9594, {'recall': 0.9594, 'fpr': 0.101, 'f1score': 0.8229, 'precision': 0.7204, 'tpr': 0.9594}, 0), (1.2216, 0.4677, 0.2461, 0.9532, {'recall': 0.9532, 'fpr': 0.2081, 'f1score': 0.7013, 'precision': 0.5548, 'tpr': 0.9532}, 0), (1.2216, 0.4677, 0.2461, 0.9532, {'recall': 0.9532, 'fpr': 0.2081, 'f1score': 0.7013, 'precision': 0.5548, 'tpr': 0.9532}, 1), (1.2216, 0.4677, 0.2461, 0.996, {'recall': 0.996, 'fpr': 0.001, 'f1score': 0.9962, 'precision': 0.9963, 'tpr': 0.996}, 2), (1.2216, 0.4677, 0.2461, 0.9608, {'recall': 0.9608, 'fpr': 0.2257, 'f1score': 0.6882, 'precision': 0.536, 'tpr': 0.9608}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 10

    rls = [(1, 0, 1, 0.9331, {'recall': 0.9331, 'fpr': 0.1147, 'f1score': 0.7934, 'precision': 0.6901, 'tpr': 0.9331}, 0), (0, 0, 1, 0.9279, {'recall': 0.9279, 'fpr': 0.1097, 'f1score': 0.7958, 'precision': 0.6966, 'tpr': 0.9279}, 0), (0.5166, 0.0073, 0.4907, 0.9266, {'recall': 0.9266, 'fpr': 0.3582, 'f1score': 0.5716, 'precision': 0.4132, 'tpr': 0.9266}, 0), (0.5415, 0.0001, 0.4586, 0.9993, {'recall': 0.9993, 'fpr': 0.0003, 'f1score': 0.9991, 'precision': 0.9989, 'tpr': 0.9993}, 1), (0.5472, 0.0001, 0.4529, 0.9993, {'recall': 0.9993, 'fpr': 0.0002, 'f1score': 0.9993, 'precision': 0.9993, 'tpr': 0.9993}, 2), (0.5584, 0.0, 0.4416, 0.9996, {'recall': 0.9996, 'fpr': 0.0, 'f1score': 0.9998, 'precision': 1.0, 'tpr': 0.9996}, 3), (0.5584, 0.0, 0.4416, 0.9996, {'recall': 0.9996, 'fpr': 0.0, 'f1score': 0.9998, 'precision': 1.0, 'tpr': 0.9996}, 4), (0.5584, 0.0, 0.4416, 0.9989, {'recall': 0.9989, 'fpr': 0.0002, 'f1score': 0.9991, 'precision': 0.9993, 'tpr': 0.9989}, 5), (0.5584, 0.0, 0.4416, 0.9336, {'recall': 0.9336, 'fpr': 0.0509, 'f1score': 0.8807, 'precision': 0.8334, 'tpr': 0.9336}, 5)]
    gen = 5
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 0.1

    rls = [(1, 0, 1, 0.9272, {'recall': 0.9272, 'fpr': 0.09, 'f1score': 0.8209, 'precision': 0.7366, 'tpr': 0.9272}, 0), (0, 0, 1, 0.9339, {'recall': 0.9339, 'fpr': 0.0935, 'f1score': 0.8194, 'precision': 0.7299, 'tpr': 0.9339}, 0), (0.7558, 0.0811, 0.3253, 0.9189, {'recall': 0.9189, 'fpr': 0.2869, 'f1score': 0.6167, 'precision': 0.464, 'tpr': 0.9189}, 0), (0.7558, 0.0811, 0.3253, 0.9189, {'recall': 0.9189, 'fpr': 0.2869, 'f1score': 0.6167, 'precision': 0.464, 'tpr': 0.9189}, 1), (0.7558, 0.0811, 0.3253, 0.9835, {'recall': 0.9835, 'fpr': 0.0328, 'f1score': 0.9346, 'precision': 0.8904, 'tpr': 0.9835}, 2), (0.7558, 0.0811, 0.3253, 0.9205, {'recall': 0.9205, 'fpr': 0.3103, 'f1score': 0.6006, 'precision': 0.4457, 'tpr': 0.9205}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 1












    # (4,9)
    # 4 and 9 for delta from 10 to 100 in steps of 10. default is 20.

    rls = [(1, 0, 1, 0.9753, {'recall': 0.9753, 'fpr': 0.1453, 'f1score': 0.7932, 'precision': 0.6684, 'tpr': 0.9753}, 0), (0, 0, 1, 0.9711, {'recall': 0.9711, 'fpr': 0.1428, 'f1score': 0.7928, 'precision': 0.6698, 'tpr': 0.9711}, 0), (0.6404, 0.0281, 0.3877, 0.9719, {'recall': 0.9719, 'fpr': 0.2592, 'f1score': 0.6856, 'precision': 0.5296, 'tpr': 0.9719}, 0), (0.6526, 0.0442, 0.3916, 0.9558, {'recall': 0.9558, 'fpr': 0.1893, 'f1score': 0.738, 'precision': 0.601, 'tpr': 0.9558}, 1), (0.6791, 0.0662, 0.3871, 0.9338, {'recall': 0.9338, 'fpr': 0.0639, 'f1score': 0.8695, 'precision': 0.8136, 'tpr': 0.9338}, 2), (0.6791, 0.0662, 0.3871, 0.9338, {'recall': 0.9338, 'fpr': 0.0639, 'f1score': 0.8695, 'precision': 0.8136, 'tpr': 0.9338}, 3), (0.6791, 0.0662, 0.3871, 0.9198, {'recall': 0.9198, 'fpr': 0.1221, 'f1score': 0.7899, 'precision': 0.6922, 'tpr': 0.9198}, 4), (0.6791, 0.0662, 0.3871, 0.9705, {'recall': 0.9705, 'fpr': 0.2676, 'f1score': 0.6776, 'precision': 0.5206, 'tpr': 0.9705}, 4)]
    gen = 4
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 10
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.951, {'recall': 0.951, 'fpr': 0.0987, 'f1score': 0.8232, 'precision': 0.7257, 'tpr': 0.951}, 0), (0, 0, 1, 0.957, {'recall': 0.957, 'fpr': 0.0972, 'f1score': 0.8272, 'precision': 0.7284, 'tpr': 0.957}, 0), (0.6393, 0.0514, 0.4121, 0.9486, {'recall': 0.9486, 'fpr': 0.2986, 'f1score': 0.6233, 'precision': 0.4641, 'tpr': 0.9486}, 0), (0.6393, 0.0514, 0.4121, 0.9486, {'recall': 0.9486, 'fpr': 0.2986, 'f1score': 0.6233, 'precision': 0.4641, 'tpr': 0.9486}, 1), (0.6393, 0.0514, 0.4121, 0.9985, {'recall': 0.9985, 'fpr': 0.0002, 'f1score': 0.9989, 'precision': 0.9993, 'tpr': 0.9985}, 2), (0.6393, 0.0514, 0.4121, 0.9543, {'recall': 0.9543, 'fpr': 0.3, 'f1score': 0.6262, 'precision': 0.466, 'tpr': 0.9543}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.5
    eta = 2
    delta = 20
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.9798, {'recall': 0.9798, 'fpr': 0.1613, 'f1score': 0.7791, 'precision': 0.6466, 'tpr': 0.9798}, 0), (0, 0, 1, 0.9799, {'recall': 0.9799, 'fpr': 0.1571, 'f1score': 0.7819, 'precision': 0.6505, 'tpr': 0.9799}, 0), (0.5727, 0.0202, 0.4475, 0.9798, {'recall': 0.9798, 'fpr': 0.2181, 'f1score': 0.7218, 'precision': 0.5713, 'tpr': 0.9798}, 0), (0.5727, 0.0202, 0.4475, 0.9798, {'recall': 0.9798, 'fpr': 0.2181, 'f1score': 0.7218, 'precision': 0.5713, 'tpr': 0.9798}, 1), (0.5727, 0.0202, 0.4475, 1.0, {'recall': 1.0, 'fpr': 0.0002, 'f1score': 0.9997, 'precision': 0.9993, 'tpr': 1.0}, 2), (0.5727, 0.0202, 0.4475, 0.9824, {'recall': 0.9824, 'fpr': 0.2244, 'f1score': 0.7194, 'precision': 0.5675, 'tpr': 0.9824}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 30
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.978, {'recall': 0.978, 'fpr': 0.1187, 'f1score': 0.8239, 'precision': 0.7118, 'tpr': 0.978}, 0), (0, 0, 1, 0.9742, {'recall': 0.9742, 'fpr': 0.1165, 'f1score': 0.8241, 'precision': 0.7141, 'tpr': 0.9742}, 0), (0.6591, 0.0248, 0.3657, 0.9752, {'recall': 0.9752, 'fpr': 0.3186, 'f1score': 0.6417, 'precision': 0.4781, 'tpr': 0.9752}, 0), (0.6591, 0.0248, 0.3657, 0.9752, {'recall': 0.9752, 'fpr': 0.3186, 'f1score': 0.6417, 'precision': 0.4781, 'tpr': 0.9752}, 1), (0.6591, 0.0248, 0.3657, 0.9932, {'recall': 0.9932, 'fpr': 0.0013, 'f1score': 0.9944, 'precision': 0.9956, 'tpr': 0.9932}, 2), (0.6591, 0.0248, 0.3657, 0.9715, {'recall': 0.9715, 'fpr': 0.3213, 'f1score': 0.6376, 'precision': 0.4745, 'tpr': 0.9715}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 40
    max_steps = 3000


    rls = [(1, 0, 1, 0.9766, {'recall': 0.9766, 'fpr': 0.1283, 'f1score': 0.8125, 'precision': 0.6956, 'tpr': 0.9766}, 0), (0, 0, 1, 0.9745, {'recall': 0.9745, 'fpr': 0.1281, 'f1score': 0.8111, 'precision': 0.6946, 'tpr': 0.9745}, 0), (0.5847, 0.0279, 0.4432, 0.9721, {'recall': 0.9721, 'fpr': 0.3235, 'f1score': 0.6356, 'precision': 0.4721, 'tpr': 0.9721}, 0), (0.5847, 0.0279, 0.4432, 0.9721, {'recall': 0.9721, 'fpr': 0.3235, 'f1score': 0.6356, 'precision': 0.4721, 'tpr': 0.9721}, 1), (0.5847, 0.0279, 0.4432, 0.9986, {'recall': 0.9986, 'fpr': 0.0002, 'f1score': 0.999, 'precision': 0.9993, 'tpr': 0.9986}, 2), (0.5847, 0.0279, 0.4432, 0.9718, {'recall': 0.9718, 'fpr': 0.3398, 'f1score': 0.6254, 'precision': 0.461, 'tpr': 0.9718}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 50
    max_steps = 3000

    rls = [(1, 0, 1, 0.9779, {'recall': 0.9779, 'fpr': 0.1203, 'f1score': 0.821, 'precision': 0.7076, 'tpr': 0.9779}, 0), (0, 0, 1, 0.9749, {'recall': 0.9749, 'fpr': 0.121, 'f1score': 0.8196, 'precision': 0.7069, 'tpr': 0.9749}, 0), (0.7024, 0.0235, 0.3211, 0.9765, {'recall': 0.9765, 'fpr': 0.3073, 'f1score': 0.6497, 'precision': 0.4868, 'tpr': 0.9765}, 0), (0.7024, 0.0235, 0.3211, 0.9765, {'recall': 0.9765, 'fpr': 0.3073, 'f1score': 0.6497, 'precision': 0.4868, 'tpr': 0.9765}, 1), (0.7024, 0.0235, 0.3211, 0.9688, {'recall': 0.9688, 'fpr': 0.0183, 'f1score': 0.9546, 'precision': 0.9408, 'tpr': 0.9688}, 2), (0.7024, 0.0235, 0.3211, 0.9685, {'recall': 0.9685, 'fpr': 0.2941, 'f1score': 0.6567, 'precision': 0.4968, 'tpr': 0.9685}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 60
    max_steps = 3000

    rls = [(1, 0, 1, 0.9721, {'recall': 0.9721, 'fpr': 0.1277, 'f1score': 0.8099, 'precision': 0.694, 'tpr': 0.9721}, 0), (0, 0, 1, 0.9674, {'recall': 0.9674, 'fpr': 0.1271, 'f1score': 0.8086, 'precision': 0.6945, 'tpr': 0.9674}, 0), (0.7315, 0.031, 0.2995, 0.969, {'recall': 0.969, 'fpr': 0.252, 'f1score': 0.6879, 'precision': 0.5332, 'tpr': 0.969}, 0), (0.7315, 0.031, 0.2995, 0.9176, {'recall': 0.9176, 'fpr': 0.156, 'f1score': 0.7525, 'precision': 0.6378, 'tpr': 0.9176}, 1), (0.7315, 0.031, 0.2995, 0.9666, {'recall': 0.9666, 'fpr': 0.263, 'f1score': 0.6781, 'precision': 0.5222, 'tpr': 0.9666}, 1)]
    gen = 1
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 70
    max_steps = 3000

    rls = [(1, 0, 1, 0.9622, {'recall': 0.9622, 'fpr': 0.1582, 'f1score': 0.7718, 'precision': 0.6443, 'tpr': 0.9622}, 0), (0, 0, 1, 0.9619, {'recall': 0.9619, 'fpr': 0.1518, 'f1score': 0.7785, 'precision': 0.6538, 'tpr': 0.9619}, 0), (0.6013, 0.0413, 0.44, 0.9587, {'recall': 0.9587, 'fpr': 0.2806, 'f1score': 0.6625, 'precision': 0.5062, 'tpr': 0.9587}, 0), (0.6013, 0.0413, 0.44, 0.9587, {'recall': 0.9587, 'fpr': 0.2806, 'f1score': 0.6625, 'precision': 0.5062, 'tpr': 0.9587}, 1), (0.6013, 0.0413, 0.44, 0.9959, {'recall': 0.9959, 'fpr': 0.0023, 'f1score': 0.994, 'precision': 0.9922, 'tpr': 0.9959}, 2), (0.6013, 0.0413, 0.44, 0.9652, {'recall': 0.9652, 'fpr': 0.2895, 'f1score': 0.6594, 'precision': 0.5007, 'tpr': 0.9652}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 80
    max_steps = 3000

    rls = [(1, 0, 1, 0.9289, {'recall': 0.9289, 'fpr': 0.1008, 'f1score': 0.8065, 'precision': 0.7126, 'tpr': 0.9289}, 0), (0, 0, 1, 0.9309, {'recall': 0.9309, 'fpr': 0.0962, 'f1score': 0.8148, 'precision': 0.7245, 'tpr': 0.9309}, 0), (0.604, 0.072, 0.468, 0.928, {'recall': 0.928, 'fpr': 0.2419, 'f1score': 0.6573, 'precision': 0.5089, 'tpr': 0.928}, 0), (0.604, 0.072, 0.468, 0.928, {'recall': 0.928, 'fpr': 0.2419, 'f1score': 0.6573, 'precision': 0.5089, 'tpr': 0.928}, 1), (0.604, 0.072, 0.468, 0.9985, {'recall': 0.9985, 'fpr': 0.0004, 'f1score': 0.9985, 'precision': 0.9985, 'tpr': 0.9985}, 2), (0.604, 0.072, 0.468, 0.9278, {'recall': 0.9278, 'fpr': 0.2546, 'f1score': 0.6472, 'precision': 0.4969, 'tpr': 0.9278}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 90
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.9494, {'recall': 0.9494, 'fpr': 0.1091, 'f1score': 0.8086, 'precision': 0.7041, 'tpr': 0.9494}, 0), (0, 0, 1, 0.9539, {'recall': 0.9539, 'fpr': 0.1055, 'f1score': 0.8144, 'precision': 0.7105, 'tpr': 0.9539}, 0), (0.7565, 0.0563, 0.2998, 0.9437, {'recall': 0.9437, 'fpr': 0.2761, 'f1score': 0.6359, 'precision': 0.4795, 'tpr': 0.9437}, 0), (0.7565, 0.0563, 0.2998, 0.9437, {'recall': 0.9437, 'fpr': 0.2761, 'f1score': 0.6359, 'precision': 0.4795, 'tpr': 0.9437}, 1), (0.7565, 0.0563, 0.2998, 0.9924, {'recall': 0.9924, 'fpr': 0.0026, 'f1score': 0.9915, 'precision': 0.9906, 'tpr': 0.9924}, 2), (0.7565, 0.0563, 0.2998, 0.9453, {'recall': 0.9453, 'fpr': 0.3111, 'f1score': 0.6106, 'precision': 0.451, 'tpr': 0.9453}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 100
    max_steps = 3000

    
    # 4 and 9 for eta from 2 to 10 in steps of 1. default is 2.

    rls = [(1, 0, 1, 0.9766, {'recall': 0.9766, 'fpr': 0.1449, 'f1score': 0.7934, 'precision': 0.6681, 'tpr': 0.9766}, 0), (0, 0, 1, 0.9743, {'recall': 0.9743, 'fpr': 0.1441, 'f1score': 0.7938, 'precision': 0.6697, 'tpr': 0.9743}, 0), (0.6402, 0.0274, 0.3872, 0.9726, {'recall': 0.9726, 'fpr': 0.2536, 'f1score': 0.6903, 'precision': 0.535, 'tpr': 0.9726}, 0), (0.691, 0.0812, 0.3902, 0.9188, {'recall': 0.9188, 'fpr': 0.1203, 'f1score': 0.7923, 'precision': 0.6964, 'tpr': 0.9188}, 1), (0.691, 0.0812, 0.3902, 0.9188, {'recall': 0.9188, 'fpr': 0.1203, 'f1score': 0.7923, 'precision': 0.6964, 'tpr': 0.9188}, 2), (0.691, 0.0812, 0.3902, 0.8576, {'recall': 0.8576, 'fpr': 0.1211, 'f1score': 0.7583, 'precision': 0.6796, 'tpr': 0.8576}, 3), (0.691, 0.0812, 0.3902, 0.9752, {'recall': 0.9752, 'fpr': 0.2482, 'f1score': 0.6945, 'precision': 0.5392, 'tpr': 0.9752}, 3)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000


    rls = [(1, 0, 1, 0.9416, {'recall': 0.9416, 'fpr': 0.1497, 'f1score': 0.772, 'precision': 0.6542, 'tpr': 0.9416}, 0), (0, 0, 1, 0.9383, {'recall': 0.9383, 'fpr': 0.1512, 'f1score': 0.7669, 'precision': 0.6484, 'tpr': 0.9383}, 0), (0.6464, 0.0655, 0.4191, 0.9345, {'recall': 0.9345, 'fpr': 0.2934, 'f1score': 0.641, 'precision': 0.4878, 'tpr': 0.9345}, 0), (0.6464, 0.0655, 0.4191, 0.9345, {'recall': 0.9345, 'fpr': 0.2934, 'f1score': 0.641, 'precision': 0.4878, 'tpr': 0.9345}, 1), (0.6464, 0.0655, 0.4191, 0.9986, {'recall': 0.9986, 'fpr': 0.0008, 'f1score': 0.998, 'precision': 0.9973, 'tpr': 0.9986}, 2), (0.6464, 0.0655, 0.4191, 0.9382, {'recall': 0.9382, 'fpr': 0.2915, 'f1score': 0.6427, 'precision': 0.4887, 'tpr': 0.9382}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 3
    delta = 20
    max_steps = 3000

#     rls = [(1, 0, 1, 0.9868, {'recall': 0.9868, 'fpr': 0.1789, 'f1score': 0.7638, 'precision': 0.623, 'tpr': 0.9868}, 0), (0, 0, 1, 0.9861, {'recall': 0.9861, 'fpr': 0.1817, 'f1score': 0.7602, 'precision': 0.6185, 'tpr': 0.9861}, 0), (0.5437, 0.0142, 0.4705, 0.9858, {'recall': 0.9858, 'fpr': 0.3382, 'f1score': 0.6337, 'precision': 0.4669, 'tpr': 0.9858}, 0), (0.5688, 0.0, 0.4312, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 1), (0.5849, 0.0003, 0.4154, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 2), (0.5849, 0.0003, 0.4154, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 3), (0.5849, 0.0003, 0.4154, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 4), (0.5849, 0.0003, 0.4154, 0.982, {'recall': 0.982, 'fpr': 0.1214, 'f1score': 0.8222, 'precision': 0.7072, 'tpr': 0.982}, 4)]
    rls =     rls = [(1, 0, 1, 0.9821, {'recall': 0.9821, 'fpr': 0.1554, 'f1score': 0.7856, 'precision': 0.6547, 'tpr': 0.9821}, 0), (0, 0, 1, 0.9709, {'recall': 0.9709, 'fpr': 0.1511, 'f1score': 0.7851, 'precision': 0.659, 'tpr': 0.9709}, 0), (0.5388, 0.0234, 0.4846, 0.9766, {'recall': 0.9766, 'fpr': 0.2765, 'f1score': 0.6733, 'precision': 0.5137, 'tpr': 0.9766}, 0), (0.5388, 0.0234, 0.4846, 0.9766, {'recall': 0.9766, 'fpr': 0.2765, 'f1score': 0.6733, 'precision': 0.5137, 'tpr': 0.9766}, 1), (0.5388, 0.0234, 0.4846, 0.9983, {'recall': 0.9983, 'fpr': 0.0012, 'f1score': 0.9971, 'precision': 0.9959, 'tpr': 0.9983}, 2), (0.5388, 0.0234, 0.4846, 0.9742, {'recall': 0.9742, 'fpr': 0.2817, 'f1score': 0.6677, 'precision': 0.5079, 'tpr': 0.9742}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 4
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9756, {'recall': 0.9756, 'fpr': 0.1456, 'f1score': 0.7922, 'precision': 0.6669, 'tpr': 0.9756}, 0), (0, 0, 1, 0.9747, {'recall': 0.9747, 'fpr': 0.1423, 'f1score': 0.7941, 'precision': 0.67, 'tpr': 0.9747}, 0), (0.5796, 0.0308, 0.4512, 0.9692, {'recall': 0.9692, 'fpr': 0.2997, 'f1score': 0.6527, 'precision': 0.4921, 'tpr': 0.9692}, 0), (0.6048, 0.0595, 0.4547, 0.9405, {'recall': 0.9405, 'fpr': 0.0152, 'f1score': 0.9445, 'precision': 0.9485, 'tpr': 0.9405}, 1), (0.6048, 0.0595, 0.4547, 0.9405, {'recall': 0.9405, 'fpr': 0.0152, 'f1score': 0.9445, 'precision': 0.9485, 'tpr': 0.9405}, 2), (0.6048, 0.0595, 0.4547, 0.9885, {'recall': 0.9885, 'fpr': 0.0041, 'f1score': 0.9875, 'precision': 0.9865, 'tpr': 0.9885}, 3), (0.6048, 0.0595, 0.4547, 0.9736, {'recall': 0.9736, 'fpr': 0.3179, 'f1score': 0.6417, 'precision': 0.4786, 'tpr': 0.9736}, 3)]
    gen = 3
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 4
    delta = 20
    max_steps = 3000


    rls = [(1, 0, 1, 0.9528, {'recall': 0.9528, 'fpr': 0.1647, 'f1score': 0.7611, 'precision': 0.6336, 'tpr': 0.9528}, 0), (0, 0, 1, 0.9485, {'recall': 0.9485, 'fpr': 0.1619, 'f1score': 0.762, 'precision': 0.6368, 'tpr': 0.9485}, 0), (0.5233, 0.0525, 0.5292, 0.9475, {'recall': 0.9475, 'fpr': 0.2418, 'f1score': 0.6878, 'precision': 0.5399, 'tpr': 0.9475}, 0), (0.5233, 0.0525, 0.5292, 0.9993, {'recall': 0.9993, 'fpr': 0.0001, 'f1score': 0.9995, 'precision': 0.9997, 'tpr': 0.9993}, 1), (0.5233, 0.0525, 0.5292, 0.9444, {'recall': 0.9444, 'fpr': 0.2349, 'f1score': 0.6921, 'precision': 0.5462, 'tpr': 0.9444}, 1)]
    gen = 1
    TempMax = 1000
    TempMin = 5
    SampleSize = 100
    ReductionRate = 0.6
    eta = 5
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9776, {'recall': 0.9776, 'fpr': 0.1656, 'f1score': 0.7719, 'precision': 0.6378, 'tpr': 0.9776}, 0), (0, 0, 1, 0.9806, {'recall': 0.9806, 'fpr': 0.1643, 'f1score': 0.7747, 'precision': 0.6403, 'tpr': 0.9806}, 0), (0.4633, 0.0231, 0.5598, 0.9769, {'recall': 0.9769, 'fpr': 0.3067, 'f1score': 0.651, 'precision': 0.4881, 'tpr': 0.9769}, 0), (0.4633, 0.0231, 0.5598, 0.9769, {'recall': 0.9769, 'fpr': 0.3067, 'f1score': 0.651, 'precision': 0.4881, 'tpr': 0.9769}, 1), (0.4633, 0.0231, 0.5598, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 2), (0.4633, 0.0231, 0.5598, 0.9753, {'recall': 0.9753, 'fpr': 0.3137, 'f1score': 0.6455, 'precision': 0.4824, 'tpr': 0.9753}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 6
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9776, {'recall': 0.9776, 'fpr': 0.1656, 'f1score': 0.7719, 'precision': 0.6378, 'tpr': 0.9776}, 0), (0, 0, 1, 0.9806, {'recall': 0.9806, 'fpr': 0.1643, 'f1score': 0.7747, 'precision': 0.6403, 'tpr': 0.9806}, 0), (0.4633, 0.0231, 0.5598, 0.9769, {'recall': 0.9769, 'fpr': 0.3067, 'f1score': 0.651, 'precision': 0.4881, 'tpr': 0.9769}, 0), (0.4633, 0.0231, 0.5598, 0.9769, {'recall': 0.9769, 'fpr': 0.3067, 'f1score': 0.651, 'precision': 0.4881, 'tpr': 0.9769}, 1), (0.4633, 0.0231, 0.5598, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 2), (0.4633, 0.0231, 0.5598, 0.9753, {'recall': 0.9753, 'fpr': 0.3137, 'f1score': 0.6455, 'precision': 0.4824, 'tpr': 0.9753}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 7
    delta = 20
    max_steps = 3000


    rls = [(1, 0, 1, 0.983, {'recall': 0.983, 'fpr': 0.1507, 'f1score': 0.7902, 'precision': 0.6606, 'tpr': 0.983}, 0), (0, 0, 1, 0.9764, {'recall': 0.9764, 'fpr': 0.1447, 'f1score': 0.7949, 'precision': 0.6703, 'tpr': 0.9764}, 0), (0.7113, 0.0206, 0.3093, 0.9794, {'recall': 0.9794, 'fpr': 0.2925, 'f1score': 0.6632, 'precision': 0.5014, 'tpr': 0.9794}, 0), (0.7113, 0.0206, 0.3093, 0.9794, {'recall': 0.9794, 'fpr': 0.2925, 'f1score': 0.6632, 'precision': 0.5014, 'tpr': 0.9794}, 1), (0.7113, 0.0206, 0.3093, 0.963, {'recall': 0.963, 'fpr': 0.0155, 'f1score': 0.9559, 'precision': 0.9488, 'tpr': 0.963}, 2), (0.7113, 0.0206, 0.3093, 0.9792, {'recall': 0.9792, 'fpr': 0.2962, 'f1score': 0.6583, 'precision': 0.4958, 'tpr': 0.9792}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 8
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9797, {'recall': 0.9797, 'fpr': 0.126, 'f1score': 0.8164, 'precision': 0.6998, 'tpr': 0.9797}, 0), (0, 0, 1, 0.9723, {'recall': 0.9723, 'fpr': 0.1234, 'f1score': 0.8159, 'precision': 0.7029, 'tpr': 0.9723}, 0), (0.4854, 0.029, 0.5436, 0.971, {'recall': 0.971, 'fpr': 0.342, 'f1score': 0.6223, 'precision': 0.4578, 'tpr': 0.971}, 0), (0.4854, 0.029, 0.5436, 0.971, {'recall': 0.971, 'fpr': 0.342, 'f1score': 0.6223, 'precision': 0.4578, 'tpr': 0.971}, 1), (0.4854, 0.029, 0.5436, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 2), (0.4854, 0.029, 0.5436, 0.9772, {'recall': 0.9772, 'fpr': 0.3438, 'f1score': 0.6249, 'precision': 0.4593, 'tpr': 0.9772}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 9
    delta = 20
    max_steps = 3000

    
    # 4 and 9 for ReductionRate from 0.5 to 0.9 in steps of 0.1. default is 0.6.
    rls = [(1, 0, 1, 0.9692, {'recall': 0.9692, 'fpr': 0.1353, 'f1score': 0.8012, 'precision': 0.6828, 'tpr': 0.9692}, 0), (0, 0, 1, 0.9728, {'recall': 0.9728, 'fpr': 0.1328, 'f1score': 0.8043, 'precision': 0.6856, 'tpr': 0.9728}, 0), (0.634, 0.0308, 0.3968, 0.9692, {'recall': 0.9692, 'fpr': 0.326, 'f1score': 0.6309, 'precision': 0.4677, 'tpr': 0.9692}, 0), (0.6513, 0.0, 0.3487, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 1), (0.6628, 0.0, 0.3372, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 2), (0.6628, 0.0, 0.3372, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 3), (0.6628, 0.0, 0.3372, 1.0, {'recall': 1.0, 'fpr': 0.0002, 'f1score': 0.9997, 'precision': 0.9993, 'tpr': 1.0}, 4), (0.6628, 0.0, 0.3372, 0.9684, {'recall': 0.9684, 'fpr': 0.1501, 'f1score': 0.7835, 'precision': 0.658, 'tpr': 0.9684}, 4)]
    gen = 4
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.5
    eta = 2
    delta = 20
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.9739, {'recall': 0.9739, 'fpr': 0.1268, 'f1score': 0.8123, 'precision': 0.6968, 'tpr': 0.9739}, 0), (0, 0, 1, 0.9809, {'recall': 0.9809, 'fpr': 0.1243, 'f1score': 0.8179, 'precision': 0.7013, 'tpr': 0.9809}, 0), (0.8273, 0.0287, 0.2014, 0.9713, {'recall': 0.9713, 'fpr': 0.2496, 'f1score': 0.6933, 'precision': 0.539, 'tpr': 0.9713}, 0), (0.8826, 0.0937, 0.2111, 0.9063, {'recall': 0.9063, 'fpr': 0.1305, 'f1score': 0.7737, 'precision': 0.6749, 'tpr': 0.9063}, 1), (0.8826, 0.0937, 0.2111, 0.9063, {'recall': 0.9063, 'fpr': 0.1305, 'f1score': 0.7737, 'precision': 0.6749, 'tpr': 0.9063}, 2), (0.8826, 0.0937, 0.2111, 0.9498, {'recall': 0.9498, 'fpr': 0.1269, 'f1score': 0.8003, 'precision': 0.6914, 'tpr': 0.9498}, 3), (0.8826, 0.0937, 0.2111, 0.9758, {'recall': 0.9758, 'fpr': 0.2545, 'f1score': 0.6893, 'precision': 0.5328, 'tpr': 0.9758}, 3)]
    gen = 3
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9741, {'recall': 0.9741, 'fpr': 0.1141, 'f1score': 0.8263, 'precision': 0.7174, 'tpr': 0.9741}, 0), (0, 0, 1, 0.9756, {'recall': 0.9756, 'fpr': 0.1183, 'f1score': 0.8231, 'precision': 0.7118, 'tpr': 0.9756}, 0), (0.7958, 0.0265, 0.2307, 0.9735, {'recall': 0.9735, 'fpr': 0.2915, 'f1score': 0.6595, 'precision': 0.4987, 'tpr': 0.9735}, 0), (0.847, 0.0645, 0.2175, 0.9355, {'recall': 0.9355, 'fpr': 0.1413, 'f1score': 0.7768, 'precision': 0.6641, 'tpr': 0.9355}, 1), (0.847, 0.0645, 0.2175, 0.9355, {'recall': 0.9355, 'fpr': 0.1413, 'f1score': 0.7768, 'precision': 0.6641, 'tpr': 0.9355}, 2), (0.847, 0.0645, 0.2175, 0.9508, {'recall': 0.9508, 'fpr': 0.1099, 'f1score': 0.8203, 'precision': 0.7213, 'tpr': 0.9508}, 3), (0.847, 0.0645, 0.2175, 0.9743, {'recall': 0.9743, 'fpr': 0.2425, 'f1score': 0.7002, 'precision': 0.5464, 'tpr': 0.9743}, 3)]
    gen = 3
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.7
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9776, {'recall': 0.9776, 'fpr': 0.1253, 'f1score': 0.8155, 'precision': 0.6995, 'tpr': 0.9776}, 0), (0, 0, 1, 0.9738, {'recall': 0.9738, 'fpr': 0.1257, 'f1score': 0.813, 'precision': 0.6977, 'tpr': 0.9738}, 0), (0.6195, 0.0305, 0.411, 0.9695, {'recall': 0.9695, 'fpr': 0.329, 'f1score': 0.6316, 'precision': 0.4684, 'tpr': 0.9695}, 0), (0.6195, 0.0305, 0.411, 0.9695, {'recall': 0.9695, 'fpr': 0.329, 'f1score': 0.6316, 'precision': 0.4684, 'tpr': 0.9695}, 1), (0.6195, 0.0305, 0.411, 0.9993, {'recall': 0.9993, 'fpr': 0.0, 'f1score': 0.9997, 'precision': 1.0, 'tpr': 0.9993}, 2), (0.6195, 0.0305, 0.411, 0.9744, {'recall': 0.9744, 'fpr': 0.334, 'f1score': 0.6289, 'precision': 0.4642, 'tpr': 0.9744}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.8
    eta = 2
    delta = 20
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.9722, {'recall': 0.9722, 'fpr': 0.1392, 'f1score': 0.7975, 'precision': 0.6761, 'tpr': 0.9722}, 0), (0, 0, 1, 0.9745, {'recall': 0.9745, 'fpr': 0.1317, 'f1score': 0.8068, 'precision': 0.6883, 'tpr': 0.9745}, 0), (0.6412, 0.0283, 0.3871, 0.9717, {'recall': 0.9717, 'fpr': 0.2827, 'f1score': 0.6651, 'precision': 0.5056, 'tpr': 0.9717}, 0), (0.6412, 0.0283, 0.3871, 0.9717, {'recall': 0.9717, 'fpr': 0.2827, 'f1score': 0.6651, 'precision': 0.5056, 'tpr': 0.9717}, 1), (0.6412, 0.0283, 0.3871, 0.999, {'recall': 0.999, 'fpr': 0.0002, 'f1score': 0.9992, 'precision': 0.9993, 'tpr': 0.999}, 2), (0.6412, 0.0283, 0.3871, 0.9745, {'recall': 0.9745, 'fpr': 0.2895, 'f1score': 0.6618, 'precision': 0.501, 'tpr': 0.9745}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.9
    eta = 2
    delta = 20
    max_steps = 3000

    # 4 and 9 for SampleSize from 10 to 100 in steps of 10. default is 50.

    rls = [(1, 0, 1, 0.9809, {'recall': 0.9809, 'fpr': 0.1351, 'f1score': 0.8057, 'precision': 0.6835, 'tpr': 0.9809}, 0), (0, 0, 1, 0.9792, {'recall': 0.9792, 'fpr': 0.135, 'f1score': 0.8048, 'precision': 0.6831, 'tpr': 0.9792}, 0), (0.5414, 0.0258, 0.4844, 0.9742, {'recall': 0.9742, 'fpr': 0.3194, 'f1score': 0.6401, 'precision': 0.4766, 'tpr': 0.9742}, 0), (0.5414, 0.0258, 0.4844, 0.9742, {'recall': 0.9742, 'fpr': 0.3194, 'f1score': 0.6401, 'precision': 0.4766, 'tpr': 0.9742}, 1), (0.5414, 0.0258, 0.4844, 0.9983, {'recall': 0.9983, 'fpr': 0.0009, 'f1score': 0.9976, 'precision': 0.997, 'tpr': 0.9983}, 2), (0.5414, 0.0258, 0.4844, 0.9783, {'recall': 0.9783, 'fpr': 0.3211, 'f1score': 0.6409, 'precision': 0.4766, 'tpr': 0.9783}, 2)]
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 10
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9757, {'recall': 0.9757, 'fpr': 0.1613, 'f1score': 0.7766, 'precision': 0.6451, 'tpr': 0.9757}, 0), (0, 0, 1, 0.9722, {'recall': 0.9722, 'fpr': 0.1634, 'f1score': 0.7725, 'precision': 0.6408, 'tpr': 0.9722}, 0), (0.8035, 0.0307, 0.2272, 0.9693, {'recall': 0.9693, 'fpr': 0.2879, 'f1score': 0.6597, 'precision': 0.5, 'tpr': 0.9693}, 0), (0.8035, 0.0307, 0.2272, 0.9693, {'recall': 0.9693, 'fpr': 0.2879, 'f1score': 0.6597, 'precision': 0.5, 'tpr': 0.9693}, 1), (0.8035, 0.0307, 0.2272, 0.981, {'recall': 0.981, 'fpr': 0.008, 'f1score': 0.9772, 'precision': 0.9735, 'tpr': 0.981}, 2), (0.8035, 0.0307, 0.2272, 0.9782, {'recall': 0.9782, 'fpr': 0.2906, 'f1score': 0.6624, 'precision': 0.5008, 'tpr': 0.9782}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 20
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

#     rls = [(1, 0, 1, 0.9837, {'recall': 0.9837, 'fpr': 0.1623, 'f1score': 0.7787, 'precision': 0.6444, 'tpr': 0.9837}, 0), (0, 0, 1, 0.984, {'recall': 0.984, 'fpr': 0.1604, 'f1score': 0.7803, 'precision': 0.6464, 'tpr': 0.984}, 0), (0.5073, 0.0204, 0.5131, 0.9796, {'recall': 0.9796, 'fpr': 0.1964, 'f1score': 0.7432, 'precision': 0.5987, 'tpr': 0.9796}, 0), (0.5258, 0.0, 0.4742, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 1), (0.5258, 0.0, 0.4742, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 2), (0.5258, 0.0, 0.4742, 1.0, {'recall': 1.0, 'fpr': 0.0002, 'f1score': 0.9997, 'precision': 0.9993, 'tpr': 1.0}, 3), (0.5258, 0.0, 0.4742, 0.9844, {'recall': 0.9844, 'fpr': 0.021, 'f1score': 0.9582, 'precision': 0.9333, 'tpr': 0.9844}, 3)]
    rls = [(1, 0, 1, 0.9813, {'recall': 0.9813, 'fpr': 0.17, 'f1score': 0.7698, 'precision': 0.6332, 'tpr': 0.9813}, 0), (0, 0, 1, 0.9782, {'recall': 0.9782, 'fpr': 0.1624, 'f1score': 0.7756, 'precision': 0.6425, 'tpr': 0.9782}, 0), (0.787, 0.023, 0.236, 0.977, {'recall': 0.977, 'fpr': 0.284, 'f1score': 0.6685, 'precision': 0.5081, 'tpr': 0.977}, 0), (0.787, 0.023, 0.236, 0.9366, {'recall': 0.9366, 'fpr': 0.0445, 'f1score': 0.8984, 'precision': 0.8631, 'tpr': 0.9366}, 1), (0.787, 0.023, 0.236, 0.9768, {'recall': 0.9768, 'fpr': 0.2867, 'f1score': 0.6641, 'precision': 0.5031, 'tpr': 0.9768}, 1)]
    gen = 1
    TempMax = 1000
    TempMin = 5
    SampleSize = 30
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9741, {'recall': 0.9741, 'fpr': 0.1721, 'f1score': 0.7636, 'precision': 0.6279, 'tpr': 0.9741}, 0), (0, 0, 1, 0.9644, {'recall': 0.9644, 'fpr': 0.1781, 'f1score': 0.7535, 'precision': 0.6183, 'tpr': 0.9644}, 0), (0.7771, 0.0286, 0.2515, 0.9714, {'recall': 0.9714, 'fpr': 0.3143, 'f1score': 0.6418, 'precision': 0.4793, 'tpr': 0.9714}, 0), (0.8136, 0.0688, 0.2552, 0.9312, {'recall': 0.9312, 'fpr': 0.14, 'f1score': 0.7766, 'precision': 0.6659, 'tpr': 0.9312}, 1), (0.8136, 0.0688, 0.2552, 0.9312, {'recall': 0.9312, 'fpr': 0.14, 'f1score': 0.7766, 'precision': 0.6659, 'tpr': 0.9312}, 2), (0.8136, 0.0688, 0.2552, 0.9482, {'recall': 0.9482, 'fpr': 0.1433, 'f1score': 0.7804, 'precision': 0.6631, 'tpr': 0.9482}, 3), (0.8136, 0.0688, 0.2552, 0.9634, {'recall': 0.9634, 'fpr': 0.3145, 'f1score': 0.6393, 'precision': 0.4784, 'tpr': 0.9634}, 3)]
    gen = 3
    TempMax = 1000
    TempMin = 5
    SampleSize = 40
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9803, {'recall': 0.9803, 'fpr': 0.1454, 'f1score': 0.7949, 'precision': 0.6684, 'tpr': 0.9803}, 0), (0, 0, 1, 0.9763, {'recall': 0.9763, 'fpr': 0.1424, 'f1score': 0.7966, 'precision': 0.6727, 'tpr': 0.9763}, 0), (0.5713, 0.0203, 0.449, 0.9797, {'recall': 0.9797, 'fpr': 0.3112, 'f1score': 0.6495, 'precision': 0.4857, 'tpr': 0.9797}, 0), (0.5713, 0.0203, 0.449, 0.9797, {'recall': 0.9797, 'fpr': 0.3112, 'f1score': 0.6495, 'precision': 0.4857, 'tpr': 0.9797}, 1), (0.5713, 0.0203, 0.449, 0.998, {'recall': 0.998, 'fpr': 0.0001, 'f1score': 0.9988, 'precision': 0.9997, 'tpr': 0.998}, 2), (0.5713, 0.0203, 0.449, 0.9792, {'recall': 0.9792, 'fpr': 0.3189, 'f1score': 0.6419, 'precision': 0.4774, 'tpr': 0.9792}, 2)]    
    gen = 2
    TempMax = 1000
    TempMin = 5
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9725, {'recall': 0.9725, 'fpr': 0.1534, 'f1score': 0.7823, 'precision': 0.6543, 'tpr': 0.9725}, 0), (0, 0, 1, 0.9752, {'recall': 0.9752, 'fpr': 0.1514, 'f1score': 0.7858, 'precision': 0.658, 'tpr': 0.9752}, 0), (0.6128, 0.0321, 0.4193, 0.9679, {'recall': 0.9679, 'fpr': 0.3115, 'f1score': 0.644, 'precision': 0.4825, 'tpr': 0.9679}, 0), (0.6128, 0.0321, 0.4193, 0.9966, {'recall': 0.9966, 'fpr': 0.0015, 'f1score': 0.9958, 'precision': 0.9949, 'tpr': 0.9966}, 1), (0.6128, 0.0321, 0.4193, 0.9698, {'recall': 0.9698, 'fpr': 0.3141, 'f1score': 0.6419, 'precision': 0.4798, 'tpr': 0.9698}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 60
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.9622, {'recall': 0.9622, 'fpr': 0.1546, 'f1score': 0.7758, 'precision': 0.6499, 'tpr': 0.9622}, 0), (0, 0, 1, 0.9597, {'recall': 0.9597, 'fpr': 0.1516, 'f1score': 0.7784, 'precision': 0.6548, 'tpr': 0.9597}, 0), (0.6574, 0.0469, 0.3895, 0.9531, {'recall': 0.9531, 'fpr': 0.3453, 'f1score': 0.6128, 'precision': 0.4516, 'tpr': 0.9531}, 0), (0.6692, 0.0051, 0.3359, 0.9949, {'recall': 0.9949, 'fpr': 0.001, 'f1score': 0.9957, 'precision': 0.9966, 'tpr': 0.9949}, 1), (0.6767, 0.001, 0.3243, 0.999, {'recall': 0.999, 'fpr': 0.0002, 'f1score': 0.9992, 'precision': 0.9993, 'tpr': 0.999}, 2), (0.6819, 0.0061, 0.3242, 0.9939, {'recall': 0.9939, 'fpr': 0.0026, 'f1score': 0.9926, 'precision': 0.9912, 'tpr': 0.9939}, 3), (0.6833, 0.0082, 0.3249, 0.9918, {'recall': 0.9918, 'fpr': 0.0075, 'f1score': 0.9834, 'precision': 0.9752, 'tpr': 0.9918}, 4), (0.6908, 0.0058, 0.315, 0.9942, {'recall': 0.9942, 'fpr': 0.0013, 'f1score': 0.9949, 'precision': 0.9955, 'tpr': 0.9942}, 5), (0.6908, 0.0058, 0.315, 0.9942, {'recall': 0.9942, 'fpr': 0.0013, 'f1score': 0.9949, 'precision': 0.9955, 'tpr': 0.9942}, 6), (0.6908, 0.0058, 0.315, 0.9986, {'recall': 0.9986, 'fpr': 0.0008, 'f1score': 0.998, 'precision': 0.9973, 'tpr': 0.9986}, 7), (0.6908, 0.0058, 0.315, 0.9588, {'recall': 0.9588, 'fpr': 0.2379, 'f1score': 0.6976, 'precision': 0.5483, 'tpr': 0.9588}, 7)]
    gen = 7
    TempMin = 5
    TempMax = 1000
    SampleSize = 70
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9844, {'recall': 0.9844, 'fpr': 0.1266, 'f1score': 0.8175, 'precision': 0.6991, 'tpr': 0.9844}, 0), (0, 0, 1, 0.9857, {'recall': 0.9857, 'fpr': 0.1363, 'f1score': 0.807, 'precision': 0.6832, 'tpr': 0.9857}, 0), (0.4849, 0.015, 0.5301, 0.985, {'recall': 0.985, 'fpr': 0.3088, 'f1score': 0.6523, 'precision': 0.4876, 'tpr': 0.985}, 0), (0.4849, 0.015, 0.5301, 0.985, {'recall': 0.985, 'fpr': 0.3088, 'f1score': 0.6523, 'precision': 0.4876, 'tpr': 0.985}, 1), (0.4849, 0.015, 0.5301, 0.9997, {'recall': 0.9997, 'fpr': 0.0, 'f1score': 0.9998, 'precision': 1.0, 'tpr': 0.9997}, 2), (0.4849, 0.015, 0.5301, 0.9817, {'recall': 0.9817, 'fpr': 0.3191, 'f1score': 0.6448, 'precision': 0.4801, 'tpr': 0.9817}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 80
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

    rls = [(1, 0, 1, 0.9674, {'recall': 0.9674, 'fpr': 0.1489, 'f1score': 0.7845, 'precision': 0.6598, 'tpr': 0.9674}, 0), (0, 0, 1, 0.9706, {'recall': 0.9706, 'fpr': 0.1464, 'f1score': 0.7901, 'precision': 0.6662, 'tpr': 0.9706}, 0), (0.5662, 0.037, 0.4708, 0.963, {'recall': 0.963, 'fpr': 0.246, 'f1score': 0.6911, 'precision': 0.539, 'tpr': 0.963}, 0), (0.5662, 0.037, 0.4708, 0.963, {'recall': 0.963, 'fpr': 0.246, 'f1score': 0.6911, 'precision': 0.539, 'tpr': 0.963}, 1), (0.5662, 0.037, 0.4708, 0.9807, {'recall': 0.9807, 'fpr': 0.0054, 'f1score': 0.9813, 'precision': 0.982, 'tpr': 0.9807}, 2), (0.5662, 0.037, 0.4708, 0.9687, {'recall': 0.9687, 'fpr': 0.2527, 'f1score': 0.6878, 'precision': 0.5332, 'tpr': 0.9687}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 90
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000

#     rls = [(1, 0, 1, 0.9868, {'recall': 0.9868, 'fpr': 0.1789, 'f1score': 0.7638, 'precision': 0.623, 'tpr': 0.9868}, 0), (0, 0, 1, 0.9861, {'recall': 0.9861, 'fpr': 0.1817, 'f1score': 0.7602, 'precision': 0.6185, 'tpr': 0.9861}, 0), (0.5437, 0.0142, 0.4705, 0.9858, {'recall': 0.9858, 'fpr': 0.3382, 'f1score': 0.6337, 'precision': 0.4669, 'tpr': 0.9858}, 0), (0.5688, 0.0, 0.4312, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 1), (0.5849, 0.0003, 0.4154, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 2), (0.5849, 0.0003, 0.4154, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 3), (0.5849, 0.0003, 0.4154, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 4), (0.5849, 0.0003, 0.4154, 0.982, {'recall': 0.982, 'fpr': 0.1214, 'f1score': 0.8222, 'precision': 0.7072, 'tpr': 0.982}, 4)]
    rls = [(1, 0, 1, 0.9821, {'recall': 0.9821, 'fpr': 0.1554, 'f1score': 0.7856, 'precision': 0.6547, 'tpr': 0.9821}, 0), (0, 0, 1, 0.9709, {'recall': 0.9709, 'fpr': 0.1511, 'f1score': 0.7851, 'precision': 0.659, 'tpr': 0.9709}, 0), (0.5388, 0.0234, 0.4846, 0.9766, {'recall': 0.9766, 'fpr': 0.2765, 'f1score': 0.6733, 'precision': 0.5137, 'tpr': 0.9766}, 0), (0.5388, 0.0234, 0.4846, 0.9766, {'recall': 0.9766, 'fpr': 0.2765, 'f1score': 0.6733, 'precision': 0.5137, 'tpr': 0.9766}, 1), (0.5388, 0.0234, 0.4846, 0.9983, {'recall': 0.9983, 'fpr': 0.0012, 'f1score': 0.9971, 'precision': 0.9959, 'tpr': 0.9983}, 2), (0.5388, 0.0234, 0.4846, 0.9742, {'recall': 0.9742, 'fpr': 0.2817, 'f1score': 0.6677, 'precision': 0.5079, 'tpr': 0.9742}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 100
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000


    
    
    # 4 and 9 for lambda from 1 to 20 in steps of 2. default is 1.

    rls = [(1, 0, 1, 0.982, {'recall': 0.982, 'fpr': 0.1299, 'f1score': 0.8126, 'precision': 0.693, 'tpr': 0.982}, 0), (0, 0, 1, 0.978, {'recall': 0.978, 'fpr': 0.1359, 'f1score': 0.8048, 'precision': 0.6837, 'tpr': 0.978}, 0), (0.5369, 0.0206, 0.4837, 0.9794, {'recall': 0.9794, 'fpr': 0.2086, 'f1score': 0.7324, 'precision': 0.5849, 'tpr': 0.9794}, 0), (0.5391, 0.0, 0.4609, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 1), (0.5391, 0.0, 0.4609, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 2), (0.5391, 0.0, 0.4609, 1.0, {'recall': 1.0, 'fpr': 0.0, 'f1score': 1.0, 'precision': 1.0, 'tpr': 1.0}, 3), (0.5391, 0.0, 0.4609, 0.9776, {'recall': 0.9776, 'fpr': 0.1742, 'f1score': 0.764, 'precision': 0.627, 'tpr': 0.9776}, 3)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 1
    
    rls = [(1, 0, 1, 0.9776, {'recall': 0.9776, 'fpr': 0.136, 'f1score': 0.8034, 'precision': 0.6819, 'tpr': 0.9776}, 0), (0, 0, 1, 0.9766, {'recall': 0.9766, 'fpr': 0.1405, 'f1score': 0.7984, 'precision': 0.6753, 'tpr': 0.9766}, 0), (0.551, 0.0927, 0.5417, 0.9691, {'recall': 0.9691, 'fpr': 0.3273, 'f1score': 0.6324, 'precision': 0.4693, 'tpr': 0.9691}, 0), (0.551, 0.0927, 0.5417, 0.9691, {'recall': 0.9691, 'fpr': 0.3273, 'f1score': 0.6324, 'precision': 0.4693, 'tpr': 0.9691}, 1), (0.551, 0.0927, 0.5417, 0.9997, {'recall': 0.9997, 'fpr': 0.0001, 'f1score': 0.9997, 'precision': 0.9997, 'tpr': 0.9997}, 2), (0.551, 0.0927, 0.5417, 0.9666, {'recall': 0.9666, 'fpr': 0.331, 'f1score': 0.6309, 'precision': 0.4682, 'tpr': 0.9666}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 3
     
    rls = [(1, 0, 1, 0.9909, {'recall': 0.9909, 'fpr': 0.2083, 'f1score': 0.7389, 'precision': 0.589, 'tpr': 0.9909}, 0), (0, 0, 1, 0.9862, {'recall': 0.9862, 'fpr': 0.2074, 'f1score': 0.7372, 'precision': 0.5886, 'tpr': 0.9862}, 0), (0.755, 0.0593, 0.3043, 0.9881, {'recall': 0.9881, 'fpr': 0.318, 'f1score': 0.6483, 'precision': 0.4824, 'tpr': 0.9881}, 0), (0.755, 0.0593, 0.3043, 0.9627, {'recall': 0.9627, 'fpr': 0.0193, 'f1score': 0.9498, 'precision': 0.9373, 'tpr': 0.9627}, 1), (0.755, 0.0593, 0.3043, 0.9871, {'recall': 0.9871, 'fpr': 0.3242, 'f1score': 0.6429, 'precision': 0.4767, 'tpr': 0.9871}, 1)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 5
    

    rls = [(1, 0, 1, 0.9797, {'recall': 0.9797, 'fpr': 0.1226, 'f1score': 0.8206, 'precision': 0.7059, 'tpr': 0.9797}, 0), (0, 0, 1, 0.9738, {'recall': 0.9738, 'fpr': 0.1237, 'f1score': 0.8156, 'precision': 0.7016, 'tpr': 0.9738}, 0), (0.7201, 0.1768, 0.4567, 0.9747, {'recall': 0.9747, 'fpr': 0.3347, 'f1score': 0.6285, 'precision': 0.4637, 'tpr': 0.9747}, 0), (0.7201, 0.1768, 0.4567, 0.9747, {'recall': 0.9747, 'fpr': 0.3347, 'f1score': 0.6285, 'precision': 0.4637, 'tpr': 0.9747}, 1), (0.7201, 0.1768, 0.4567, 0.9993, {'recall': 0.9993, 'fpr': 0.0, 'f1score': 0.9997, 'precision': 1.0, 'tpr': 0.9993}, 2), (0.7201, 0.1768, 0.4567, 0.9769, {'recall': 0.9769, 'fpr': 0.3304, 'f1score': 0.6344, 'precision': 0.4697, 'tpr': 0.9769}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 7

    rls = [(1, 0, 1, 0.9782, {'recall': 0.9782, 'fpr': 0.1335, 'f1score': 0.8061, 'precision': 0.6855, 'tpr': 0.9782}, 0), (0, 0, 1, 0.9711, {'recall': 0.9711, 'fpr': 0.1383, 'f1score': 0.7979, 'precision': 0.6772, 'tpr': 0.9711}, 0), (0.8196, 0.2824, 0.4628, 0.9686, {'recall': 0.9686, 'fpr': 0.3215, 'f1score': 0.635, 'precision': 0.4723, 'tpr': 0.9686}, 0), (0.8196, 0.2824, 0.4628, 0.9686, {'recall': 0.9686, 'fpr': 0.3215, 'f1score': 0.635, 'precision': 0.4723, 'tpr': 0.9686}, 1), (0.8196, 0.2824, 0.4628, 0.999, {'recall': 0.999, 'fpr': 0.0006, 'f1score': 0.9985, 'precision': 0.998, 'tpr': 0.999}, 2), (0.8196, 0.2824, 0.4628, 0.9696, {'recall': 0.9696, 'fpr': 0.3249, 'f1score': 0.6356, 'precision': 0.4728, 'tpr': 0.9696}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 9

    rls = [(1, 0, 1, 0.973, {'recall': 0.973, 'fpr': 0.1428, 'f1score': 0.7949, 'precision': 0.672, 'tpr': 0.973}, 0), (0, 0, 1, 0.968, {'recall': 0.968, 'fpr': 0.1516, 'f1score': 0.7839, 'precision': 0.6586, 'tpr': 0.968}, 0), (1.0108, 0.3649, 0.3541, 0.9668, {'recall': 0.9668, 'fpr': 0.3213, 'f1score': 0.6336, 'precision': 0.4712, 'tpr': 0.9668}, 0), (1.0108, 0.3649, 0.3541, 0.9668, {'recall': 0.9668, 'fpr': 0.3213, 'f1score': 0.6336, 'precision': 0.4712, 'tpr': 0.9668}, 1), (1.0108, 0.3649, 0.3541, 0.9993, {'recall': 0.9993, 'fpr': 0.0004, 'f1score': 0.999, 'precision': 0.9986, 'tpr': 0.9993}, 2), (1.0108, 0.3649, 0.3541, 0.9712, {'recall': 0.9712, 'fpr': 0.3171, 'f1score': 0.6414, 'precision': 0.4788, 'tpr': 0.9712}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 11

    rls = [(1, 0, 1, 0.9759, {'recall': 0.9759, 'fpr': 0.1639, 'f1score': 0.7729, 'precision': 0.6398, 'tpr': 0.9759}, 0), (0, 0, 1, 0.9774, {'recall': 0.9774, 'fpr': 0.1599, 'f1score': 0.7793, 'precision': 0.6479, 'tpr': 0.9774}, 0), (0.9637, 0.3531, 0.3894, 0.9748, {'recall': 0.9748, 'fpr': 0.3233, 'f1score': 0.6367, 'precision': 0.4727, 'tpr': 0.9748}, 0), (0.9637, 0.3531, 0.3894, 0.9748, {'recall': 0.9748, 'fpr': 0.3233, 'f1score': 0.6367, 'precision': 0.4727, 'tpr': 0.9748}, 1), (0.9637, 0.3531, 0.3894, 0.9963, {'recall': 0.9963, 'fpr': 0.0014, 'f1score': 0.9958, 'precision': 0.9953, 'tpr': 0.9963}, 2), (0.9637, 0.3531, 0.3894, 0.9733, {'recall': 0.9733, 'fpr': 0.3235, 'f1score': 0.638, 'precision': 0.4745, 'tpr': 0.9733}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 14

    rls = [(1, 0, 1, 0.9706, {'recall': 0.9706, 'fpr': 0.157, 'f1score': 0.7764, 'precision': 0.6469, 'tpr': 0.9706}, 0), (0, 0, 1, 0.9699, {'recall': 0.9699, 'fpr': 0.1539, 'f1score': 0.7813, 'precision': 0.6541, 'tpr': 0.9699}, 0), (1.1108, 0.6024, 0.4916, 0.9646, {'recall': 0.9646, 'fpr': 0.3451, 'f1score': 0.6174, 'precision': 0.454, 'tpr': 0.9646}, 0), (1.1108, 0.6024, 0.4916, 0.9646, {'recall': 0.9646, 'fpr': 0.3451, 'f1score': 0.6174, 'precision': 0.454, 'tpr': 0.9646}, 1), (1.1108, 0.6024, 0.4916, 0.9993, {'recall': 0.9993, 'fpr': 0.0002, 'f1score': 0.9993, 'precision': 0.9993, 'tpr': 0.9993}, 2), (1.1108, 0.6024, 0.4916, 0.9702, {'recall': 0.9702, 'fpr': 0.3466, 'f1score': 0.6207, 'precision': 0.4563, 'tpr': 0.9702}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 17

    rls = [(1, 0, 1, 0.9667, {'recall': 0.9667, 'fpr': 0.1271, 'f1score': 0.8085, 'precision': 0.6947, 'tpr': 0.9667}, 0), (0, 0, 1, 0.9717, {'recall': 0.9717, 'fpr': 0.1275, 'f1score': 0.8098, 'precision': 0.6941, 'tpr': 0.9717}, 0), (1.0809, 0.7267, 0.6458, 0.9637, {'recall': 0.9637, 'fpr': 0.3497, 'f1score': 0.615, 'precision': 0.4516, 'tpr': 0.9637}, 0), (1.0809, 0.7267, 0.6458, 0.9637, {'recall': 0.9637, 'fpr': 0.3497, 'f1score': 0.615, 'precision': 0.4516, 'tpr': 0.9637}, 1), (1.0809, 0.7267, 0.6458, 0.9997, {'recall': 0.9997, 'fpr': 0.0002, 'f1score': 0.9995, 'precision': 0.9993, 'tpr': 0.9997}, 2), (1.0809, 0.7267, 0.6458, 0.9718, {'recall': 0.9718, 'fpr': 0.348, 'f1score': 0.6196, 'precision': 0.4548, 'tpr': 0.9718}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    mylambda = 20

    
    # 4 and 9 for lambda from 0.1 to 1 in steps of *10. default is 1.
    
    rls = [(1, 0, 1, 0.9589, {'recall': 0.9589, 'fpr': 0.118, 'f1score': 0.8146, 'precision': 0.7081, 'tpr': 0.9589}, 0), (0, 0, 1, 0.9556, {'recall': 0.9556, 'fpr': 0.1238, 'f1score': 0.8055, 'precision': 0.6962, 'tpr': 0.9556}, 0), (0.4533, 0.0044, 0.5511, 0.9565, {'recall': 0.9565, 'fpr': 0.3386, 'f1score': 0.6211, 'precision': 0.4599, 'tpr': 0.9565}, 0), (0.4581, 0.0002, 0.5421, 0.9976, {'recall': 0.9976, 'fpr': 0.0002, 'f1score': 0.9985, 'precision': 0.9993, 'tpr': 0.9976}, 1), (0.4596, 0.0001, 0.5405, 0.9986, {'recall': 0.9986, 'fpr': 0.0002, 'f1score': 0.999, 'precision': 0.9993, 'tpr': 0.9986}, 2), (0.4596, 0.0001, 0.5405, 0.9986, {'recall': 0.9986, 'fpr': 0.0002, 'f1score': 0.999, 'precision': 0.9993, 'tpr': 0.9986}, 3), (0.4596, 0.0001, 0.5405, 0.9997, {'recall': 0.9997, 'fpr': 0.0, 'f1score': 0.9998, 'precision': 1.0, 'tpr': 0.9997}, 4), (0.4596, 0.0001, 0.5405, 0.9595, {'recall': 0.9595, 'fpr': 0.349, 'f1score': 0.6128, 'precision': 0.4502, 'tpr': 0.9595}, 4)]
    gen = 4
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.9697, {'recall': 0.9697, 'fpr': 0.1056, 'f1score': 0.8346, 'precision': 0.7325, 'tpr': 0.9697}, 0), (0, 0, 1, 0.9646, {'recall': 0.9646, 'fpr': 0.1166, 'f1score': 0.8188, 'precision': 0.7113, 'tpr': 0.9646}, 0), (0.6265, 0.0374, 0.4109, 0.9626, {'recall': 0.9626, 'fpr': 0.282, 'f1score': 0.6621, 'precision': 0.5046, 'tpr': 0.9626}, 0), (0.6265, 0.0374, 0.4109, 0.9626, {'recall': 0.9626, 'fpr': 0.282, 'f1score': 0.6621, 'precision': 0.5046, 'tpr': 0.9626}, 1), (0.6265, 0.0374, 0.4109, 1.0, {'recall': 1.0, 'fpr': 0.0001, 'f1score': 0.9998, 'precision': 0.9997, 'tpr': 1.0}, 2), (0.6265, 0.0374, 0.4109, 0.9694, {'recall': 0.9694, 'fpr': 0.2691, 'f1score': 0.6749, 'precision': 0.5176, 'tpr': 0.9694}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    
    rls = [(1, 0, 1, 0.9861, {'recall': 0.9861, 'fpr': 0.1685, 'f1score': 0.7734, 'precision': 0.6361, 'tpr': 0.9861}, 0), (0, 0, 1, 0.9851, {'recall': 0.9851, 'fpr': 0.1736, 'f1score': 0.7686, 'precision': 0.6301, 'tpr': 0.9851}, 0), (0.6746, 0.2297, 0.5551, 0.977, {'recall': 0.977, 'fpr': 0.1563, 'f1score': 0.7827, 'precision': 0.6529, 'tpr': 0.977}, 0), (0.6746, 0.2297, 0.5551, 0.977, {'recall': 0.977, 'fpr': 0.1563, 'f1score': 0.7827, 'precision': 0.6529, 'tpr': 0.977}, 1), (0.6746, 0.2297, 0.5551, 0.9993, {'recall': 0.9993, 'fpr': 0.0002, 'f1score': 0.9993, 'precision': 0.9993, 'tpr': 0.9993}, 2), (0.6746, 0.2297, 0.5551, 0.9817, {'recall': 0.9817, 'fpr': 0.1775, 'f1score': 0.7625, 'precision': 0.6234, 'tpr': 0.9817}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.6
    eta = 2
    delta = 20
    max_steps = 3000
    
    # 6 and 8 for delta from 10 to 100 in steps of 10. default is 20.
    # 6 and 8 for eta from 2 to 10 in steps of 1. default is 2.
    # 6 and 8 for ReductionRate from 0.5 to 0.9 in steps of 0.1. default is 0.6.
    # 6 and 8 for SampleSize from 10 to 100 in steps of 10. default is 50.
#     rls = 
#     gen = 1
#     TempMin = 5
#     TempMax = 1000
#     SampleSize = 60
#     ReductionRate = 0.6
#     eta = 2
#     delta = 20
#     max_steps = 3000
     
#     # 6 and 8
#     rls = 
#     gen = 
#     numgens = 
#     numalphas = 
#     myepsilon = 
#     mylambda = 
#     final_payoff = 


#     Multilabel classification : Positive class : 9, Negative class : 1,7
    rls = [(1, 0, 1, 0.7126, {'precision': 0.7126}, 0), (0, 0, 1, 0.7073, {'precision': 0.7073}, 0), (0.8414, 0.8547, 0.0133, 0.8547, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8547, 'tpr': 0.0}, 0), (0.8414, 0.8547, 0.0133, 0.7076, {'precision': 0.7076}, 1), (0.8414, 0.8547, 0.0133, 0.71, {'precision': 0.71}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 50
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1

    rls = [(1, 0, 1, 0.6877, {'precision': 0.6877}, 0), (0, 0, 1, 0.6858, {'precision': 0.6858}, 0), (0.8271, 0.8438, 0.0167, 0.8438, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8438, 'tpr': 0.0}, 0), (0.8271, 0.8438, 0.0167, 0.6917, {'precision': 0.6917}, 1), (0.8271, 0.8438, 0.0167, 0.6819, {'precision': 0.6819}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 25
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1
    
    rls = [(1, 0, 1, 0.6918, {'precision': 0.6918}, 0), (0, 0, 1, 0.6875, {'precision': 0.6875}, 0), (0.7738, 0.8258, 0.052, 0.8258, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8258, 'tpr': 0.0}, 0), (0.7738, 0.8258, 0.052, 0.5032, {'precision': 0.5032}, 1), (0.7738, 0.8258, 0.052, 0.6753, {'precision': 0.6753}, 1)]
    gen = 3
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1

    rls = [(1, 0, 1, 0.7216, {'precision': 0.7216}, 0), (0, 0, 1, 0.7224, {'precision': 0.7224}, 0), (0.8465, 0.8627, 0.0162, 0.8627, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8627, 'tpr': 0.0}, 0), (0.8465, 0.8627, 0.0162, 0.7111, {'precision': 0.7111}, 1), (0.8465, 0.8627, 0.0162, 0.7185, {'precision': 0.7185}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 17
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1

    rls = [(1, 0, 1, 0.7133, {'precision': 0.7133}, 0), (0, 0, 1, 0.7151, {'precision': 0.7151}, 0), (0.8292, 0.8601, 0.0309, 0.8601, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8601, 'tpr': 0.0}, 0), (0.8292, 0.8601, 0.0309, 0.704, {'precision': 0.704}, 1), (0.8292, 0.8601, 0.0309, 0.7111, {'precision': 0.7111}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 12
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1

#     rls = 
#     gen = 2
#     TempMin = 5
#     TempMax = 1000
#     SampleSize = 50
#     ReductionRate = 0.8
#     eta = 5,15
#     delta = 20
#     max_steps = 6000
#     low = -255
#     high = +255
#     dividend = 10
#     maxwidthlength = 10
#     maxheightlength = 5
#     positiveintensitysize = 500
#     negativeintensitysize = 700
#     mylambda = 1

    rls = [(1, 0, 1, 0.7349, {'precision': 0.7349}, 0), (0, 0, 1, 0.7265, {'precision': 0.7265}, 0), (0.8352, 0.8598, 0.0246, 0.8598, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8598, 'tpr': 0.0}, 0), (0.8352, 0.8598, 0.0246, 0.7168, {'precision': 0.7168}, 1), (0.8352, 0.8598, 0.0246, 0.7264, {'precision': 0.7264}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 5
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1

    rls = [(1, 0, 1, 0.6926, {'precision': 0.6926}, 0), (0, 0, 1, 0.6946, {'precision': 0.6946}, 0), (0.8238, 0.851, 0.0272, 0.851, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.851, 'tpr': 0.0}, 0), (0.8238, 0.851, 0.0272, 0.7124, {'precision': 0.7124}, 1), (0.8238, 0.851, 0.0272, 0.703, {'precision': 0.703}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 10
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1

    rls = [(1, 0, 1, 0.7214, {'precision': 0.7214}, 0), (0, 0, 1, 0.7238, {'precision': 0.7238}, 0), (0.8312, 0.8668, 0.0356, 0.8668, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8668, 'tpr': 0.0}, 0), (0.8312, 0.8668, 0.0356, 0.7145, {'precision': 0.7145}, 1), (0.8312, 0.8668, 0.0356, 0.7268, {'precision': 0.7268}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 15
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 600
    mylambda = 1

    rls = [(1, 0, 1, 0.7202, {'precision': 0.7202}, 0), (0, 0, 1, 0.7224, {'precision': 0.7224}, 0), (0.817, 0.8609, 0.0439, 0.8609, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8609, 'tpr': 0.0}, 0), (0.817, 0.8609, 0.0439, 0.8609, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8609, 'tpr': 0.0}, 1), (0.817, 0.8609, 0.0439, 0.719, {'precision': 0.719}, 2), (0.817, 0.8609, 0.0439, 0.7187, {'precision': 0.7187}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1


    rls = [(1, 0, 1, 0.6844, {'precision': 0.6844}, 0), (0, 0, 1, 0.6839, {'precision': 0.6839}, 0), (0.8033, 0.8355, 0.0322, 0.8355, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8355, 'tpr': 0.0}, 0), (0.8425, 0.8748, 0.0323, 0.8748, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8748, 'tpr': 0.0}, 1), (0.8425, 0.8748, 0.0323, 0.8748, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8748, 'tpr': 0.0}, 2), (0.8425, 0.8748, 0.0323, 0.7173, {'precision': 0.7173}, 3), (0.8425, 0.8748, 0.0323, 0.6814, {'precision': 0.6814}, 3)]
    gen = 3
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 25
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1
    

    rls = [(1, 0, 1, 0.6926, {'precision': 0.6926}, 0), (0, 0, 1, 0.6867, {'precision': 0.6867}, 0), (0.8147, 0.8413, 0.0266, 0.8413, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8413, 'tpr': 0.0}, 0), (0.8147, 0.8413, 0.0266, 0.6962, {'precision': 0.6962}, 1), (0.8147, 0.8413, 0.0266, 0.692, {'precision': 0.692}, 1)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 5
    maxheightlength = 10
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1



    
    rls = [(1, 0, 1, 0.7004, {'precision': 0.7004}, 0), (0, 0, 1, 0.706, {'precision': 0.706}, 0), (0.8233, 0.8527, 0.0294, 0.8527, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8527, 'tpr': 0.0}, 0), (0.8233, 0.8527, 0.0294, 0.7003, {'precision': 0.7003}, 1), (0.8233, 0.8527, 0.0294, 0.6891, {'precision': 0.6891}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 15
    maxheightlength = 15
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1

    rls = [(1, 0, 1, 0.713, {'precision': 0.713}, 0), (0, 0, 1, 0.7112, {'precision': 0.7112}, 0), (0.8327, 0.865, 0.0323, 0.865, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.865, 'tpr': 0.0}, 0), (0.8327, 0.865, 0.0323, 0.6896, {'precision': 0.6896}, 1), (0.8327, 0.865, 0.0323, 0.7159, {'precision': 0.7159}, 1)]
    gen = 1
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 20
    maxheightlength = 10
    positiveintensitysize = 500
    negativeintensitysize = 700
    mylambda = 1

    rls = [(1, 0, 1, 0.7164, {'precision': 0.7164}, 0), (0, 0, 1, 0.7203, {'precision': 0.7203}, 0), (0.8351, 0.8845, 0.0494, 0.8845, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8845, 'tpr': 0.0}, 0), (0.8351, 0.8845, 0.0494, 0.8845, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8845, 'tpr': 0.0}, 1), (0.8351, 0.8845, 0.0494, 0.5018, {'precision': 0.5018}, 2), (0.8351, 0.8845, 0.0494, 0.7361, {'precision': 0.7361}, 2)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 600
    mylambda = 1

    rls = [(1, 0, 1, 0.6941, {'precision': 0.6941}, 0), (0, 0, 1, 0.6821, {'precision': 0.6821}, 0), (0.8102, 0.8513, 0.0411, 0.8513, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8513, 'tpr': 0.0}, 0), (0.8102, 0.8513, 0.0411, 0.7091, {'precision': 0.7091}, 1), (0.8102, 0.8513, 0.0411, 0.6916, {'precision': 0.6916}, 1)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 500
    negativeintensitysize = 600
    mylambda = 1
    
    rls = [(1, 0, 1, 0.6984, {'precision': 0.6984}, 0), (0, 0, 1, 0.6959, {'precision': 0.6959}, 0), (0.8372, 0.8542, 0.017, 0.8542, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8542, 'tpr': 0.0}, 0), (0.8372, 0.8542, 0.017, 0.8542, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8542, 'tpr': 0.0}, 1), (0.8372, 0.8542, 0.017, 0.6189, {'precision': 0.6189}, 2), (0.8372, 0.8542, 0.017, 0.6979, {'precision': 0.6979}, 2)]
    gen = 3
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 600
    negativeintensitysize = 700
    mylambda = 1

    rls = [(1, 0, 1, 0.723, {'precision': 0.723}, 0), (0, 0, 1, 0.7209, {'precision': 0.7209}, 0), (0.845, 0.8655, 0.0205, 0.8655, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8655, 'tpr': 0.0}, 0), (0.845, 0.8655, 0.0205, 0.6991, {'precision': 0.6991}, 1), (0.845, 0.8655, 0.0205, 0.7168, {'precision': 0.7168}, 1)]
    gen = 3
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 10
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 700
    negativeintensitysize = 800
    mylambda = 1
    
    rls = [(1, 0, 1, 0.7161, {'precision': 0.7161}, 0), (0, 0, 1, 0.7166, {'precision': 0.7166}, 0), (0.8202, 0.8519, 0.0317, 0.8519, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8519, 'tpr': 0.0}, 0), (0.8395, 0.8725, 0.033, 0.8725, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8725, 'tpr': 0.0}, 1), (0.8395, 0.8725, 0.033, 0.8725, {'recall': 0.0, 'fpr': 0.0, 'f1score': 0.0, 'precision': 0.8725, 'tpr': 0.0}, 2), (0.8395, 0.8725, 0.033, 0.7195, {'precision': 0.7195}, 3), (0.8395, 0.8725, 0.033, 0.7072, {'precision': 0.7072}, 3)]
    gen = 2
    TempMin = 5
    TempMax = 1000
    SampleSize = 50
    ReductionRate = 0.8
    eta = 5,15
    delta = 20
    max_steps = 6000
    low = -255
    high = +255
    dividend = 20
    maxwidthlength = 10
    maxheightlength = 5
    positiveintensitysize = 800
    negativeintensitysize = 900
    mylambda = 1


#     rls = 
#     gen = 3
#     TempMin = 5
#     TempMax = 1000
#     SampleSize = 50
#     ReductionRate = 0.8
#     eta = 5,15
#     delta = 20
#     max_steps = 6000
#     low = -255
#     high = +255
#     dividend = 20
#     maxwidthlength = 10
#     maxheightlength = 5
#     positiveintensitysize = 500
#     negativeintensitysize = 700
#     mylambda = 1








    
    
    
    
    
    results = {}

    rls[0][4]['payoff'] = rls[0][0]
    rls[0][4]['error'] = rls[0][1]
    rls[0][4]['norm'] = rls[0][2]
    results['training error on original training data and original testing data'] = rls[0][4]

    rls[1][4]['payoff'] = rls[1][0]
    rls[1][4]['error'] = rls[1][1]
    rls[1][4]['norm'] = rls[1][2]    
    results['testing error on original training data and original testing data'] = rls[1][4]

    rls[-2][4]['payoff'] = rls[-2][0]
    rls[-2][4]['error'] = rls[-2][1]
    rls[-2][4]['norm'] = rls[-2][2]    
    results['testing error on manipulated training data and manipulated testing data'] = rls[-2][4]

    rls[-1][4]['payoff'] = rls[-1][0]
    rls[-1][4]['error'] = rls[-1][1]
    rls[-1][4]['norm'] = rls[-1][2]    
    results['testing error on original training data and manipulated testing data'] = rls[-1][4]

    print(results)
#     print('numgens',numgens)
#     print('numalphas',numalphas)
#     print('myepsilon',myepsilon)
#     print('mylambda',mylambda)
#     print('final_payoff',final_payoff)

    
#     print('rls[2:-2]',rls[2:-2])
    
    trainingresults = []
    precisions = []
    recalls = []
    f1scores = []
    tprs = []
    fprs = []
    errors = []
    payoffs = []
    norms = []

    tup = rls[0]
    tup[4]['payoff'] = tup[0]
    tup[4]['error'] = tup[1]
    tup[4]['norm'] = tup[2]

    trainingresults.append(tup[4])
    precisions.append(tup[4]['precision'])
    recalls.append(tup[4]['recall'])
    f1scores.append(tup[4]['f1score'])
    tprs.append(tup[4]['tpr'])
    fprs.append(tup[4]['fpr'])
    errors.append(tup[4]['error'])
    payoffs.append(tup[4]['payoff'])
    norms.append(tup[4]['norm'])

    for tup in rls[2:-2]:
        tup[4]['payoff'] = tup[0]
        tup[4]['error'] = tup[1]
        tup[4]['norm'] = tup[2]
        trainingresults.append(tup[4])
        precisions.append(tup[4]['precision'])
        recalls.append(tup[4]['recall'])
        f1scores.append(tup[4]['f1score'])
        tprs.append(tup[4]['tpr'])
        fprs.append(tup[4]['fpr'])
        errors.append(tup[4]['error'])
        payoffs.append(tup[4]['payoff'])
        norms.append(tup[4]['norm'])
    
    print('trainingresults',trainingresults)
    print('precisions',precisions)
    print('recalls',recalls)
    print('f1scores',f1scores)
    print('tprs',tprs)
    print('fprs',fprs)
    print('errors',errors)
    print('payoffs',payoffs)
    print('norms',norms)

    
    
    
    
    
    
#     l = [(1, 0, 1, 0.6558079725675097, {'recall': 0.9788867562380038, 'fpr': 0.1597440844927389, 'f1score': 0.6558079725675097, 'precision': 0.49307122139864645, 'tpr': 0.9788867562380038}, 0), (0, 0, 1, 0.6569626394953906, {'recall': 0.9849660523763336, 'fpr': 0.22784258148915296, 'f1score': 0.6569626394953906, 'precision': 0.49284154331472946, 'tpr': 0.9849660523763336}, 0), (1.3651282317376676, 0.6470588235294118, 0.28193059179174407, 0.6470588235294118, {'recall': 1.0, 'fpr': 0.14109347442680775, 'f1score': 0.6470588235294118, 'precision': 0.4782608695652174, 'tpr': 1.0}, 0), (1.3770177921928193, 0.6589483839845635, 0.28193059179174407, 0.6589483839845635, {'recall': 1.0, 'fpr': 0.13903638151425762, 'f1score': 0.6589483839845635, 'precision': 0.4913669064748201, 'tpr': 1.0}, 1), (1.3670707027532045, 0.6504312531709792, 0.2833605504177745, 0.6504312531709792, {'recall': 1.0, 'fpr': 0.13517755542475965, 'f1score': 0.6504312531709792, 'precision': 0.48195488721804514, 'tpr': 1.0}, 2), (1.334106515817929, 0.6475531389026199, 0.31344662308469085, 0.6475531389026199, {'recall': 1.0, 'fpr': 0.13974911799294396, 'f1score': 0.6475531389026199, 'precision': 0.4788011695906433, 'tpr': 1.0}, 3), (1.3367129605099304, 0.6523855890944499, 0.3156726285845195, 0.6523855890944499, {'recall': 1.0, 'fpr': 0.14013738959764474, 'f1score': 0.6523855890944499, 'precision': 0.4841040462427746, 'tpr': 1.0}, 4), (1.3295978726282573, 0.6608015640273704, 0.331203691399113, 0.6608015640273704, {'recall': 1.0, 'fpr': 0.136560409287682, 'f1score': 0.6608015640273704, 'precision': 0.49343065693430654, 'tpr': 1.0}, 5), (1.3165120446414962, 0.6477157360406092, 0.331203691399113, 0.6477157360406092, {'recall': 1.0, 'fpr': 0.1360517545579298, 'f1score': 0.6477157360406092, 'precision': 0.47897897897897895, 'tpr': 1.0}, 6), (1.3282022491949466, 0.6594059405940594, 0.331203691399113, 0.6594059405940594, {'recall': 1.0, 'fpr': 0.13532651455546812, 'f1score': 0.6594059405940594, 'precision': 0.4918759231905465, 'tpr': 1.0}, 7), (1.3164966405117453, 0.6477003319108582, 0.331203691399113, 0.6477003319108582, {'recall': 1.0, 'fpr': 0.14560062708210855, 'f1score': 0.6477003319108582, 'precision': 0.4789621318373071, 'tpr': 1.0}, 8), (1.323519509394276, 0.656641604010025, 0.33312209461574915, 0.656641604010025, {'recall': 1.0, 'fpr': 0.13463050314465408, 'f1score': 0.656641604010025, 'precision': 0.48880597014925375, 'tpr': 1.0}, 9), (0, 0.656641604010025, 1.6566416040100251, 0.6645489199491741, {'recall': 0.9840075258701787, 'fpr': 0.22742694538688848, 'f1score': 0.6645489199491741, 'precision': 0.5016786570743406, 'tpr': 0.9840075258701787}, 10), (0, 0.656641604010025, 1.6566416040100251, 0.6633472534532605, {'recall': 0.9833333333333333, 'fpr': 0.22549234135667395, 'f1score': 0.6633472534532605, 'precision': 0.5004847309743092, 'tpr': 0.9833333333333333}, 10)]
#     numgens = 10
#     numalphas = 10
#     myepsilon = 0.0001
#     mylambda = 1

def trainplots():
#     mylambda1 = 1
#     numalphas1 = 10
#     precisions1 = [0.5096426545660806, 0.5014014325755216, 0.20039187744923406, 0.20039187744923406]
#     recalls1 = [0.586105675146771, 0.5230669265756985, 0.367047308319739, 0.367047308319739]
#     f1scores1 = [0.5452063106796117, 0.5120050882493242, 0.25924645696508813, 0.25924645696508813]
#     tprs1 = [0.586105675146771, 0.5230669265756985, 0.367047308319739, 0.367047308319739]
#     fprs1 = [0.1776248202177933, 0.16467804978399506, 0.4611196712891628, 0.4611196712891628]
#     errors1 = [0, 0.47693307342430147, 0.632952691680261, 0.632952691680261]
#     payoffs1 = [0, 1.1780682070157824, 1.2807443361825106, 1.2807443361825106]
#     norms1 = [0, 0.29886486640851917, 0.3522083554977504, 0.3522083554977504]
#         
# 
#     mylambda2 = 10
#     numalphas2 = 50
#     precisions2 = [0.5028702640642939, 0.49523809523809526, 0.11420118343195267, 0.11420118343195267]
#     recalls2 = [0.5706840390879478, 0.5084745762711864, 0.18786502271252434, 0.18786502271252434]
#     f1scores2 = [0.5346353371986573, 0.5017690575747829, 0.14205103042198233, 0.14205103042198233]
#     tprs2 = [0.5706840390879478, 0.5084745762711864, 0.18786502271252434, 0.18786502271252434]
#     fprs2 = [0.17800616649537512, 0.16337854500616522, 0.46213212595184194, 0.46213212595184194]
#     errors2 = [0, 4.915254237288136, 8.121349772874757, 8.121349772874757]
#     payoffs2 = [0, 5.576203915910264, 8.439891588190555, 8.439891588190555]
#     norms2 = [0, 0.33905032137787217, 0.6814581846842014, 0.6814581846842014]
# 
# 
#     mylambda3 = 20
#     numalphas3 = 100
#     precisions3 = [0.5175611126720989, 0.49548387096774194, 0.0805012015104703, 0.2182476794204211, 0.1365079365079365, 0.011857707509881422, 0.011857707509881422]
#     recalls3 = [0.6, 0.5003257328990228, 0.15124153498871332, 0.31596197967879386, 0.25261096605744127, 0.025440313111545987, 0.025440313111545987]
#     f1scores3 = [0.5557399306079348, 0.4978930307941653, 0.1050744931107875, 0.258168184252812, 0.17723837874971377, 0.016175860638739114, 0.016175860638739114]
#     tprs3 = [0.6, 0.5003257328990228, 0.15124153498871332, 0.31596197967879386, 0.25261096605744127, 0.025440313111545987, 0.025440313111545987]
#     fprs3 = [0.176464542651593, 0.16073997944501542, 0.5523249819569028, 0.3541901733511129, 0.5028759244042728, 0.6677624820217793, 0.6677624820217793]
#     errors3 = [0, 9.993485342019543, 16.975169300225733, 13.680760406424124, 14.947780678851174, 19.49119373776908, 19.49119373776908]
#     payoffs3 = [0, 10.632242406180278, 17.317661081614002, 14.284966059257641, 15.261417308524516, 19.931919382044768, 19.931919382044768]
#     norms3 = [0, 0.3612429358392646, 0.6575082186117314, 0.39579434716648265, 0.6863633703266583, 0.5592743557243125, 0.5592743557243125]
# 
# 
#     mylambda4 = 0.5
#     numalphas4 = 20
#     precisions4 = [0.5039846111569113, 0.49710982658959535, 0.4849693251533742, 0.4425007169486665, 0.4425007169486665]
#     recalls4 = [0.6009174311926605, 0.531036724081898, 0.518360655737705, 0.5037544890630101, 0.5037544890630101]
#     f1scores4 = [0.5481990733821551, 0.5135135135135135, 0.5011093502377179, 0.47114503816793896, 0.47114503816793896]
#     tprs4 = [0.6009174311926605, 0.531036724081898, 0.518360655737705, 0.5037544890630101, 0.5037544890630101]
#     fprs4 = [0.18516618793598688, 0.17000925640234496, 0.1722051282051282, 0.19965081647324637, 0.19965081647324637]
#     errors4 = [0, 0.23448163795905103, 0.24081967213114752, 0.24812275546849494, 0.24812275546849494]
#     payoffs4 = [0, 0.9222687909075138, 0.8541820534283024, 0.8320489630237852, 0.8320489630237852]
#     norms4 = [0, 0.3122128470515373, 0.3866376187028451, 0.41607379244470966, 0.41607379244470966]
#         
# 
#     mylambda5 = 0.2
#     numalphas5 = 50
#     precisions5 = [0.5138657792567942, 0.49955022488755624, 0.49955022488755624]
#     recalls5 = [0.6053577262332571, 0.543733681462141, 0.543733681462141]
#     f1scores5 = [0.5558722063896805, 0.5207063603688076, 0.5207063603688076]
#     tprs5 = [0.6053577262332571, 0.543733681462141, 0.543733681462141]
#     fprs5 = [0.17999794640106787, 0.17142563681183237, 0.17142563681183237]
#     errors5 = [0, 0.09125326370757181, 0.09125326370757181]
#     payoffs5 = [0, 0.8284613089456938, 0.8284613089456938]
#     norms5 = [0, 0.262791954761878, 0.262791954761878]
#         
# 
#     mylambda6 = 0.01
#     numalphas6 = 50
#     precisions6 = [0.506166072896684, 0.50210463018641, 0.3905792201938247, 0.4845583693638048, 0.445859872611465, 0.4845583693638048, 0.4845583693638048]
#     recalls6 = [0.6018246985988921, 0.539231514368744, 0.5676383884703571, 0.5190208402249421, 0.5, 0.5190208402249421, 0.5190208402249421]
#     f1scores6 = [0.549866031557011, 0.5200062276194924, 0.46275033377837116, 0.5011978917105894, 0.4713804713804714, 0.5011978917105894, 0.5011978917105894]
#     tprs6 = [0.6018246985988921, 0.539231514368744, 0.5676383884703571, 0.5190208402249421, 0.5, 0.5190208402249421, 0.5190208402249421]
#     fprs6 = [0.18518137909772892, 0.17066886529939193, 0.2774186929311583, 0.17070676076506086, 0.19691358024691358, 0.17070676076506086, 0.17070676076506086]
#     errors6 = [0, 0.004607684856312561, 0.004323616115296429, 0.004809791597750579, 0.005, 0.004809791597750579, 0.004809791597750579]
#     payoffs6 = [0, 0.7672730381542716, 0.7543424797643027, 0.731421660653315, 0.744277083189356, 0.731421660653315, 0.731421660653315]
#     norms6 = [0, 0.23733464670204096, 0.24998113635099373, 0.2733881309444355, 0.26072291681064386, 0.2733881309444355, 0.2733881309444355]
#         
# 
#     mylambda7 = 10
#     numalphas7 = 100
#     precisions7 = [0.509703196347032, 0.4925187032418953, 0.1289326384867786, 0.20694288913773795, 0.14525241479861492, 0.14525241479861492]
#     recalls7 = [0.5846153846153846, 0.5160026126714565, 0.21872953503601833, 0.30166503428011754, 0.2602024159320927, 0.2602024159320927]
#     f1scores7 = [0.5445952126848606, 0.5039872408293461, 0.16223436551305404, 0.2454835281615303, 0.1864327485380117, 0.1864327485380117]
#     tprs7 = [0.5846153846153846, 0.5160026126714565, 0.21872953503601833, 0.30166503428011754, 0.2602024159320927, 0.2602024159320927]
#     fprs7 = [0.1762955361723961, 0.1671801191209694, 0.46306176893084344, 0.3636643730101674, 0.48166786484543495, 0.48166786484543495]
#     errors7 = [0, 4.839973873285435, 7.812704649639817, 6.983349657198826, 7.397975840679073, 7.397975840679073]
#     payoffs7 = [0, 5.530996766216198, 8.301517026209632, 7.4670826745024055, 7.898058462965916, 7.898058462965916]
#     norms7 = [0, 0.30897710706923665, 0.5111876234301835, 0.5162669826964201, 0.4999173777131576, 0.4999173777131576]
#         
# 
#     mylambda8 = 10
#     numalphas8 = 20
#     precisions8 = [0.5108571428571429, 0.5010805804260574, 0.239251040221914, 0.2853206412825651, 0.1835229667088074, 0.2853206412825651, 0.2853206412825651]
#     recalls8 = [0.5864217776320105, 0.5271191945436831, 0.3384565075212557, 0.3719790986283475, 0.28426892950391647, 0.3719790986283475, 0.3719790986283475]
#     f1scores8 = [0.5460375629867156, 0.5137701804368471, 0.2803358613217768, 0.3229373405160193, 0.22304737516005121, 0.3229373405160193, 0.3229373405160193]
#     tprs8 = [0.5864217776320105, 0.5271191945436831, 0.3384565075212557, 0.3719790986283475, 0.28426892950391647, 0.3719790986283475, 0.3719790986283475]
#     fprs8 = [0.1755717362321813, 0.16623804135377018, 0.33781564360500926, 0.2929759704251386, 0.39800739523418244, 0.2929759704251386, 0.2929759704251386]
#     errors8 = [0, 4.728808054563169, 6.615434924787442, 6.280209013716524, 7.157310704960835, 6.280209013716524, 6.280209013716524]
#     payoffs8 = [0, 5.4084124530589985, 7.056313129027419, 6.66867472800063, 7.622312829417546, 6.66867472800063, 6.66867472800063]
#     norms8 = [0, 0.32039560150417046, 0.5591217957600225, 0.6115342857158943, 0.5349978755432891, 0.6115342857158943, 0.6115342857158943]
#         
# 
#     mylambda9 = 10
#     numalphas9 = 10
#     precisions9 = [0.5169274537695591, 0.49111675126903553, 0.4909993792675357, 0.2895543503890592, 0.4935185185185185, 0.34550709406200736, 0.34550709406200736]
#     recalls9 = [0.5872656755009696, 0.5063788027477919, 0.517500817795224, 0.40235910878112713, 0.5220372184133203, 0.4297385620915033, 0.4297385620915033]
#     f1scores9 = [0.5498562566197609, 0.4986310194878402, 0.5039018952062431, 0.3367612779377485, 0.5073774393146121, 0.3830468977570638, 0.3830468977570638]
#     tprs9 = [0.5872656755009696, 0.5063788027477919, 0.517500817795224, 0.40235910878112713, 0.5220372184133203, 0.4297385620915033, 0.4297385620915033]
#     fprs9 = [0.17494333402019369, 0.16463101714051115, 0.16832597762496151, 0.3090890439064424, 0.16853240217726198, 0.2557494866529774, 0.2557494866529774]
#     errors9 = [0, 4.936211972522081, 4.8249918220477594, 5.976408912188729, 4.779627815866797, 5.702614379084967, 5.702614379084967]
#     payoffs9 = [0, 5.613622059272161, 5.41478418963845, 6.391601202706889, 5.210716244515645, 6.057424570435412, 6.057424570435412]
#     norms9 = [0, 0.3225899132499199, 0.4102076324093096, 0.58480770948184, 0.5689115713511521, 0.6451898086495547, 0.6451898086495547]
#         
# 
#     mylambda10 = 10
#     numalphas10 = 10
#     precisions10 = [0.5124555160142349, 0.4915764139590854, 0.5026946107784431, 0.30875931158489595, 0.45721054190109567, 0.04330708661417323, 0.04330708661417323]
#     recalls10 = [0.6139717940308298, 0.5353866317169069, 0.5426632191338073, 0.39306736429038586, 0.5022771633051398, 0.08986928104575163, 0.08986928104575163]
#     f1scores10 = [0.55863921217547, 0.5125470514429109, 0.5219148274790177, 0.3458495180549561, 0.4786854751201364, 0.05844845908607864, 0.05844845908607864]
#     tprs10 = [0.6139717940308298, 0.5353866317169069, 0.5426632191338073, 0.39306736429038586, 0.5022771633051398, 0.08986928104575163, 0.08986928104575163]
#     fprs10 = [0.18264793354527742, 0.17336889618383258, 0.17113125901504225, 0.2762266475056457, 0.18846391116594693, 0.6237166324435318, 0.6237166324435318]
#     errors10 = [0, 0.23230668414154654, 0.22866839043309634, 0.30346631785480704, 0.24886141834743009, 0.4550653594771242, 0.4550653594771242]
#     payoffs10 = [0, 1.004525986978824, 0.9979098447629909, 0.9976697759933637, 0.9982853407607597, 1.053429735573995, 1.053429735573995]
#     norms10 = [0, 0.22778069716272253, 0.23075854567010545, 0.30579654186144345, 0.25057607758667033, 0.4016356239031291, 0.4016356239031291]
# 
#     mylambda11 = 1
#     numalphas11 = 10
#     precisions11 = [0.5126791620727673, 0.5029154518950437, 0.4959617110379898, 0.4959617110379898]
#     recalls11 = [0.6066536203522505, 0.5653883972468043, 0.5397135416666666, 0.5397135416666666]
#     f1scores11 = [0.5557215416791156, 0.5323252584477705, 0.5169134840218238, 0.5169134840218238]
#     tprs11 = [0.6066536203522505, 0.5653883972468043, 0.5397135416666666, 0.5397135416666666]
#     fprs11 = [0.181631395109924, 0.17488973228023388, 0.17321134868421054, 0.17321134868421054]
#     errors11 = [0, 0.43461160275319566, 0.46028645833333337, 0.46028645833333337]
#     payoffs11 = [0, 1.179715160662358, 1.1363456471017066, 1.1363456471017066]
#     norms11 = [0, 0.2548964420908377, 0.3239408112316269, 0.3239408112316269]


# Following are results for experiment with handwritten digits data

    # 7 and 9
    mylambda1 = 10
    numalphas1 = 1000
    f1scores1 = [0.7787, 0.5653, 0.5653]

    # 1 and 4
    mylambda2 = 10
    numalphas2 = 1000
    f1scores2 = [0.9734, 0.5487, 0.647, 0.6465, 0.6572, 0.544, 0.6549, 0.652, 0.6617, 0.5455, 0.5455]

    
    # 4 and 9
    mylambda3 = 10
    numalphas3 = 1000
    f1scores3 = [0.7301, 0.6376, 0.8696, 0.8819, 0.8818, 0.8775, 0.7829, 0.7829]

    
    # 2 and 6
    mylambda4 = 10
    numalphas4 = 1000
    f1scores4 = [0.8731, 0.8182, 0.8182]

    
    # 5 and 8
    mylambda5 = 10
    numalphas5 = 1000
    f1scores5 = [0.8504, 0.6439, 0.8789, 0.8882, 0.8882]
    
    # 2 and 8
    mylambda6 = 10
    numalphas6 = 1000
    f1scores6 = [0.8542, 0.7491, 0.7704, 0.7704]

    
    # 3 and 8
    mylambda7 = 10
    numalphas7 = 1000
    f1scores7 = [0.8551, 0.6244, 0.7416, 0.7434, 0.7417, 0.7438, 0.7467, 0.7467]

    
#     # 6 and 8
#     mylambda8 = 10
#     numalphas8 = 1000
#     f1scores8 = [0.7943, 0.6521, 0.5908, 0.639, 0.6085, 0.628, 0.6312, 0.6255, 0.7511, 0.7034, 0.8473, 0.7008, 0.9322, 0.9322]

    







    
    iterationnum = range(0,14)
    colormap = plt.cm.gist_ncar
    colors = [colormap(i) for i in np.linspace(0, 1,20)]

    plt.gca().set_color_cycle([colormap(i) for i in np.linspace(0, 0.9, 11)])
    
#     plt.plot(iterationnum[0:len(precisions1)],precisions1, label=str(mylambda1)+','+str(numalphas1), linestyle='-', marker='o', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions2)],precisions2, label=str(mylambda2)+','+str(numalphas2), linestyle='-', marker='v', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions3)],precisions3, label=str(mylambda3)+','+str(numalphas3), linestyle='-', marker='^', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions4)],precisions4, label=str(mylambda4)+','+str(numalphas4), linestyle='-', marker='<', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions5)],precisions5, label=str(mylambda5)+','+str(numalphas5), linestyle='-', marker='>', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions6)],precisions6, label=str(mylambda6)+','+str(numalphas6), linestyle='-', marker='s', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions7)],precisions7, label=str(mylambda7)+','+str(numalphas7), linestyle='-', marker='p', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions8)],precisions8, label=str(mylambda8)+','+str(numalphas8), linestyle='-', marker='H', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions9)],precisions9, label=str(mylambda9)+','+str(numalphas9), linestyle='-', marker='d', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions10)],precisions10, label=str(mylambda10)+','+str(numalphas10), linestyle='-', marker='x', linewidth=2)
#     plt.plot(iterationnum[0:len(precisions11)],precisions11, label=str(mylambda11)+','+str(numalphas11), linestyle='-', marker='D', linewidth=2)
#     title('Training Precisions')
#     xlabel('Iteration')
#     ylabel('Precision')
# #     legend = plt.legend(loc='upper center', shadow=True)
# #     plt.legend(loc=2)
# #     legend.get_frame().set_facecolor('#00FFCC')
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
# #     plt.legend()
# #     plt.grid()
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/TrainingPrecisions.png", dpi=300)
# #     plt.show()
  
#     plt.plot(iterationnum[0:len(recalls1)],recalls1, label=str(mylambda1)+','+str(numalphas1), linestyle='-', marker='o', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls2)],recalls2, label=str(mylambda2)+','+str(numalphas2), linestyle='-', marker='v', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls3)],recalls3, label=str(mylambda3)+','+str(numalphas3), linestyle='-', marker='^', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls4)],recalls4, label=str(mylambda4)+','+str(numalphas4), linestyle='-', marker='<', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls5)],recalls5, label=str(mylambda5)+','+str(numalphas5), linestyle='-', marker='>', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls6)],recalls6, label=str(mylambda6)+','+str(numalphas6), linestyle='-', marker='s', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls7)],recalls7, label=str(mylambda7)+','+str(numalphas7), linestyle='-', marker='p', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls8)],recalls8, label=str(mylambda8)+','+str(numalphas8), linestyle='-', marker='H', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls9)],recalls9, label=str(mylambda9)+','+str(numalphas9), linestyle='-', marker='d', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls10)],recalls10, label=str(mylambda10)+','+str(numalphas10), linestyle='-', marker='x', linewidth=2)
#     plt.plot(iterationnum[0:len(recalls11)],recalls11, label=str(mylambda11)+','+str(numalphas11), linestyle='-', marker='D', linewidth=2)
#     title('Training Recalls')
#     xlabel('Iteration')
#     ylabel('Recall')
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
# #     plt.legend()
# #     plt.grid()
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/TrainingRecalls.png", dpi=300)
# #     plt.show()
#       
    plt.plot(iterationnum[0:len(f1scores1)],f1scores1, label=str(7)+','+str(9), linestyle='-', marker='o', linewidth=2)
    plt.plot(iterationnum[0:len(f1scores2)],f1scores2, label=str(1)+','+str(4), linestyle='-', marker='v', linewidth=2)
    plt.plot(iterationnum[0:len(f1scores3)],f1scores3, label=str(4)+','+str(9), linestyle='-', marker='^', linewidth=2)
    plt.plot(iterationnum[0:len(f1scores4)],f1scores4, label=str(2)+','+str(6), linestyle='-', marker='<', linewidth=2)
    plt.plot(iterationnum[0:len(f1scores5)],f1scores5, label=str(5)+','+str(8), linestyle='-', marker='>', linewidth=2)
    plt.plot(iterationnum[0:len(f1scores6)],f1scores6, label=str(2)+','+str(8), linestyle='-', marker='s', linewidth=2)
    plt.plot(iterationnum[0:len(f1scores7)],f1scores7, label=str(3)+','+str(8), linestyle='-', marker='p', linewidth=2)
#     plt.plot(iterationnum[0:len(f1scores8)],f1scores8, label=str(mylambda8)+','+str(numalphas8), linestyle='-', marker='H', linewidth=2)
#     plt.plot(iterationnum[0:len(f1scores9)],f1scores9, label=str(mylambda9)+','+str(numalphas9), linestyle='-', marker='d', linewidth=2)
#     plt.plot(iterationnum[0:len(f1scores10)],f1scores10, label=str(mylambda10)+','+str(numalphas10), linestyle='-', marker='x', linewidth=2)
#     plt.plot(iterationnum[0:len(f1scores11)],f1scores11, label=str(mylambda11)+','+str(numalphas11), linestyle='-', marker='D', linewidth=2)
#    title('Training F1Scores')
    xlabel('Game Iteration')
    ylabel('Training performance: f1score')

    ax = plt.subplot(111)
    box = ax.get_position()
    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
#     plt.legend()
# #     plt.grid()
    plt.grid(linestyle='-', linewidth=0.4)
    savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/TrainingF1Scores.png", dpi=300)
#     plt.show()
   
#     plt.plot(iterationnum[0:len(tprs1)],tprs1, label=str(mylambda1)+','+str(numalphas1), linestyle='-', marker='o', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs2)],tprs2, label=str(mylambda2)+','+str(numalphas2), linestyle='-', marker='v', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs3)],tprs3, label=str(mylambda3)+','+str(numalphas3), linestyle='-', marker='^', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs4)],tprs4, label=str(mylambda4)+','+str(numalphas4), linestyle='-', marker='<', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs5)],tprs5, label=str(mylambda5)+','+str(numalphas5), linestyle='-', marker='>', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs6)],tprs6, label=str(mylambda6)+','+str(numalphas6), linestyle='-', marker='s', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs7)],tprs7, label=str(mylambda7)+','+str(numalphas7), linestyle='-', marker='p', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs8)],tprs8, label=str(mylambda8)+','+str(numalphas8), linestyle='-', marker='H', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs9)],tprs9, label=str(mylambda9)+','+str(numalphas9), linestyle='-', marker='d', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs10)],tprs10, label=str(mylambda10)+','+str(numalphas10), linestyle='-', marker='x', linewidth=2)
#     plt.plot(iterationnum[0:len(tprs11)],tprs11, label=str(mylambda11)+','+str(numalphas11), linestyle='-', marker='D', linewidth=2)
#     title('Training TPRs')
#     xlabel('Iteration')
#     ylabel('TPR')
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
# #     plt.legend()
# #     plt.grid()
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/TrainingTPRs.png", dpi=300)
# #     plt.show()
#   
#    
#     plt.plot(iterationnum[0:len(fprs1)],fprs1, label=str(mylambda1)+','+str(numalphas1), linestyle='-', marker='o', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs2)],fprs2, label=str(mylambda2)+','+str(numalphas2), linestyle='-', marker='v', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs3)],fprs3, label=str(mylambda3)+','+str(numalphas3), linestyle='-', marker='^', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs4)],fprs4, label=str(mylambda4)+','+str(numalphas4), linestyle='-', marker='<', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs5)],fprs5, label=str(mylambda5)+','+str(numalphas5), linestyle='-', marker='>', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs6)],fprs6, label=str(mylambda6)+','+str(numalphas6), linestyle='-', marker='s', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs7)],fprs7, label=str(mylambda7)+','+str(numalphas7), linestyle='-', marker='p', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs8)],fprs8, label=str(mylambda8)+','+str(numalphas8), linestyle='-', marker='H', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs9)],fprs9, label=str(mylambda9)+','+str(numalphas9), linestyle='-', marker='d', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs10)],fprs10, label=str(mylambda10)+','+str(numalphas10), linestyle='-', marker='x', linewidth=2)
#     plt.plot(iterationnum[0:len(fprs11)],fprs11, label=str(mylambda11)+','+str(numalphas11), linestyle='-', marker='D', linewidth=2)
#     title('Training FPRs')
#     xlabel('Iteration')
#     ylabel('FPR')
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
# #     plt.legend()
# #     plt.grid()
#    plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/TrainingFPRs.png", dpi=300)
# #     plt.show()
#   
#   
#     plt.plot(iterationnum[0:len(errors1)],errors1, label=str(mylambda1)+','+str(numalphas1), linestyle='-', marker='o', linewidth=2)
#     plt.plot(iterationnum[0:len(errors2)],errors2, label=str(mylambda2)+','+str(numalphas2), linestyle='-', marker='v', linewidth=2)
#     plt.plot(iterationnum[0:len(errors3)],errors3, label=str(mylambda3)+','+str(numalphas3), linestyle='-', marker='^', linewidth=2)
#     plt.plot(iterationnum[0:len(errors4)],errors4, label=str(mylambda4)+','+str(numalphas4), linestyle='-', marker='<', linewidth=2)
#     plt.plot(iterationnum[0:len(errors5)],errors5, label=str(mylambda5)+','+str(numalphas5), linestyle='-', marker='>', linewidth=2)
#     plt.plot(iterationnum[0:len(errors6)],errors6, label=str(mylambda6)+','+str(numalphas6), linestyle='-', marker='s', linewidth=2)
#     plt.plot(iterationnum[0:len(errors7)],errors7, label=str(mylambda7)+','+str(numalphas7), linestyle='-', marker='p', linewidth=2)
#     plt.plot(iterationnum[0:len(errors8)],errors8, label=str(mylambda8)+','+str(numalphas8), linestyle='-', marker='H', linewidth=2)
#     plt.plot(iterationnum[0:len(errors9)],errors9, label=str(mylambda9)+','+str(numalphas9), linestyle='-', marker='d', linewidth=2)
#     plt.plot(iterationnum[0:len(errors10)],errors10, label=str(mylambda10)+','+str(numalphas10), linestyle='-', marker='x', linewidth=2)
#     plt.plot(iterationnum[0:len(errors11)],errors11, label=str(mylambda11)+','+str(numalphas11), linestyle='-', marker='D', linewidth=2)
#     title('Training Errors')
#     xlabel('Iteration')
#     ylabel('Error')
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
# #     plt.legend()
# #     plt.grid()
#    plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/TrainingErrors.png", dpi=300)
# #     plt.show()

#     plt.gca().set_color_cycle([colormap(i) for i in np.linspace(0, 0.9, 15)])
#   
#     plt.plot(iterationnum[0:len(payoffs1)],payoffs1, label=str(mylambda1)+','+str(numalphas1), linestyle='-', marker='o', linewidth=2)    
#     plt.plot(iterationnum[0:len(payoffs2)],payoffs2, label=str(mylambda2)+','+str(numalphas2), linestyle='-', marker='v', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs3)],payoffs3, label=str(mylambda3)+','+str(numalphas3), linestyle='-', marker='^', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs4)],payoffs4, label=str(mylambda4)+','+str(numalphas4), linestyle='-', marker='<', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs5)],payoffs5, label=str(mylambda5)+','+str(numalphas5), linestyle='-', marker='>', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs6)],payoffs6, label=str(mylambda6)+','+str(numalphas6), linestyle='-', marker='s', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs7)],payoffs7, label=str(mylambda7)+','+str(numalphas7), linestyle='-', marker='p', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs8)],payoffs8, label=str(mylambda8)+','+str(numalphas8), linestyle='-', marker='H', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs9)],payoffs9, label=str(mylambda9)+','+str(numalphas9), linestyle='-', marker='d', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs10)],payoffs10, label=str(mylambda10)+','+str(numalphas10), linestyle='-', marker='x', linewidth=2)
#     plt.plot(iterationnum[0:len(payoffs11)],payoffs11, label=str(mylambda11)+','+str(numalphas11), linestyle='-', marker='D', linewidth=2)
#     title('Training Payoffs')
#     xlabel('Iteration')
#     ylabel('Payoff')
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
# #     plt.legend()
# #     plt.grid()
#    plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/TrainingPayoffs.png", dpi=300)
# #     plt.show()
  
  
#     plt.plot(iterationnum[0:len(norms1)],norms1, label=str(mylambda1)+','+str(numalphas1), linestyle='-', marker='o', linewidth=2)
#     plt.plot(iterationnum[0:len(norms2)],norms2, label=str(mylambda2)+','+str(numalphas2), linestyle='-', marker='v', linewidth=2)
#     plt.plot(iterationnum[0:len(norms3)],norms3, label=str(mylambda3)+','+str(numalphas3), linestyle='-', marker='^', linewidth=2)
#     plt.plot(iterationnum[0:len(norms4)],norms4, label=str(mylambda4)+','+str(numalphas4), linestyle='-', marker='<', linewidth=2)
#     plt.plot(iterationnum[0:len(norms5)],norms5, label=str(mylambda5)+','+str(numalphas5), linestyle='-', marker='>', linewidth=2)
#     plt.plot(iterationnum[0:len(norms6)],norms6, label=str(mylambda6)+','+str(numalphas6), linestyle='-', marker='s', linewidth=2)
#     plt.plot(iterationnum[0:len(norms7)],norms7, label=str(mylambda7)+','+str(numalphas7), linestyle='-', marker='p', linewidth=2)
#     plt.plot(iterationnum[0:len(norms8)],norms8, label=str(mylambda8)+','+str(numalphas8), linestyle='-', marker='H', linewidth=2)
#     plt.plot(iterationnum[0:len(norms9)],norms9, label=str(mylambda9)+','+str(numalphas9), linestyle='-', marker='d', linewidth=2)
#     plt.plot(iterationnum[0:len(norms10)],norms10, label=str(mylambda10)+','+str(numalphas10), linestyle='-', marker='x', linewidth=2)
#     plt.plot(iterationnum[0:len(norms11)],norms11, label=str(mylambda11)+','+str(numalphas11), linestyle='-', marker='D', linewidth=2)
#     title('Training Norms')
#     xlabel('Iteration')
#     ylabel('Norm')
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
# #     plt.legend()
# #     plt.grid()
#    plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/TrainingNorms.png", dpi=300)
# #     plt.show()


    print('Successfully saved all plots one at a time')



def saplots():
    

    # (7,9)
 
#     deltay1 = []
#     deltay2 = []
#     deltay3 = []
#      
#     deltax1 = []
#     deltax2 = []
#     deltax3 = []
#      
#     deltay1.append(0.8331)
#     deltax1.append(10)
#      
#     deltay1.append(0.8167)
#     deltax1.append(20)
#      
#     deltay1.append(0.8107)
#     deltax1.append(30)
#          
#     deltay1.append(0.8226)
#     deltax1.append(40)
#      
#     deltay1.append(0.8151)
#     deltax1.append(50)
#      
#     deltay1.append(0.8185)
#     deltax1.append(60)
#          
#     deltay1.append(0.8085)
#     deltax1.append(70)
#      
#     deltay1.append(0.8118)
#     deltax1.append(80)
#      
#     deltay1.append(0.824)
#     deltax1.append(90)
#      
#     deltay1.append(0.8231)
#     deltax1.append(100)
#      
#          
#     deltay2.append(0.7018)
#     deltax2.append(10)
#      
#     deltay2.append(0.6874)
#     deltax2.append(20)
#      
#     deltay2.append(0.6868)
#     deltax2.append(30)
#      
#     deltay2.append(0.5895)
#     deltax2.append(40)
#      
#     deltay2.append(0.6117)
#     deltax2.append(50)
#      
#     deltay2.append(0.5911)
#     deltax2.append(60)
#      
#     deltay2.append(0.6343)
#     deltax2.append(70)
#      
#     deltay2.append(0.6719)
#     deltax2.append(80)
#          
#     deltay2.append(0.6475)
#     deltax2.append(90)
#      
#     deltay2.append(0.6011)
#     deltax2.append(100)
#          
#          
#     deltay3.append(0.9919)
#     deltax3.append(10)
#      
#     deltay3.append(0.8273)
#     deltax3.append(20)
#      
#     deltay3.append(0.8486)
#     deltax3.append(30)
#          
#     deltay3.append(0.9991)
#     deltax3.append(40)
#      
#     deltay3.append(0.9998)
#     deltax3.append(50)
#      
#     deltay3.append(0.9995)
#     deltax3.append(60)
#      
#     deltay3.append(0.9995)
#     deltax3.append(70)
#          
#     deltay3.append(0.9956)
#     deltax3.append(80)
#          
#     deltay3.append(0.9995)
#     deltax3.append(90)
#      
#     deltay3.append(0.9998)
#     deltax3.append(100)
#        
#     fig = plt.figure(1)
#     ax = fig.add_subplot(111)
#    
#     ax.plot(deltax1,deltay1, label='Original Learner Performance', linestyle='-', marker='o', linewidth=2)
#     ax.plot(deltax2,deltay2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     ax.plot(deltax3,deltay3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#      
#     xlabel(r'Upper bound for Annealing step [$\delta$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#        
# #     box = ax.get_position()
# #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
# #     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#    
#     handles, labels = ax.get_legend_handles_labels()
#     lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
#        
# #     ax.grid('on')
#    
# #     ax.legend(loc='best', bbox_to_anchor=(0.1, 1.05))
#     ax.grid(linestyle='-', linewidth=0.4)
#     fig.savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/PerturbationStepParams79.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
#          
#     l1 = deltay1
#     l2 = deltay2
#     l3 = deltay3
 
 
#     etay1 = []
#     etay2 = []
#     etay3 = []
#       
#     etax1 = []
#     etax2 = []
#     etax3 = []
#       
#     etay1.append(0.806)
# #     etax1.append(2)
#     etax1.append(8)
#       
#     etay1.append(0.8319)
# #     etax1.append(3)
#     etax1.append(7)
#       
#     etay1.append(0.7975)
# #     etax1.append(4)
#     etax1.append(6)
#       
#     etay1.append(0.8181)
# #     etax1.append(5)
#     etax1.append(5)
#       
#     etay1.append(0.8054)
# #     etax1.append(6)
#     etax1.append(4)
#       
#     etay1.append(0.814)
# #     etax1.append(7)
#     etax1.append(3)
#       
#     etay1.append(0.8064)
# #     etax1.append(8)
#     etax1.append(2)
#       
#     etay1.append(0.811)
# #     etax1.append(9)
#     etax1.append(1)
#       
#       
#     etay2.append(0.6104)
#     etax2.append(2)
#       
#     etay2.append(0.7425)
#     etax2.append(3)
#       
#     etay2.append(0.7275)
#     etax2.append(4)
#       
#     etay2.append(0.7992)
#     etax2.append(5)
#       
#     etay2.append(0.5966)
#     etax2.append(6)
#       
#     etay2.append(0.7033)
#     etax2.append(7)
#       
#     etay2.append(0.6811)
#     etax2.append(8)
#       
#     etay2.append(0.6515)
#     etax2.append(9)
#       
#       
#     etay3.append(0.9996)
#     etax3.append(2)
#       
#     etay3.append(0.9998)
#     etax3.append(3)
#       
#     etay3.append(0.9976)
#     etax3.append(4)
#       
#     etay3.append(0.9995)
#     etax3.append(5)
#       
#     etay3.append(0.9996)
#     etax3.append(6)
#       
#     etay3.append(0.9943)
#     etax3.append(7)
#       
#     etay3.append(0.8179)
#     etax3.append(8)
#       
#     etay3.append(0.9978)
#     etax3.append(9)
#     
#     fig = plt.figure(1)
#     ax = fig.add_subplot(111)
#     
#      
#     ax.plot(etax1,etay1, label='Original Learner Performance', linestyle='-', marker='o', linewidth=2)
#     ax.plot(etax1,etay2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     ax.plot(etax1,etay3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#      
#     xlabel(r'Upper bound for Annealing width [$\eta$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#     
# #     ax = plt.subplot(111)
# #     box = ax.get_position()
# #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
# #     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
# #     plt.grid(linestyle='-', linewidth=0.4)
#     
#     handles, labels = ax.get_legend_handles_labels()
#     lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
#     
#     ax.grid(linestyle='-', linewidth=0.4)
#     
#     fig.savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/PerturbationIndexParams79.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
#          
#     l1 = etay1
#     l2 = etay2
#     l3 = etay3
     
 
#     ReductionRatey1 = []
#     ReductionRatey2 = []
#     ReductionRatey3 = []
#      
#     ReductionRatex1 = []
#     ReductionRatex2 = []
#     ReductionRatex3 = []
#      
#     ReductionRatey1.append(0.8262)
#     ReductionRatex1.append(0.5)
#      
#     ReductionRatey1.append(0.8219)
#     ReductionRatex1.append(0.6)
#      
#     ReductionRatey1.append(0.8149)
#     ReductionRatex1.append(0.7)
#      
#     ReductionRatey1.append(0.8102)
#     ReductionRatex1.append(0.8)
#      
#     ReductionRatey1.append(0.8212)
#     ReductionRatex1.append(0.9)
#      
#     ReductionRatey2.append(0.607)
#     ReductionRatex2.append(0.5)
#      
#     ReductionRatey2.append(0.5826)
#     ReductionRatex2.append(0.6)
#      
#     ReductionRatey2.append(0.6483)
#     ReductionRatex2.append(0.7)
#      
#     ReductionRatey2.append(0.6657)
#     ReductionRatex2.append(0.8)
#      
#     ReductionRatey2.append(0.6405)
#     ReductionRatex2.append(0.9)
#      
#     ReductionRatey3.append(0.9991)
#     ReductionRatex3.append(0.5)
#      
#     ReductionRatey3.append(1.0)
#     ReductionRatex3.append(0.6)
#      
#     ReductionRatey3.append(0.8124)
#     ReductionRatex3.append(0.7)
#      
#     ReductionRatey3.append(0.9091)
#     ReductionRatex3.append(0.8)
#      
#     ReductionRatey3.append(0.9971)
#     ReductionRatex3.append(0.9)
#     
#     
#     fig = plt.figure(1)
#     ax = fig.add_subplot(111)
#    
#     ax.plot(ReductionRatex1,ReductionRatey1, label='Original Learner Performance', linestyle='-', marker='o', linewidth=2)
#     ax.plot(ReductionRatex2,ReductionRatey2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     ax.plot(ReductionRatex3,ReductionRatey3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#     
#     xlabel(r'Reduction rate [$\rho$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#    
# #     ax = plt.subplot(111)
# #     box = ax.get_position()
# #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
# #     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#    
#     handles, labels = ax.get_legend_handles_labels()
#     lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
#        
#     ax.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/ReductionRateParams79.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
#      
#     l1 = ReductionRatey1
#     l2 = ReductionRatey2
#     l3 = ReductionRatey3
 
#     SampleSizey1 = []
#     SampleSizey2 = []
#     SampleSizey3 = []
#     
#     SampleSizex1 = []
#     SampleSizex2 = []
#     SampleSizex3 = []
#     
#     SampleSizey1.append(0.8158)
#     SampleSizex1.append(10)
#     
#     SampleSizey1.append(0.8081)
#     SampleSizex1.append(20)
#     
#     SampleSizey1.append(0.8144)
#     SampleSizex1.append(30)
#     
#     SampleSizey1.append(0.8139)
#     SampleSizex1.append(40)
#     
#     SampleSizey1.append(0.8166)
#     SampleSizex1.append(50)
#     
#     SampleSizey1.append(0.8327)
#     SampleSizex1.append(60)
#     
#     SampleSizey1.append(0.8165)
#     SampleSizex1.append(70)
#     
#     SampleSizey1.append(0.8155)
#     SampleSizex1.append(80)
#     
#     SampleSizey1.append(0.8226)
#     SampleSizex1.append(90)
#     
#     SampleSizey1.append(0.8014)
#     SampleSizex1.append(100)
#     
#     SampleSizey2.append(0.5894)
#     SampleSizex2.append(10)
#     
#     SampleSizey2.append(0.705)
#     SampleSizex2.append(20)
#     
#     SampleSizey2.append(0.6813)
#     SampleSizex2.append(30)
#     
#     SampleSizey2.append(0.6256)
#     SampleSizex2.append(40)
#     
#     SampleSizey2.append(0.6639)
#     SampleSizex2.append(50)
#     
#     SampleSizey2.append(0.663)
#     SampleSizex2.append(60)
#     
#     SampleSizey2.append(0.6305)
#     SampleSizex2.append(70)
#     
#     SampleSizey2.append(0.7048)
#     SampleSizex2.append(80)
#     
#     SampleSizey2.append(0.6416)
#     SampleSizex2.append(90)
#     
#     SampleSizey2.append(0.6608)
#     SampleSizex2.append(100)
#     
#     SampleSizey3.append(0.9995)
#     SampleSizex3.append(10)
#     
#     SampleSizey3.append(0.8709)
#     SampleSizex3.append(20)
#     
#     SampleSizey3.append(0.9985)
#     SampleSizex3.append(30)
#     
#     SampleSizey3.append(0.9945)
#     SampleSizex3.append(40)
#     
#     SampleSizey3.append(0.9973)
#     SampleSizex3.append(50)
#     
#     SampleSizey3.append(0.994)
#     SampleSizex3.append(60)
#     
#     SampleSizey3.append(0.9985)
#     SampleSizex3.append(70)
#     
#     SampleSizey3.append(0.753)
#     SampleSizex3.append(80)
#     
#     SampleSizey3.append(0.7698)
#     SampleSizex3.append(90)
#     
#     SampleSizey3.append(0.7765)
#     SampleSizex3.append(100)
#    
#    
#     
#     fig = plt.figure(1)
#     ax = fig.add_subplot(111)
#    
#     ax.plot(SampleSizex1,SampleSizey1, label='Original Learner Performance', linestyle='-', marker='o', linewidth=2)
#     ax.plot(SampleSizex2,SampleSizey2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     ax.plot(SampleSizex3,SampleSizey3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#    
#     xlabel(r'Sample size [$\nu$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#   
# #     ax = plt.subplot(111)
# #     box = ax.get_position()
# #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
# #     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#   
#     handles, labels = ax.get_legend_handles_labels()
#     lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
#     plt.grid(linestyle='-', linewidth=0.4)
#     fig.savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/SampleSizeParams79.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
#    
#    
#     l1 = SampleSizey1
#     l2 = SampleSizey2
#     l3 = SampleSizey3


    mylambday1 = []
    mylambday2 = []
    mylambday3 = []
     
    mylambdax1 = []
    mylambdax2 = []
    mylambdax3 = []
     
    mylambday1.append(0.8195)
    mylambdax1.append(1)
     
    mylambday1.append(0.8109)
    mylambdax1.append(3)
     
    mylambday1.append(0.8162)
    mylambdax1.append(5)
     
    mylambday1.append(0.8099)
    mylambdax1.append(7)
     
    mylambday1.append(0.8275)
    mylambdax1.append(9)
     
    mylambday1.append(0.8263)
    mylambdax1.append(11)
     
    mylambday1.append(0.8355)
    mylambdax1.append(14)
     
    mylambday1.append(0.8128)
    mylambdax1.append(17)
     
    mylambday1.append(0.8283)
    mylambdax1.append(20)
       
       
    mylambday2.append(0.7734)
    mylambdax2.append(1)
     
    mylambday2.append(0.6076)
    mylambdax2.append(3)
     
    mylambday2.append(0.6794)
    mylambdax2.append(5)
     
    mylambday2.append(0.6423)
    mylambdax2.append(7)
     
    mylambday2.append(0.6516)
    mylambdax2.append(9)
     
    mylambday2.append(0.5819)
    mylambdax2.append(11)
     
    mylambday2.append(0.6387)
    mylambdax2.append(14)
     
    mylambday2.append(0.717)
    mylambdax2.append(17)
     
    mylambday2.append(0.5935)
    mylambdax2.append(20)
   
    mylambday3.append(0.9991)
    mylambdax3.append(1)
     
    mylambday3.append(0.9984)
    mylambdax3.append(3)
     
    mylambday3.append(0.7474)
    mylambdax3.append(5)
     
    mylambday3.append(0.9934)
    mylambdax3.append(7)
     
    mylambday3.append(0.9995)
    mylambdax3.append(9)
     
    mylambday3.append(0.9993)
    mylambdax3.append(11)
     
    mylambday3.append(0.9721)
    mylambdax3.append(14)
     
    mylambday3.append(0.9037)
    mylambdax3.append(17)
     
    mylambday3.append(0.9971)
    mylambdax3.append(20)
  
  
    fig = plt.figure(1)
    ax = fig.add_subplot(111)
    
    ax.plot(mylambdax1,mylambday1, label='Original Learner Performance', linestyle='-', marker='o', linewidth=2)
    ax.plot(mylambdax2,mylambday2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
    ax.plot(mylambdax3,mylambday3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
    
    xlabel(r'Error weight [$\lambda$]', fontsize=20)    
    ylabel('Testing performance : f1score', fontsize=20)
    
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
  
    handles, labels = ax.get_legend_handles_labels()
    lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
      
    ax.grid(linestyle='-', linewidth=0.4)
    fig.savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/mylambda79.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
    
    
    l1 = mylambday1
    l2 = mylambday2
    l3 = mylambday3


    # (4,9)

#     deltay1 = []
#     deltay2 = []
#     deltay3 = []
# 
#     deltax1 = []
#     deltax2 = []
#     deltax3 = []
# 
#     deltay1.append(0.7928)
#     deltax1.append(10)
# 
#     deltay1.append(0.8272)
#     deltax1.append(20)
# 
#     deltay1.append(0.7819)
#     deltax1.append(30)
#     
#     deltay1.append(0.8241)
#     deltax1.append(40)
# 
#     deltay1.append(0.8111)
#     deltax1.append(50)
# 
#     deltay1.append(0.8196)
#     deltax1.append(60)
#     
#     deltay1.append(0.8086)
#     deltax1.append(70)
# 
#     deltay1.append(0.7785)
#     deltax1.append(80)
# 
#     deltay1.append(0.8148)
#     deltax1.append(90)
# 
#     deltay1.append(0.8144)
#     deltax1.append(100)
#     
#     deltay2.append(0.6776)
#     deltax2.append(10)
# 
#     deltay2.append(0.6262)
#     deltax2.append(20)
# 
#     deltay2.append(0.7194)
#     deltax2.append(30)
# 
#     deltay2.append(0.6376)
#     deltax2.append(40)
# 
#     deltay2.append(0.6254)
#     deltax2.append(50)
# 
#     deltay2.append(0.6567)
#     deltax2.append(60)
# 
#     deltay2.append(0.6781)
#     deltax2.append(70)
# 
#     deltay2.append(0.6594)
#     deltax2.append(80)
#     
#     deltay2.append(0.6472)
#     deltax2.append(90)
# 
#     deltay2.append(0.6106)
#     deltax2.append(100)
#     
#     
#     deltay3.append(0.7899)
#     deltax3.append(10)
# 
#     deltay3.append(0.9989)
#     deltax3.append(20)
# 
#     deltay3.append(0.9997)
#     deltax3.append(30)
#     
#     deltay3.append(0.9944)
#     deltax3.append(40)
# 
#     deltay3.append(0.999)
#     deltax3.append(50)
# 
#     deltay3.append(0.9546)
#     deltax3.append(60)
# 
#     deltay3.append(0.7525)
#     deltax3.append(70)
#     
#     deltay3.append(0.994)
#     deltax3.append(80)
#     
#     deltay3.append(0.9985)
#     deltax3.append(90)
# 
#     deltay3.append(0.9915)
#     deltax3.append(100)
#     
#     plt.plot(deltax1,deltay1, label='learner performance', linestyle='-', marker='o', linewidth=2)
#     plt.plot(deltax2,deltay2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     plt.plot(deltax3,deltay3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#  
#     xlabel(r'Upper Bound for Perturbation Step [$\delta$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/PerturbationStepParams49.png", dpi=300)
 
 
#     l1 = deltay1
#     l2 = deltay2
#     l3 = deltay3
# 
# 
#     etay1 = []
#     etay2 = []
#     etay3 = []
# 
#     etax1 = []
#     etax2 = []
#     etax3 = []
# 
#     etay1.append(0.7938)
#     etax1.append(2)
# 
#     etay1.append(0.7669)
#     etax1.append(3)
# 
#     etay1.append(0.7941)
#     etax1.append(4)
# 
#     etay1.append(0.762)
#     etax1.append(5)
# 
#     etay1.append(0.7747)
#     etax1.append(6)
# 
#     etay1.append(0.7747)
#     etax1.append(7)
# 
#     etay1.append(0.7949)
#     etax1.append(8)
# 
#     etay1.append(0.8159)
#     etax1.append(9)
# 
# 
#     etay2.append(0.6945)
#     etax2.append(2)
# 
#     etay2.append(0.6427)
#     etax2.append(3)
# 
#     etay2.append(0.6417)
#     etax2.append(4)
# 
#     etay2.append(0.6921)
#     etax2.append(5)
# 
#     etay2.append(0.6455)
#     etax2.append(6)
# 
#     etay2.append(0.6455)
#     etax2.append(7)
# 
#     etay2.append(0.6583)
#     etax2.append(8)
# 
#     etay2.append(0.6249)
#     etax2.append(9)
# 
# 
#     etay3.append(0.7583)
#     etax3.append(2)
# 
#     etay3.append(0.998)
#     etax3.append(3)
# 
#     etay3.append(0.9875)
#     etax3.append(4)
# 
#     etay3.append(0.9995)
#     etax3.append(5)
# 
#     etay3.append(0.9997)
#     etax3.append(6)
# 
#     etay3.append(0.9997)
#     etax3.append(7)
# 
#     etay3.append(0.9559)
#     etax3.append(8)
# 
#     etay3.append(1.0)
#     etax3.append(9)
# 
#     plt.plot(etax1,etay1, label='learner performance', linestyle='-', marker='o', linewidth=2)
#     plt.plot(etax2,etay2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     plt.plot(etax3,etay3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#  
#     xlabel(r'Upper Bound for Perturbation Index [$\eta$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/PerturbationIndexParams49.png", dpi=300)
 
#     l1 = etay1
#     l2 = etay2
#     l3 = etay3
#     
# 
#     ReductionRatey1 = []
#     ReductionRatey2 = []
#     ReductionRatey3 = []
# 
#     ReductionRatex1 = []
#     ReductionRatex2 = []
#     ReductionRatex3 = []
# 
#     ReductionRatey1.append(0.8043)
#     ReductionRatex1.append(0.5)
# 
#     ReductionRatey1.append(0.8179)
#     ReductionRatex1.append(0.6)
# 
#     ReductionRatey1.append(0.8231)
#     ReductionRatex1.append(0.7)
# 
#     ReductionRatey1.append(0.813)
#     ReductionRatex1.append(0.8)
# 
#     ReductionRatey1.append(0.8068)
#     ReductionRatex1.append(0.9)
# 
#     ReductionRatey2.append(0.7835)
#     ReductionRatex2.append(0.5)
# 
#     ReductionRatey2.append(0.6893)
#     ReductionRatex2.append(0.6)
# 
#     ReductionRatey2.append(0.7002)
#     ReductionRatex2.append(0.7)
# 
#     ReductionRatey2.append(0.6289)
#     ReductionRatex2.append(0.8)
# 
#     ReductionRatey2.append(0.6618)
#     ReductionRatex2.append(0.9)
# 
#     ReductionRatey3.append(0.9997)
#     ReductionRatex3.append(0.5)
# 
#     ReductionRatey3.append(0.8003)
#     ReductionRatex3.append(0.6)
# 
#     ReductionRatey3.append(0.8203)
#     ReductionRatex3.append(0.7)
# 
#     ReductionRatey3.append(0.9997)
#     ReductionRatex3.append(0.8)
# 
#     ReductionRatey3.append(0.9992)
#     ReductionRatex3.append(0.9)
# 

#     plt.plot(ReductionRatex1,ReductionRatey1, label='learner performance', linestyle='-', marker='o', linewidth=2)
#     plt.plot(ReductionRatex2,ReductionRatey2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     plt.plot(ReductionRatex3,ReductionRatey3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#  
#     xlabel(r'Reduction Rate [$\rho$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/ReductionRateParams49.png", dpi=300)


#     l1 = ReductionRatey1
#     l2 = ReductionRatey2
#     l3 = ReductionRatey3
# 
#     SampleSizey1 = []
#     SampleSizey2 = []
#     SampleSizey3 = []
#  
#     SampleSizex1 = []
#     SampleSizex2 = []
#     SampleSizex3 = []
#  
#     SampleSizey1.append(0.8048)
#     SampleSizex1.append(10)
#  
#     SampleSizey1.append(0.7725)
#     SampleSizex1.append(20)
#  
#     SampleSizey1.append(0.7756)
#     SampleSizex1.append(30)
#  
#     SampleSizey1.append(0.7535)
#     SampleSizex1.append(40)
#  
#     SampleSizey1.append(0.7966)
#     SampleSizex1.append(50)
#  
#     SampleSizey1.append(0.7858)
#     SampleSizex1.append(60)
#  
#     SampleSizey1.append(0.7817)
#     SampleSizex1.append(70)
#  
#     SampleSizey1.append(0.807)
#     SampleSizex1.append(80)
#  
#     SampleSizey1.append(0.7901)
#     SampleSizex1.append(90)
#  
#     SampleSizey1.append(0.7851)
#     SampleSizex1.append(100)
#  
#     SampleSizey2.append(0.6409)
#     SampleSizex2.append(10)
#  
#     SampleSizey2.append(0.6624)
#     SampleSizex2.append(20)
#  
#     SampleSizey2.append(0.6641)
#     SampleSizex2.append(30)
#  
#     SampleSizey2.append(0.6393)
#     SampleSizex2.append(40)
#  
#     SampleSizey2.append(0.6419)
#     SampleSizex2.append(50)
#  
#     SampleSizey2.append(0.6419)
#     SampleSizex2.append(60)
#  
#     SampleSizey2.append(0.6599)
#     SampleSizex2.append(70)
#  
#     SampleSizey2.append(0.6448)
#     SampleSizex2.append(80)
#  
#     SampleSizey2.append(0.6878)
#     SampleSizex2.append(90)
#  
#     SampleSizey2.append(0.6677)
#     SampleSizex2.append(100)
#  
#     SampleSizey3.append(0.9976)
#     SampleSizex3.append(10)
#  
#     SampleSizey3.append(0.9772)
#     SampleSizex3.append(20)
#  
#     SampleSizey3.append(0.8984)
#     SampleSizex3.append(30)
#  
#     SampleSizey3.append(0.7804)
#     SampleSizex3.append(40)
#  
#     SampleSizey3.append(0.9988)
#     SampleSizex3.append(50)
#  
#     SampleSizey3.append(0.9958)
#     SampleSizex3.append(60)
#  
#     SampleSizey3.append(0.9794)
#     SampleSizex3.append(70)
#  
#     SampleSizey3.append(0.9998)
#     SampleSizex3.append(80)
#  
#     SampleSizey3.append(0.9813)
#     SampleSizex3.append(90)
#  
#     SampleSizey3.append(0.9971)
#     SampleSizex3.append(100)
# 
# # 
#     plt.plot(SampleSizex1,SampleSizey1, label='learner performance', linestyle='-', marker='o', linewidth=2)
#     plt.plot(SampleSizex2,SampleSizey2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     plt.plot(SampleSizex3,SampleSizey3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#  
#     xlabel(r'Sample Size [$\nu$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/SampleSizeParams49.png", dpi=300)
#  
#     l1 = SampleSizey1
#     l2 = SampleSizey2
#     l3 = SampleSizey3


#     mylambday1 = []
#     mylambday2 = []
#     mylambday3 = []
#    
#     mylambdax1 = []
#     mylambdax2 = []
#     mylambdax3 = []
#    
#     mylambday1.append(0.8048)
#     mylambdax1.append(1)
#    
#     mylambday1.append(0.7984)
#     mylambdax1.append(3)
#    
#     mylambday1.append(0.7372)
#     mylambdax1.append(5)
#    
#     mylambday1.append(0.8156)
#     mylambdax1.append(7)
#    
#     mylambday1.append(0.7979)
#     mylambdax1.append(9)
#    
#     mylambday1.append(0.7839)
#     mylambdax1.append(11)
#    
#     mylambday1.append(0.7793)
#     mylambdax1.append(14)
#    
#     mylambday1.append(0.7813)
#     mylambdax1.append(17)
#    
#     mylambday1.append(0.8098)
#     mylambdax1.append(20)
#      
#      
#     mylambday2.append(0.764)
#     mylambdax2.append(1)
#    
#     mylambday2.append(0.6309)
#     mylambdax2.append(3)
#    
#     mylambday2.append(0.6429)
#     mylambdax2.append(5)
#    
#     mylambday2.append(0.6344)
#     mylambdax2.append(7)
#    
#     mylambday2.append(0.6356)
#     mylambdax2.append(9)
#    
#     mylambday2.append(0.6414)
#     mylambdax2.append(11)
#    
#     mylambday2.append(0.638)
#     mylambdax2.append(14)
#    
#     mylambday2.append(0.6207)
#     mylambdax2.append(17)
#    
#     mylambday2.append(0.6196)
#     mylambdax2.append(20)
#  
#     mylambday3.append(0.9)
#     mylambdax3.append(1)
#    
#     mylambday3.append(0.9997)
#     mylambdax3.append(3)
#    
#     mylambday3.append(0.9498)
#     mylambdax3.append(5)
#    
#     mylambday3.append(0.9997)
#     mylambdax3.append(7)
#    
#     mylambday3.append(0.9985)
#     mylambdax3.append(9)
#    
#     mylambday3.append(0.999)
#     mylambdax3.append(11)
#    
#     mylambday3.append(0.9958)
#     mylambdax3.append(14)
#    
#     mylambday3.append(0.9993)
#     mylambdax3.append(17)
#    
#     mylambday3.append(0.9995)
#     mylambdax3.append(20)
#  
#   
#     plt.plot(mylambdax1,mylambday1, label='learner performance', linestyle='-', marker='o', linewidth=2)
#     plt.plot(mylambdax2,mylambday2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     plt.plot(mylambdax3,mylambday3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
#   
#     xlabel(r'Error Weight [$\lambda$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/mylambda49.png", dpi=300)
#   
#   
#     l1 = mylambday1
#     l2 = mylambday2
#     l3 = mylambday3



    
    
    
    print('Output results for ',perfmetric)
    ttest=stats.ttest_ind(l1,l2,equal_var=True)
    print 't-statistic independent = %6.3f manipulated testing pvalue = ' % ttest[0],"{:.2e}".format(ttest[1])
#     ttest=stats.ttest_rel(l1,l2)
#     print 't-statistic dependent = %6.3f pvalue = %6.4f' % ttest
    
    ttest=stats.ttest_ind(l1,l3,equal_var=True)
    print 't-statistic independent = %6.3f manipulated training and manipulated testing pvalue = ' % ttest[0],"{:.2e}".format(ttest[1])

    ttest=stats.ttest_ind(l2,l3,equal_var=True)
    print 't-statistic independent = %6.3f manipulated testing and manipulated training/testing pvalue = ' % ttest[0],"{:.2e}".format(ttest[1])

    a = np.array([l1,l2,l3])
    friedmantest = stats.friedmanchisquare(*(a[i, :] for i in range(a.shape[0])))
#     print 'friedmantest-statistic = %6.3f pvalue = %6.100f' % friedmantest
    print 'friedmantest-statistic = %6.3f pvalue = ' % friedmantest[0],"{:.2e}".format(friedmantest[1])


    
    print('Successfully saved all plots one at a time')

        
def gaplots():
#     mutationx1 = []
#     mutationy1 = []
#                      
#     mutationx1.append(5)
#     mutationy1.append(0.7988)
#                 
#     mutationx1.append(10)
# #     mutationy1.append(0.8008)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(20)
# #     mutationy1.append(0.8051)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(30)
# #     mutationy1.append(0.7726)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(40)
# #     mutationy1.append(0.7817)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(50)
# #     mutationy1.append(0.7939)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(60)
# #     mutationy1.append(0.798)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(70)
# #     mutationy1.append(0.7728)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(80)
# #     mutationy1.append(0.7936)
# #     mutationx1.append(80)
# #     mutationy1.append(0.6241)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(90)
# #     mutationy1.append(0.8092)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(100)
# #     mutationy1.append(0.7916)
#     mutationy1.append(0.7988)
#                  
#     mutationx1.append(200)
# #     mutationy1.append(0.7866)
#     mutationy1.append(0.7988)
#                  
#                
#     mutationx2 = []
#     mutationy2 = []
#     mutationx2.append(5)
#     mutationy2.append(0.5908)
#                
#     mutationx2.append(10)
#     mutationy2.append(0.6231)
#                
#     mutationx2.append(20)
#     mutationy2.append(0.5949)
#                
#     mutationx2.append(30)
#     mutationy2.append(0.6084)
#                
#     mutationx2.append(40)
#     mutationy2.append(0.5933)
#                
#     mutationx2.append(50)
#     mutationy2.append(0.6336)
#                
#     mutationx2.append(60)
#     mutationy2.append(0.6446)
#                
#     mutationx2.append(70)
#     mutationy2.append(0.6275)
#                
#     mutationx2.append(80)
#     mutationy2.append(0.5936)
#                
#     mutationx2.append(90)
#     mutationy2.append(0.6274)
#                
#     mutationx2.append(100)
#     mutationy2.append(0.6973)
#                 
#     mutationx2.append(200)
#     mutationy2.append(0.6222)
#                
#     mutationx3 = []
#     mutationy3 = []
#                    
#     mutationx3.append(5)
#     mutationy3.append(0.7041)
#                
#     mutationx3.append(10)
#     mutationy3.append(0.7274)
#                
#     mutationx3.append(20)
#     mutationy3.append(0.6779)
#                
#     mutationx3.append(30)
#     mutationy3.append(0.9047)
#                
#     mutationx3.append(40)
#     mutationy3.append(0.7988)
#                
#     mutationx3.append(50)
#     mutationy3.append(0.7601)
#                
#     mutationx3.append(60)
#     mutationy3.append(0.7209)
#                 
#     mutationx3.append(70)
#     mutationy3.append(0.6829)
#                 
#     mutationx3.append(80)
#     mutationy3.append(0.7374)
#                 
#     mutationx3.append(90)
#     mutationy3.append(0.7616)
#                 
#     mutationx3.append(100)
#     mutationy3.append(0.9508)
#                 
#     mutationx3.append(200)
#     mutationy3.append(0.7034)
#   
#     fig = plt.figure(1)
#     ax = fig.add_subplot(111)
#   
#     ax.plot(mutationx1,mutationy1, label='Original Learner Performance', linestyle='-', marker='o', linewidth=2)
#     ax.plot(mutationx2,mutationy2, label='Manipulated Learner Performance', linestyle='--', marker='v', linewidth=2)
#     ax.plot(mutationx3,mutationy3, label='Secure Learner Performance (Our method)', linestyle='-', marker='^', linewidth=2)
# #    title('Parameter Tuning : Mutation Operation')
# #     xlabel('Upper Bound for Mutation')
#     xlabel(r'Upper bound for Mutation [$\delta$]', fontsize=20)
#     ylabel('Testing performance : f1score', fontsize=20)
#   
#     handles, labels = ax.get_legend_handles_labels()
#     lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
#       
# #     ax = plt.subplot(111)
# #     box = ax.get_position()
# #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
# #     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
# #     plt.legend()
# #     plt.grid()
#   
#     ax.grid(linestyle='-', linewidth=0.4)
#     fig.savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/MutationParams.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
#     l1 = mutationy1
#     l2 = mutationy2
#     l3 = mutationy3





#     crossoverx1 = []
#     crossovery1 = []
#                
#     crossoverx1.append(2)
#     crossovery1.append(0.7867)
#                
#     crossoverx1.append(3)
#     crossovery1.append(0.7786)
# #     crossovery1.append(0.7867)
#                
#     crossoverx1.append(4)
# #     crossovery1.append()
#     crossovery1.append(0.7867)
#                
#     crossoverx1.append(5)
#     crossovery1.append(0.7957)
# #     crossovery1.append(0.7867)
#                
#     crossoverx1.append(6)
#     crossovery1.append(0.8091)
# #     crossovery1.append(0.7867)
#                
#     crossoverx1.append(7)
# #     crossovery1.append()
#     crossovery1.append(0.7867)
#                
#     crossoverx1.append(8)
# #     crossovery1.append(0.7869)
#     crossovery1.append(0.7867)
#              
#     crossoverx1.append(9)
#     crossovery1.append(0.7929)
# #     crossovery1.append(0.7867)
#              
#              
#     crossoverx2 = []
#     crossovery2 = []
#                
#     crossoverx2.append(2)
#     crossovery2.append(0.791)
#                
#     crossoverx2.append(3)
#     crossovery2.append(0.6722)
#                
#     crossoverx2.append(4)
#     crossovery2.append(0.6669)
#                
#     crossoverx2.append(5)
#     crossovery2.append(0.6081)
#                
#     crossoverx2.append(6)
#     crossovery2.append(0.6823)
#                
#     crossoverx2.append(7)
#     crossovery2.append(0.5673)
#                
#     crossoverx2.append(8)
#     crossovery2.append(0.6509)
#              
#     crossoverx2.append(9)
#     crossovery2.append(0.6222)
#              
#              
#              
#     crossoverx3 = []
#     crossovery3 = []
#                
#     crossoverx3.append(2)
#     crossovery3.append(0.9936)
#                
#     crossoverx3.append(3)
#     crossovery3.append(0.7165)
#                
#     crossoverx3.append(4)
#     crossovery3.append(0.7345)
#                
#     crossoverx3.append(5)
#     crossovery3.append(0.9753)
#                
#     crossoverx3.append(6)
#     crossovery3.append(0.7734)
#                
#     crossoverx3.append(7)
#     crossovery3.append(0.9945)
#                
#     crossoverx3.append(8)
#     crossovery3.append(0.9929)
#              
#     crossoverx3.append(9)
#     crossovery3.append(0.7135)
#       
#     fig = plt.figure(1)
#     ax = fig.add_subplot(111)
#               
#     ax.plot(crossoverx1,crossovery1, label='Original Learner Performance', linestyle='-', marker='<', linewidth=2)
#     ax.plot(crossoverx2,crossovery2, label='Manipulated Learner Performance', linestyle='--', marker='>', linewidth=2)
#     ax.plot(crossoverx3,crossovery3, label='Secure Learner Performance (Our method)', linestyle='-', marker='s', linewidth=2)
#              
# ##     title('Parameter Tuning : Crossover Operation')
# #     xlabel('Minimum width for Crossover')
#     xlabel(r'Minimum width for Crossover [$\eta$]', fontsize=20)    
#     ylabel('Testing performance : f1score', fontsize=20)
#       
#     handles, labels = ax.get_legend_handles_labels()
#     lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
#       
# #     ax = plt.subplot(111)
# #     box = ax.get_position()
# #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
# #     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
# #     plt.legend()
# #     plt.grid()
#   
#     ax.grid(linestyle='-', linewidth=0.4)
#     fig.savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/CrossoverParams.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
#     l1 = crossovery1
#     l2 = crossovery2
#     l3 = crossovery3
  
  
  
  
   
#     selectionx1 = []
#     selectiony1 = []
#                   
#     selectionx1.append(20)
#     selectiony1.append(0.7881)
#                   
#     selectionx1.append(30)
# #     selectiony1.append()
#     selectiony1.append(0.7881)
#                       
#     selectionx1.append(40)
#     selectiony1.append(0.7905)
# #     selectiony1.append(0.7881)
#                 
#     selectionx1.append(50)
#     selectiony1.append(0.8065)
# #     selectiony1.append(0.7881)
#                   
#     selectionx1.append(60)
# # #     selectiony1.append()
#     selectiony1.append(0.7881)
#                   
#     selectionx1.append(70)
#     selectiony1.append(0.796)
# #     selectiony1.append(0.7881)
#                   
#     selectionx1.append(80)
#     selectiony1.append(0.7845)
# #     selectiony1.append(0.7881)
#                
#                
#                
#                
#                
#     selectionx2 = []
#     selectiony2 = []
#                   
#     selectionx2.append(20)
#     selectiony2.append(0.6277)
#                   
#     selectionx2.append(30)
#     selectiony2.append(0.5937)
#                       
#     selectionx2.append(40)
#     selectiony2.append(0.6783)
#                 
#     selectionx2.append(50)
#     selectiony2.append(0.6012)
#                   
#     selectionx2.append(60)
#     selectiony2.append(0.6238)
#                   
#     selectionx2.append(70)
#     selectiony2.append(0.6619)
#                   
#     selectionx2.append(80)
#     selectiony2.append(0.613)
#                
#                
#                
#                
#                
#                
#                
#                
#                
#     selectionx3 = []
#     selectiony3 = []
#                   
#     selectionx3.append(20)
#     selectiony3.append(0.8076)
#                   
#     selectionx3.append(30)
#     selectiony3.append(0.7869)
#                       
#     selectionx3.append(40)
#     selectiony3.append(0.759)
#                 
#     selectionx3.append(50)
#     selectiony3.append(0.7691)
#                   
#     selectionx3.append(60)
#     selectiony3.append(0.7775)
#                   
#     selectionx3.append(70)
#     selectiony3.append(0.9266)
#                   
#     selectionx3.append(80)
#     selectiony3.append(0.8918)
#                
#                
#     fig = plt.figure(1)
#     ax = fig.add_subplot(111)
#   
#                  
#     ax.plot(selectionx1,selectiony1, label='Original Learner Performance', linestyle='-', marker='p', linewidth=2)
#     ax.plot(selectionx2,selectiony2, label='Manipulated Learner Performance', linestyle='--', marker='H', linewidth=2)
#     ax.plot(selectionx3,selectiony3, label='Secure Learner Performance (Our method)', linestyle='-', marker='d', linewidth=2)
# #    title('Parameter Tuning : Selection Operation')
# #     xlabel('Percentage offspring size for Selection')
#     xlabel(r'Percentage offspring size for Selection [$\zeta$]', fontsize=20)
#     ylabel('Testing performance : f1score', fontsize=20)
#       
# #     ax = plt.subplot(111)
# #     box = ax.get_position()
# #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
# #     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
# #     plt.legend()color='r', linestyle='-', linewidth=2
#   
#     handles, labels = ax.get_legend_handles_labels()
#     lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
#       
#     plt.grid(linestyle='-', linewidth=0.4)
#     savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/SelectionParams.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
#     l1 = selectiony1
#     l2 = selectiony2
#     l3 = selectiony3

    
    
    
    
    populationx1 = []
    populationy1 = []
              
    populationx1.append(500)
    populationy1.append(0.7864)
          
    populationx1.append(1500)
    populationy1.append(0.7864)
          
    populationx1.append(2000)
    populationy1.append(0.7864)
          
    populationx1.append(2500)
    populationy1.append(0.7864)
          
    populationx1.append(3000)
    populationy1.append(0.7864)
       
    populationx1.append(3500)
    populationy1.append(0.7789)
          
    populationx1.append(4000)
    populationy1.append(0.7864)
          
    populationx1.append(4500)
    populationy1.append(0.7864)
          
    populationx1.append(5000)
    populationy1.append(0.7864)
          
    populationx1.append(6000)
    populationy1.append(0.7864)
          
    populationx1.append(7000)
    populationy1.append(0.7864)
          
    populationx1.append(8000)
    populationy1.append(0.7864)
          
    populationx1.append(9000)
    populationy1.append(0.7864)
          
    populationx1.append(10000)
    populationy1.append(0.7864)
              
    populationx2 = []
    populationy2 = []
              
    populationx2.append(500)
    populationy2.append(0.6403)
          
    populationx2.append(1500)
    populationy2.append(0.6194)
          
    populationx2.append(2000)
    populationy2.append(0.6104)
          
    populationx2.append(2500)
    populationy2.append(0.6101)
          
    populationx2.append(3000)
    populationy2.append(0.5777)
          
    populationx2.append(3500)
    populationy2.append(0.65)
          
    populationx2.append(4000)
    populationy2.append(0.5974)
          
    populationx2.append(4500)
    populationy2.append(0.6091)
          
    populationx2.append(5000)
    populationy2.append(0.6073)
          
    populationx2.append(6000)
    populationy2.append(0.6268)
          
    populationx2.append(7000)
    populationy2.append(0.6174)
          
    populationx2.append(8000)
    populationy2.append(0.5853)
          
    populationx2.append(9000)
    populationy2.append(0.5846)
          
    populationx2.append(10000)
    populationy2.append(0.6322)
          
    populationx3 = []
    populationy3 = []
              
    populationx3.append(500)
    populationy3.append(0.7711)
          
    populationx3.append(1500)
    populationy3.append(0.6792)
          
    populationx3.append(2000)
    populationy3.append(0.774)
          
    populationx3.append(2500)
    populationy3.append(0.6953)
          
    populationx3.append(3000)
    populationy3.append(0.759)
          
    populationx3.append(3500)
    populationy3.append(0.8285)
       
    populationx3.append(4000)
    populationy3.append(0.7503)
          
    populationx3.append(4500)
    populationy3.append(0.7388)
          
    populationx3.append(5000)
    populationy3.append(0.6914)
          
    populationx3.append(6000)
    populationy3.append(0.7792)
          
    populationx3.append(7000)
    populationy3.append(0.7205)
          
    populationx3.append(8000)
    populationy3.append(0.6984)
          
    populationx3.append(9000)
    populationy3.append(0.8452)
          
    populationx3.append(10000)
    populationy3.append(0.7477)
              
    fig = plt.figure(1)
    ax = fig.add_subplot(111)
              
    ax.plot(populationx1,populationy1, label='Original Learner Performance', linestyle='-', marker='p', linewidth=2)
    ax.plot(populationx2,populationy2, label='Manipulated Learner Performance', linestyle='--', marker='H', linewidth=2)
    ax.plot(populationx3,populationy3, label='Secure Learner Performance (Our method)', linestyle='-', marker='d', linewidth=2)
#    title('Parameter Tuning : Selection Operation')
#     xlabel('Population Size')
    xlabel(r'Population size [$\psi$]', fontsize=20)
    ylabel('Testing performance : f1score', fontsize=20)
  
    handles, labels = ax.get_legend_handles_labels()
    lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.1))
        
#     ax = plt.subplot(111)
#     box = ax.get_position()
#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
#     ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1.05), ncol=1, fancybox=True, shadow=True, prop={'size':10})
#     plt.legend()color='r', linestyle='-', linewidth=2
  
    ax.grid(linestyle='-', linewidth=0.4)
    fig.savefig("/home/aneesh/Documents/IJCNN Paper/IJCNN/images/PopulationParams.eps", format='eps', dpi=1200, bbox_extra_artists=(lgd,), bbox_inches='tight')
    l1 = populationy1
    l2 = populationy2
    l3 = populationy3




    
#     lowstrengthattacky1 = []
#     lowstrengthattacky1.append(0.8421)
#     lowstrengthattacky1.append(0.7915)
#     lowstrengthattacky1.append(0.9736)
#     lowstrengthattacky1.append(0.8295)
#     lowstrengthattacky1.append(0.8629)
#     lowstrengthattacky1.append(0.8024)
#     lowstrengthattacky1.append(0.6382)
#     lowstrengthattacky1.append(0.876)
#  
#      
#     lowstrengthattacky2 = []
#     lowstrengthattacky2.append(0.6788)
#     lowstrengthattacky2.append(0.6552)
#     lowstrengthattacky2.append(0.6648)
#     lowstrengthattacky2.append(0.6366)
#     lowstrengthattacky2.append(0.6812)
#     lowstrengthattacky2.append(0.619)
#     lowstrengthattacky2.append(0.6257)
#     lowstrengthattacky2.append(0.826)
#  
#  
#     lowstrengthattacky3 = []
#     lowstrengthattacky3.append(0.7785)
#     lowstrengthattacky3.append(0.7807)
#     lowstrengthattacky3.append(0.9813)
#     lowstrengthattacky3.append(0.8391)
#     lowstrengthattacky3.append(0.9624)
#     lowstrengthattacky3.append(0.8669)
#     lowstrengthattacky3.append(0.8202)
#     lowstrengthattacky3.append(0.9974)
#  
#     l1 = lowstrengthattacky1
#     l2 = lowstrengthattacky2
#     l3 = lowstrengthattacky3









#     mediumstrengthattacky1 = []
#     mediumstrengthattacky1.append(0.859)
#     mediumstrengthattacky1.append(0.7253)
#     mediumstrengthattacky1.append(0.9767)
#     mediumstrengthattacky1.append(0.8371)
#     mediumstrengthattacky1.append(0.857)
#     mediumstrengthattacky1.append(0.8025)
#     mediumstrengthattacky1.append(0.7082)
#     mediumstrengthattacky1.append(0.8747)
#        
#     mediumstrengthattacky2 = []
#     mediumstrengthattacky2.append(0.7868)
#     mediumstrengthattacky2.append(0.6786)
#     mediumstrengthattacky2.append(0.5634)
#     mediumstrengthattacky2.append(0.6499)
#     mediumstrengthattacky2.append(0.7172)
#     mediumstrengthattacky2.append(0.6471)
#     mediumstrengthattacky2.append(0.6168)
#     mediumstrengthattacky2.append(0.8087)
#    
#     mediumstrengthattacky3 = []
#     mediumstrengthattacky3.append(0.84)
#     mediumstrengthattacky3.append(0.7938)
#     mediumstrengthattacky3.append(0.9886)
#     mediumstrengthattacky3.append(0.8354)
#     mediumstrengthattacky3.append(0.8721)
#     mediumstrengthattacky3.append(0.7841)
#     mediumstrengthattacky3.append(0.9598)
#     mediumstrengthattacky3.append(0.9233)
#    
#     l1 = mediumstrengthattacky1
#     l2 = mediumstrengthattacky2
#     l3 = mediumstrengthattacky3
 
 
 
 
 
# 
#     highstrengthattacky1 = []
#     highstrengthattacky1.append()
#     highstrengthattacky1.append()
#     highstrengthattacky1.append()
#     highstrengthattacky1.append()
#     highstrengthattacky1.append()
#     highstrengthattacky1.append()
#     highstrengthattacky1.append()
#     highstrengthattacky1.append()
#     
#     highstrengthattacky2 = []
#     highstrengthattacky2.append()
#     highstrengthattacky2.append()
#     highstrengthattacky2.append()
#     highstrengthattacky2.append()
#     highstrengthattacky2.append()
#     highstrengthattacky2.append()
#     highstrengthattacky2.append()
#     highstrengthattacky2.append()
# 
#     highstrengthattacky3 = []
#     highstrengthattacky3.append()
#     highstrengthattacky3.append()
#     highstrengthattacky3.append()
#     highstrengthattacky3.append()
#     highstrengthattacky3.append()
#     highstrengthattacky3.append()
#     highstrengthattacky3.append()
#     highstrengthattacky3.append()
# 
#     l1 = highstrengthattacky1
#     l2 = highstrengthattacky2
#     l3 = highstrengthattacky3


# t-statistic independent =  8.310 manipulated testing pvalue =  8.78e-07
# t-statistic independent = -8.370 manipulated training and manipulated testing pvalue =  8.06e-07
# t-statistic independent = -11.902 manipulated testing and manipulated training/testing pvalue =  1.04e-08
# friedmantest-statistic = 16.000 pvalue =  3.35e-04

    
    print('Output results for ',perfmetric)
    ttest=stats.ttest_ind(l1,l2,equal_var=True)
    print 't-statistic independent = %6.3f manipulated testing pvalue = ' % ttest[0],"{:.2e}".format(ttest[1])
#     ttest=stats.ttest_rel(l1,l2)
#     print 't-statistic dependent = %6.3f pvalue = %6.4f' % ttest
    
    ttest=stats.ttest_ind(l1,l3,equal_var=True)
    print 't-statistic independent = %6.3f manipulated training and manipulated testing pvalue = ' % ttest[0],"{:.2e}".format(ttest[1])

    ttest=stats.ttest_ind(l2,l3,equal_var=True)
    print 't-statistic independent = %6.3f manipulated testing and manipulated training/testing pvalue = ' % ttest[0],"{:.2e}".format(ttest[1])

    a = np.array([l1,l2,l3])
    friedmantest = stats.friedmanchisquare(*(a[i, :] for i in range(a.shape[0])))
#     print 'friedmantest-statistic = %6.3f pvalue = %6.100f' % friedmantest
    print 'friedmantest-statistic = %6.3f pvalue = ' % friedmantest[0],"{:.2e}".format(friedmantest[1])


    
    print('Successfully saved all plots one at a time')

def ttest():
    records = []
#     record = {'testing error on original training data and original testing data': {'recall': 0.8410206084396468, 'error': 0, 'precision': 0.49394812680115274, 'tpr': 0.8410206084396468, 'fpr': 0.07452678040913335, 'f1score': 0.6223674655047204, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8500486854917235, 'error': 0.5251798561151079, 'precision': 0.4980034227039361, 'tpr': 0.8500486854917235, 'fpr': 0.07474730315127835, 'f1score': 0.6280575539568345, 'norm': 1.5251798561151078, 'payoff': 0}, 'training error on original training data and original testing data': {'recall': 0.5127952755905512, 'error': 0, 'precision': 0.48935504070131497, 'tpr': 0.5127952755905512, 'fpr': 0.16724774405250206, 'f1score': 0.5008010253123999, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8516377649325626, 'error': 0.5251798561151079, 'precision': 0.5042783799201369, 'tpr': 0.8516377649325626, 'fpr': 0.07388199285835742, 'f1score': 0.6334647079899678, 'norm': 1.5251798561151078, 'payoff': 0}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8458536585365853, 'error': 0, 'precision': 0.49798966111430215, 'tpr': 0.8458536585365853, 'fpr': 0.07422505307855626, 'f1score': 0.6268980477223427, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8504950495049505, 'error': 0.5228758169934641, 'precision': 0.4891799544419134, 'tpr': 0.8504950495049505, 'fpr': 0.07608142493638677, 'f1score': 0.6211135213304411, 'norm': 1.522875816993464, 'payoff': 0}, 'training error on original training data and original testing data': {'recall': 0.5135842880523731, 'error': 0, 'precision': 0.49154135338345867, 'tpr': 0.5135842880523731, 'fpr': 0.16654694715238583, 'f1score': 0.5023211141347848, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8533724340175953, 'error': 0.5228758169934641, 'precision': 0.496304718590108, 'tpr': 0.8533724340175953, 'fpr': 0.07523138320455125, 'f1score': 0.6276060388209921, 'norm': 1.522875816993464, 'payoff': 0}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8481012658227848, 'error': 0, 'precision': 0.4994266055045872, 'tpr': 0.8481012658227848, 'fpr': 0.07415272233075682, 'f1score': 0.6286539155539517, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8475247524752475, 'error': 0.05024082993701371, 'precision': 0.4885844748858447, 'tpr': 0.8475247524752475, 'fpr': 0.07599660729431722, 'f1score': 0.6198406951484432, 'norm': 1.0502408299370136, 'payoff': 0}, 'training error on original training data and original testing data': {'recall': 0.5238558909444986, 'error': 0, 'precision': 0.4996904024767802, 'tpr': 0.5238558909444986, 'fpr': 0.1662722502315053, 'f1score': 0.5114878783077167, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.860078277886497, 'error': 0.05024082993701371, 'precision': 0.4957698815566836, 'tpr': 0.860078277886497, 'fpr': 0.07590422822210902, 'f1score': 0.6289803220035778, 'norm': 1.0502408299370136, 'payoff': 0}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8504854368932039, 'error': 0, 'precision': 0.4997147746719909, 'tpr': 0.8504854368932039, 'fpr': 0.07451146983857264, 'f1score': 0.6295364714337046, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8414872798434442, 'error': 0.5305826999638075, 'precision': 0.49596309111880044, 'tpr': 0.8414872798434442, 'fpr': 0.07420614705382918, 'f1score': 0.6240928882438317, 'norm': 1.5305826999638075, 'payoff': 0}, 'training error on original training data and original testing data': {'recall': 0.5158781594296824, 'error': 0, 'precision': 0.500943989930774, 'tpr': 0.5158781594296824, 'fpr': 0.16326950792670372, 'f1score': 0.508301404853129, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8553519768563163, 'error': 0.5305826999638075, 'precision': 0.5048377916903813, 'tpr': 0.8553519768563163, 'fpr': 0.07396072430502423, 'f1score': 0.6349319971367215, 'norm': 1.5305826999638075, 'payoff': 0}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8013500482160077, 'error': 0, 'precision': 0.35182049110922947, 'tpr': 0.8013500482160077, 'fpr': 0.13015387231148517, 'f1score': 0.4889673433362754, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8488714425907753, 'error': 2.6067961165048543, 'precision': 0.46380697050938335, 'tpr': 0.8488714425907753, 'fpr': 0.08488243782361429, 'f1score': 0.5998613037447988, 'norm': 0.24321273478208738, 'payoff': 3.363583381722767}, 'training error on original training data and original testing data': {'recall': 0.5856910569105691, 'error': 0, 'precision': 0.5084697910784868, 'tpr': 0.5856910569105691, 'fpr': 0.17902313624678665, 'f1score': 0.5443554480882575, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8250728862973761, 'error': 2.6067961165048543, 'precision': 0.2568835098335855, 'tpr': 0.8250728862973761, 'fpr': 0.2086483731203806, 'f1score': 0.39178587909552376, 'norm': 0.24321273478208738, 'payoff': 3.363583381722767}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8079601990049752, 'error': 0, 'precision': 0.342327150084317, 'tpr': 0.8079601990049752, 'fpr': 0.13225943196269604, 'f1score': 0.4809002072845721, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8449612403100775, 'error': 5.349740932642487, 'precision': 0.4890633763320247, 'tpr': 0.8449612403100775, 'fpr': 0.07741332426920462, 'f1score': 0.6195381882770871, 'norm': 0.22248840042438456, 'payoff': 6.127252532218103}, 'training error on original training data and original testing data': {'recall': 0.6054776654711445, 'error': 0, 'precision': 0.5101648351648351, 'tpr': 0.6054776654711445, 'fpr': 0.18319120517825954, 'f1score': 0.5537498136275533, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.831041257367387, 'error': 5.349740932642487, 'precision': 0.391304347826087, 'tpr': 0.831041257367387, 'fpr': 0.1116958071634697, 'f1score': 0.5320754716981132, 'norm': 0.22248840042438456, 'payoff': 6.127252532218103}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.7967244701348748, 'error': 0, 'precision': 0.37051971326164873, 'tpr': 0.7967244701348748, 'fpr': 0.11945247406903588, 'f1score': 0.5058103975535169, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8099415204678363, 'error': 0.3583955829814875, 'precision': 0.3064159292035398, 'tpr': 0.8099415204678363, 'fpr': 0.1597587905554612, 'f1score': 0.4446227929373997, 'norm': 0.4271933729827174, 'payoff': 0.9312022099987701}, 'training error on original training data and original testing data': {'recall': 0.6004507405022537, 'error': 0, 'precision': 0.5210952780106175, 'tpr': 0.6004507405022537, 'fpr': 0.176810398184444, 'f1score': 0.5579655946148093, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7902439024390244, 'error': 0.3583955829814875, 'precision': 0.19814090019569472, 'tpr': 0.7902439024390244, 'fpr': 0.2783864118895966, 'f1score': 0.3168394289067084, 'norm': 0.4271933729827174, 'payoff': 0.9312022099987701}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8170254403131115, 'error': 0, 'precision': 0.3417928776094965, 'tpr': 0.8170254403131115, 'fpr': 0.13652572592969944, 'f1score': 0.481962481962482, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8568646543330087, 'error': 9.246018849528761, 'precision': 0.497456189937818, 'tpr': 0.8568646543330087, 'fpr': 0.07551176420623461, 'f1score': 0.6294706723891274, 'norm': 0.3156680454511367, 'payoff': 9.930350804077625}, 'training error on original training data and original testing data': {'recall': 0.6026597469996756, 'error': 0, 'precision': 0.519284516489659, 'tpr': 0.6026597469996756, 'fpr': 0.17700936503035916, 'f1score': 0.5578741930641045, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7, 'error': 9.246018849528761, 'precision': 0.14621780571892112, 'tpr': 0.7, 'fpr': 0.3576890399320306, 'f1score': 0.24190572051669182, 'norm': 0.3156680454511367, 'payoff': 9.930350804077625}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8154296875, 'error': 0, 'precision': 0.3424938474159147, 'tpr': 0.8154296875, 'fpr': 0.13612432065217392, 'f1score': 0.4823801270941652, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8218780251694094, 'error': 9.174725983236621, 'precision': 0.4873708381171068, 'tpr': 0.8218780251694094, 'fpr': 0.0758902014107249, 'f1score': 0.6118918918918919, 'norm': 0.6399918170285073, 'payoff': 9.534734166208114}, 'training error on original training data and original testing data': {'recall': 0.5755418958265933, 'error': 0, 'precision': 0.5120898100172712, 'tpr': 0.5755418958265933, 'fpr': 0.17458028633226902, 'f1score': 0.541964965727342, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.6702439024390244, 'error': 9.174725983236621, 'precision': 0.12582417582417582, 'tpr': 0.6702439024390244, 'fpr': 0.40535031847133757, 'f1score': 0.21187355435620664, 'norm': 0.6399918170285073, 'payoff': 9.534734166208114}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8338164251207729, 'error': 0, 'precision': 0.36848847139197266, 'tpr': 0.8338164251207729, 'fpr': 0.12571185720356992, 'f1score': 0.5111045306485046, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8431752178121975, 'error': 0.05471391417425228, 'precision': 0.4985689753863766, 'tpr': 0.8431752178121975, 'fpr': 0.0744454831307895, 'f1score': 0.6266187050359712, 'norm': 0.3238329340992916, 'payoff': 0.7308809800749607}, 'training error on original training data and original testing data': {'recall': 0.5896272285251215, 'error': 0, 'precision': 0.5132618510158014, 'tpr': 0.5896272285251215, 'fpr': 0.17756047349459597, 'f1score': 0.5488007240911148, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7253176930596286, 'error': 0.05471391417425228, 'precision': 0.1793570219966159, 'tpr': 0.7253176930596286, 'fpr': 0.28827375392714616, 'f1score': 0.2875968992248062, 'norm': 0.3238329340992916, 'payoff': 0.7308809800749607}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8114511352418559, 'error': 0, 'precision': 0.363395225464191, 'tpr': 0.8114511352418559, 'fpr': 0.12216849071010435, 'f1score': 0.5019847328244275, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8352941176470589, 'error': 0.0051666666666666675, 'precision': 0.4824462061155153, 'tpr': 0.8352941176470589, 'fpr': 0.07758913412563667, 'f1score': 0.6116295764536971, 'norm': 0.23822431446430148, 'payoff': 0.7669423522023653}, 'training error on original training data and original testing data': {'recall': 0.5717085919634106, 'error': 0, 'precision': 0.5147058823529411, 'tpr': 0.5717085919634106, 'fpr': 0.16942191190060582, 'f1score': 0.5417118093174431, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7196896217264791, 'error': 0.0051666666666666675, 'precision': 0.16707948660211663, 'tpr': 0.7196896217264791, 'fpr': 0.31430028039765484, 'f1score': 0.2711988304093567, 'norm': 0.23822431446430148, 'payoff': 0.7669423522023653}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8250244379276638, 'error': 0, 'precision': 0.34128588758592804, 'tpr': 0.8250244379276638, 'fpr': 0.138320455124395, 'f1score': 0.482837528604119, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8571428571428571, 'error': 4.292437520285621, 'precision': 0.4437596302003082, 'tpr': 0.8571428571428571, 'fpr': 0.09184192672998644, 'f1score': 0.584771573604061, 'norm': 0.6505834171570459, 'payoff': 4.641854103128575}, 'training error on original training data and original testing data': {'recall': 0.5887758450935346, 'error': 0, 'precision': 0.5079275198187996, 'tpr': 0.5887758450935346, 'fpr': 0.17820157900133293, 'f1score': 0.5453716370269038, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7409579667644184, 'error': 4.292437520285621, 'precision': 0.1947584789311408, 'tpr': 0.7409579667644184, 'fpr': 0.26611191305086185, 'f1score': 0.30844354018311293, 'norm': 0.6505834171570459, 'payoff': 4.641854103128575}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.810126582278481, 'error': 0, 'precision': 0.35374149659863946, 'tpr': 0.810126582278481, 'fpr': 0.12910897817038988, 'f1score': 0.49245338857650195, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.842, 'error': 0.10628238341968912, 'precision': 0.46416758544652703, 'tpr': 0.842, 'fpr': 0.08237288135593221, 'f1score': 0.5984363894811656, 'norm': 0.23983366015721397, 'payoff': 0.8664487232624751}, 'training error on original training data and original testing data': {'recall': 0.592156862745098, 'error': 0, 'precision': 0.5099915564311849, 'tpr': 0.592156862745098, 'fpr': 0.17874743326488707, 'f1score': 0.5480114925147437, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7771260997067448, 'error': 0.10628238341968912, 'precision': 0.19073896353166986, 'tpr': 0.7771260997067448, 'fpr': 0.2864057060371911, 'f1score': 0.3062993642843383, 'norm': 0.23983366015721397, 'payoff': 0.8664487232624751}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8017664376840039, 'error': 0, 'precision': 0.3435660218671152, 'tpr': 0.8017664376840039, 'fpr': 0.1325014854426619, 'f1score': 0.4810126582278481, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8435972629521017, 'error': 11.06562703053931, 'precision': 0.4728767123287671, 'tpr': 0.8435972629521017, 'fpr': 0.0816846395516685, 'f1score': 0.6060393258426966, 'norm': 0.28957343623745757, 'payoff': 11.776053594301853}, 'training error on original training data and original testing data': {'recall': 0.590715920235371, 'error': 0, 'precision': 0.5054545454545455, 'tpr': 0.590715920235371, 'fpr': 0.18150087260034903, 'f1score': 0.5447693699125716, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8490749756572541, 'error': 11.06562703053931, 'precision': 0.2756876383180525, 'tpr': 0.8490749756572541, 'fpr': 0.1945978085449758, 'f1score': 0.4162291169451074, 'norm': 0.28957343623745757, 'payoff': 11.776053594301853}}
#     records.append(record)
    
    # Following are results for experiment when error is 1-recall
    
#     record = {'testing error on original training data and original testing data': {'recall': 0.8166828322017459, 'error': 0, 'precision': 0.350541215653622, 'tpr': 0.8166828322017459, 'fpr': 0.1325516186591894, 'f1score': 0.4905330614622779, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8462291870714985, 'error': 0.632952691680261, 'precision': 0.48268156424581005, 'tpr': 0.8462291870714985, 'fpr': 0.07861448340266576, 'f1score': 0.6147278548559232, 'norm': 0.3522083554977504, 'payoff': 1.2807443361825106}, 'training error on original training data and original testing data': {'recall': 0.586105675146771, 'error': 0, 'precision': 0.5096426545660806, 'tpr': 0.586105675146771, 'fpr': 0.1776248202177933, 'f1score': 0.5452063106796117, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7064579256360078, 'error': 0.632952691680261, 'precision': 0.19125827814569538, 'tpr': 0.7064579256360078, 'fpr': 0.25921209033791814, 'f1score': 0.30102147175317906, 'norm': 0.3522083554977504, 'payoff': 1.2807443361825106}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8305905130687319, 'error': 0, 'precision': 0.4022503516174402, 'tpr': 0.8305905130687319, 'fpr': 0.10835387099515595, 'f1score': 0.542008843967151, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8493150684931506, 'error': 8.121349772874757, 'precision': 0.496, 'tpr': 0.8493150684931506, 'fpr': 0.0748853795211411, 'f1score': 0.6262626262626263, 'norm': 0.6814581846842014, 'payoff': 8.439891588190555}, 'training error on original training data and original testing data': {'recall': 0.5706840390879478, 'error': 0, 'precision': 0.5028702640642939, 'tpr': 0.5706840390879478, 'fpr': 0.17800616649537512, 'f1score': 0.5346353371986573, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.6804619826756496, 'error': 8.121349772874757, 'precision': 0.13725490196078433, 'tpr': 0.6804619826756496, 'fpr': 0.37785902559306184, 'f1score': 0.2284329563812601, 'norm': 0.6814581846842014, 'payoff': 8.439891588190555}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8299516908212561, 'error': 0, 'precision': 0.35657949356579494, 'tpr': 0.8299516908212561, 'fpr': 0.1317467063323417, 'f1score': 0.4988385598141696, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8468292682926829, 'error': 19.49119373776908, 'precision': 0.4614566719829878, 'tpr': 0.8468292682926829, 'fpr': 0.08602972399150743, 'f1score': 0.5973847212663455, 'norm': 0.5592743557243125, 'payoff': 19.931919382044768}, 'training error on original training data and original testing data': {'recall': 0.6, 'error': 0, 'precision': 0.5175611126720989, 'tpr': 0.6, 'fpr': 0.176464542651593, 'f1score': 0.5557399306079348, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8334956183057449, 'error': 19.49119373776908, 'precision': 0.4911072862880092, 'tpr': 0.8334956183057449, 'fpr': 0.07534188397179988, 'f1score': 0.6180505415162455, 'norm': 0.5592743557243125, 'payoff': 19.931919382044768}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8181818181818182, 'error': 0, 'precision': 0.3635582294800172, 'tpr': 0.8181818181818182, 'fpr': 0.12587115417304096, 'f1score': 0.5034216007140732, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8245264207377866, 'error': 0.24812275546849494, 'precision': 0.45766463752075265, 'tpr': 0.8245264207377866, 'fpr': 0.08307196744935152, 'f1score': 0.5886120996441281, 'norm': 0.41607379244470966, 'payoff': 0.8320489630237852}, 'training error on original training data and original testing data': {'recall': 0.6009174311926605, 'error': 0, 'precision': 0.5039846111569113, 'tpr': 0.6009174311926605, 'fpr': 0.18516618793598688, 'f1score': 0.5481990733821551, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.72265625, 'error': 0.24812275546849494, 'precision': 0.17969888295288974, 'tpr': 0.72265625, 'fpr': 0.2868546195652174, 'f1score': 0.28782574873590044, 'norm': 0.41607379244470966, 'payoff': 0.8320489630237852}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8316929133858267, 'error': 0, 'precision': 0.3419668150546338, 'tpr': 0.8316929133858267, 'fpr': 0.1379837067209776, 'f1score': 0.48465729853742473, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8446411012782694, 'error': 0.09125326370757181, 'precision': 0.4301452178267401, 'tpr': 0.8446411012782694, 'fpr': 0.09657981838241535, 'f1score': 0.5700066357000664, 'norm': 0.262791954761878, 'payoff': 0.8284613089456938}, 'training error on original training data and original testing data': {'recall': 0.6053577262332571, 'error': 0, 'precision': 0.5138657792567942, 'tpr': 0.6053577262332571, 'fpr': 0.17999794640106787, 'f1score': 0.5558722063896805, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7704280155642024, 'error': 0.09125326370757181, 'precision': 0.20491591203104786, 'tpr': 0.7704280155642024, 'fpr': 0.2610431532449881, 'f1score': 0.3237277743715512, 'norm': 0.262791954761878, 'payoff': 0.8284613089456938}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8091528724440117, 'error': 0, 'precision': 0.3519695044472681, 'tpr': 0.8091528724440117, 'fpr': 0.1299583793425635, 'f1score': 0.49055489964580873, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8620019436345967, 'error': 0.004809791597750579, 'precision': 0.49887514060742405, 'tpr': 0.8620019436345967, 'fpr': 0.07569450344065924, 'f1score': 0.6319914499465622, 'norm': 0.2733881309444355, 'payoff': 0.731421660653315}, 'training error on original training data and original testing data': {'recall': 0.6018246985988921, 'error': 0, 'precision': 0.506166072896684, 'tpr': 0.6018246985988921, 'fpr': 0.18518137909772892, 'f1score': 0.549866031557011, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8226120857699805, 'error': 0.004809791597750579, 'precision': 0.24393063583815028, 'tpr': 0.8226120857699805, 'fpr': 0.2221844742653304, 'f1score': 0.3762817654926438, 'norm': 0.2733881309444355, 'payoff': 0.731421660653315}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8163064833005894, 'error': 0, 'precision': 0.36304062909567497, 'tpr': 0.8163064833005894, 'fpr': 0.12374809030724834, 'f1score': 0.5025703054127608, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.84106614017769, 'error': 7.397975840679073, 'precision': 0.48657909765848084, 'tpr': 0.84106614017769, 'fpr': 0.07627046746415543, 'f1score': 0.6164978292329957, 'norm': 0.4999173777131576, 'payoff': 7.898058462965916}, 'training error on original training data and original testing data': {'recall': 0.5846153846153846, 'error': 0, 'precision': 0.509703196347032, 'tpr': 0.5846153846153846, 'fpr': 0.1762955361723961, 'f1score': 0.5445952126848606, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.733847637415622, 'error': 7.397975840679073, 'precision': 0.15854166666666666, 'tpr': 0.733847637415622, 'fpr': 0.3433647878942447, 'f1score': 0.26075038547198903, 'norm': 0.4999173777131576, 'payoff': 7.898058462965916}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8212180746561886, 'error': 0, 'precision': 0.3417825020441537, 'tpr': 0.8212180746561886, 'fpr': 0.13664912578509592, 'f1score': 0.48267898383371827, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8458536585365853, 'error': 6.280209013716524, 'precision': 0.4811320754716981, 'tpr': 0.8458536585365853, 'fpr': 0.07940552016985138, 'f1score': 0.6133710647329325, 'norm': 0.6115342857158943, 'payoff': 6.66867472800063}, 'training error on original training data and original testing data': {'recall': 0.5864217776320105, 'error': 0, 'precision': 0.5108571428571429, 'tpr': 0.5864217776320105, 'fpr': 0.1755717362321813, 'f1score': 0.5460375629867156, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8382352941176471, 'error': 6.280209013716524, 'precision': 0.25591140377132593, 'tpr': 0.8382352941176471, 'fpr': 0.21103565365025467, 'f1score': 0.39211190094015136, 'norm': 0.6115342857158943, 'payoff': 6.66867472800063}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.841948310139165, 'error': 0, 'precision': 0.38552571688666365, 'tpr': 0.841948310139165, 'fpr': 0.11446498219433611, 'f1score': 0.528879175772713, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8381046396841066, 'error': 5.702614379084967, 'precision': 0.49018475750577367, 'tpr': 0.8381046396841066, 'fpr': 0.0749130397895987, 'f1score': 0.6185792349726776, 'norm': 0.6451898086495547, 'payoff': 6.057424570435412}, 'training error on original training data and original testing data': {'recall': 0.5872656755009696, 'error': 0, 'precision': 0.5169274537695591, 'tpr': 0.5872656755009696, 'fpr': 0.17494333402019369, 'f1score': 0.5498562566197609, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.8442703232125367, 'error': 5.702614379084967, 'precision': 0.42631058358061324, 'tpr': 0.8442703232125367, 'fpr': 0.09848034637914933, 'f1score': 0.5665461715412422, 'norm': 0.6451898086495547, 'payoff': 6.057424570435412}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8214285714285714, 'error': 0, 'precision': 0.3376984126984127, 'tpr': 0.8214285714285714, 'fpr': 0.14187351241074464, 'f1score': 0.47862767154105734, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8501945525291829, 'error': 0.4550653594771242, 'precision': 0.4932279909706546, 'tpr': 0.8501945525291829, 'fpr': 0.07628270472307169, 'f1score': 0.6242857142857143, 'norm': 0.4016356239031291, 'payoff': 1.053429735573995}, 'training error on original training data and original testing data': {'recall': 0.6139717940308298, 'error': 0, 'precision': 0.5124555160142349, 'tpr': 0.6139717940308298, 'fpr': 0.18264793354527742, 'f1score': 0.55863921217547, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.7573385518590998, 'error': 0.4550653594771242, 'precision': 0.1712768311573357, 'tpr': 0.7573385518590998, 'fpr': 0.31796569876040076, 'f1score': 0.2793719545208446, 'norm': 0.4016356239031291, 'payoff': 1.053429735573995}}
#     records.append(record)
#     record = {'testing error on original training data and original testing data': {'recall': 0.8287937743190662, 'error': 0, 'precision': 0.3459196102314251, 'tpr': 0.8287937743190662, 'fpr': 0.13685015290519878, 'f1score': 0.48811228874248064, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.8526829268292683, 'error': 0.46028645833333337, 'precision': 0.4810126582278481, 'tpr': 0.8526829268292683, 'fpr': 0.08008492569002124, 'f1score': 0.6150598170302604, 'norm': 0.3239408112316269, 'payoff': 1.1363456471017066}, 'training error on original training data and original testing data': {'recall': 0.6066536203522505, 'error': 0, 'precision': 0.5126791620727673, 'tpr': 0.6066536203522505, 'fpr': 0.181631395109924, 'f1score': 0.5557215416791156, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.81648675171737, 'error': 0.46028645833333337, 'precision': 0.2798520013454423, 'tpr': 0.81648675171737, 'fpr': 0.1817332993803582, 'f1score': 0.4168336673346693, 'norm': 0.3239408112316269, 'payoff': 1.1363456471017066}}
#     records.append(record)


    # SA Output
    # (7,9) for delta from 10 to 100 in steps of 10. default is 20.
    record = {'testing error on original training data and original testing data': {'recall': 0.94, 'error': 0, 'precision': 0.7377, 'tpr': 0.94, 'fpr': 0.0908, 'f1score': 0.8266, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.9419, 'error': 0.0784, 'precision': 0.617, 'tpr': 0.9419, 'fpr': 0.1591, 'f1score': 0.7456, 'norm': 0.4155, 'payoff': 0.6629}, 'training error on original training data and original testing data': {'recall': 0.9265, 'error': 0, 'precision': 0.7191, 'tpr': 0.9265, 'fpr': 0.0982, 'f1score': 0.8097, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.9872, 'error': 0.0784, 'precision': 0.9664, 'tpr': 0.9872, 'fpr': 0.0093, 'f1score': 0.9767, 'norm': 0.4155, 'payoff': 0.6629}}
    records.append(record)
    record = {'testing error on original training data and original testing data': {'recall': 0.9544, 'error': 0, 'precision': 0.7228, 'tpr': 0.9544, 'fpr': 0.0997, 'f1score': 0.8226, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.9523, 'error': 0.0606, 'precision': 0.4269, 'tpr': 0.9523, 'fpr': 0.3458, 'f1score': 0.5895, 'norm': 0.4004, 'payoff': 0.6602}, 'training error on original training data and original testing data': {'recall': 0.9519, 'error': 0, 'precision': 0.7177, 'tpr': 0.9519, 'fpr': 0.1021, 'f1score': 0.8184, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.9989, 'error': 0.0606, 'precision': 0.9993, 'tpr': 0.9989, 'fpr': 0.0002, 'f1score': 0.9991, 'norm': 0.4004, 'payoff': 0.6602}}
    records.append(record)
    record = {'testing error on original training data and original testing data': {'recall': 0.9599, 'error': 0, 'precision': 0.7082, 'tpr': 0.9599, 'fpr': 0.1066, 'f1score': 0.8151, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.9501, 'error': 0.0423, 'precision': 0.451, 'tpr': 0.9501, 'fpr': 0.3132, 'f1score': 0.6117, 'norm': 0.531, 'payoff': 0.5113}, 'training error on original training data and original testing data': {'recall': 0.9584, 'error': 0, 'precision': 0.7052, 'tpr': 0.9584, 'fpr': 0.1091, 'f1score': 0.8125, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 1.0, 'error': 0.0423, 'precision': 0.9996, 'tpr': 1.0, 'fpr': 0.0001, 'f1score': 0.9998, 'norm': 0.531, 'payoff': 0.5113}}
    records.append(record)
    record = {'testing error on original training data and original testing data': {'recall': 0.9472, 'error': 0, 'precision': 0.7052, 'tpr': 0.9472, 'fpr': 0.1072, 'f1score': 0.8085, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.9428, 'error': 0.0599, 'precision': 0.4779, 'tpr': 0.9428, 'fpr': 0.2813, 'f1score': 0.6343, 'norm': 0.4005, 'payoff': 0.6594}, 'training error on original training data and original testing data': {'recall': 0.9379, 'error': 0, 'precision': 0.6999, 'tpr': 0.9379, 'fpr': 0.1085, 'f1score': 0.8016, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.9993, 'error': 0.0599, 'precision': 0.9996, 'tpr': 0.9993, 'fpr': 0.0001, 'f1score': 0.9995, 'norm': 0.4005, 'payoff': 0.6594}}
    records.append(record)
    record = {'testing error on original training data and original testing data': {'recall': 0.9624, 'error': 0, 'precision': 0.719, 'tpr': 0.9624, 'fpr': 0.1024, 'f1score': 0.8231, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.9619, 'error': 0.0426, 'precision': 0.4372, 'tpr': 0.9619, 'fpr': 0.3353, 'f1score': 0.6011, 'norm': 0.4942, 'payoff': 0.5484}, 'training error on original training data and original testing data': {'recall': 0.9637, 'error': 0, 'precision': 0.713, 'tpr': 0.9637, 'fpr': 0.1066, 'f1score': 0.8196, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.9996, 'error': 0.0426, 'precision': 1.0, 'tpr': 0.9996, 'fpr': 0.0, 'f1score': 0.9998, 'norm': 0.4942, 'payoff': 0.5484}}
    records.append(record)
    record = {'testing error on original training data and original testing data': {'recall': 0.9475, 'error': 0, 'precision': 0.7204, 'tpr': 0.9475, 'fpr': 0.1011, 'f1score': 0.8185, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.9444, 'error': 0.0692, 'precision': 0.4301, 'tpr': 0.9444, 'fpr': 0.34, 'f1score': 0.5911, 'norm': 0.4301, 'payoff': 0.6391}, 'training error on original training data and original testing data': {'recall': 0.9387, 'error': 0, 'precision': 0.7034, 'tpr': 0.9387, 'fpr': 0.1071, 'f1score': 0.8042, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.9993, 'error': 0.0692, 'precision': 0.9996, 'tpr': 0.9993, 'fpr': 0.0001, 'f1score': 0.9995, 'norm': 0.4301, 'payoff': 0.6391}}
    records.append(record)
    record = {'testing error on original training data and original testing data': {'recall': 0.9618, 'error': 0, 'precision': 0.7347, 'tpr': 0.9618, 'fpr': 0.0939, 'f1score': 0.8331, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.9619, 'error': 0.0428, 'precision': 0.5524, 'tpr': 0.9619, 'fpr': 0.2111, 'f1score': 0.7018, 'norm': 0.2883, 'payoff': 0.7545}, 'training error on original training data and original testing data': {'recall': 0.9669, 'error': 0, 'precision': 0.7299, 'tpr': 0.9669, 'fpr': 0.0978, 'f1score': 0.8318, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.9937, 'error': 0.0428, 'precision': 0.9901, 'tpr': 0.9937, 'fpr': 0.0027, 'f1score': 0.9919, 'norm': 0.2883, 'payoff': 0.7545}}
    records.append(record)
    record = {'testing error on original training data and original testing data': {'recall': 0.9247, 'error': 0, 'precision': 0.7217, 'tpr': 0.9247, 'fpr': 0.0969, 'f1score': 0.8107, 'norm': 1, 'payoff': 0}, 'testing error on original training data and manipulated testing data': {'recall': 0.9223, 'error': 0.0956, 'precision': 0.5471, 'tpr': 0.9223, 'fpr': 0.2068, 'f1score': 0.6868, 'norm': 0.3081, 'payoff': 0.7875}, 'training error on original training data and original testing data': {'recall': 0.9159, 'error': 0, 'precision': 0.7108, 'tpr': 0.9159, 'fpr': 0.1012, 'f1score': 0.8004, 'norm': 1, 'payoff': 1}, 'testing error on manipulated training data and manipulated testing data': {'recall': 0.9719, 'error': 0.0956, 'precision': 0.753, 'tpr': 0.9719, 'fpr': 0.087, 'f1score': 0.8486, 'norm': 0.3081, 'payoff': 0.7875}}
    records.append(record)













    
    l1 = []
    l2 = []
    l3 = []
    
    for record in records:
        l1.append(record['testing error on original training data and original testing data'][str(perfmetric)])
        l2.append(record['testing error on original training data and manipulated testing data'][str(perfmetric)])
        l3.append(record['testing error on manipulated training data and manipulated testing data'][str(perfmetric)])
#         l.append(record['training error on original training data and original testing data']['precision'])
        
    print('Output results for ',perfmetric)
    ttest=stats.ttest_ind(l1,l2,equal_var=True)
    print 't-statistic independent = %6.3f pvalue = %6.4f on manipulated testing' % ttest
#     ttest=stats.ttest_rel(l1,l2)
#     print 't-statistic dependent = %6.3f pvalue = %6.4f' % ttest
    
    ttest=stats.ttest_ind(l1,l3,equal_var=True)
    print 't-statistic independent = %6.3f pvalue = %6.4f on manipulated training and manipulated testing' % ttest

    ttest=stats.ttest_ind(l2,l3,equal_var=True)
    print 't-statistic independent = %6.3f pvalue = %6.4f on manipulated testing and manipulated training/testing' % ttest

    a = np.array([l1,l2,l3])
    friedmantest = stats.friedmanchisquare(*(a[i, :] for i in range(a.shape[0])))
    print 'friedmantest-statistic = %6.3f pvalue = %6.4f' % friedmantest

    print('l1',l1)
    print('l2',l2)
    print('l3',l3)

    print('len(l1)',len(l1))
    print('len(l2)',len(l2))
    print('len(l3)',len(l3))
    print 'Need to have length of l to be 20'



def mnistimages(TrainFile,TestFile,SaveDir):
    images = open(TrainFile).readlines()
    label = 0
    counter = 0
    for line in images:
        print line
        splitline = line.split(',')
        label = splitline[0]
        imarray = np.asfarray(splitline[1:]).reshape((28,28))

        image = Image.fromarray(imarray).convert('RGB').resize((width,height), Image.ANTIALIAS)

        image.save(SaveDir + label + '/' + str(counter) +  '.jpeg')
        counter = counter + 1

        
    images = open(TestFile).readlines()
    for line in images:
        print line
        splitline = line.split(',')
        
        label = splitline[0]
        imarray = np.asfarray(splitline[1:]).reshape((28,28))
        
        image = Image.fromarray(imarray).convert('RGB').resize((width,height), Image.ANTIALIAS)

        image.save(SaveDir + label + '/' + str(counter) +  '.jpeg')
        counter = counter + 1


    

    
if __name__ == '__main__':


#     InDir = '/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/TrainSplit/0/'
    InDir = '/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/TestSplit/0/'
#     resizer(InDir)

    
#     InDir = '/home/aneesh/Documents/AdversarialLearningDatasets/Caltech101/'
#     partitoner(InDir)
#    resizer('/home/aneesh/Documents/AdversarialLearningDatasets/Caltech101/101_ObjectCategories_Train/crocodile/')
#    resizer('/home/aneesh/Documents/AdversarialLearningDatasets/Caltech101/101_ObjectCategories_Train/crocodile_head/')

#    resizer('/home/aneesh/Documents/AdversarialLearningDatasets/Caltech101/101_ObjectCategories_Test/crocodile/')
#    resizer('/home/aneesh/Documents/AdversarialLearningDatasets/Caltech101/101_ObjectCategories_Test/crocodile_head/')
        

    InDir = '/home/aneesh/Documents/AdversarialLearningDatasets/ILSVRC2010/' 
    GameInDir = '/home/aneesh/Documents/AdversarialLearningDatasets/ILSVRC2010/cifar10_data/imagenet2010-batches-bin/'

#     partitoner(InDir)
   
#     resizer(InDir+'TrainSplit/BrownDog/')
#     resizer(InDir+'TrainSplit/BlackDog/')
#   
#     resizer(InDir+'TestSplit/BrownDog/')
#     resizer(InDir+'TestSplit/BlackDog/')

#     resizer(InDir+'TrainSplit/SmallCat/')
#     resizer(InDir+'TestSplit/SmallCat/')

#     binarizer(InDir,'TrainSplit/','train.bin')
#     copyfile(InDir + 'train.bin', GameInDir + 'train.bin')
# #      
#     binarizer(InDir,'TestSplit/','test.bin')
#     copyfile(InDir + 'test.bin', GameInDir + 'test.bin')    generatereports()

#     generatereports()
#     trainplots()
#     ttest()
#     gaplots()
    saplots()


#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/ILSVRC2010/'+'AdversarialSplit/BrownDog/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/ILSVRC2010/'+'AdversarialSplit/SmallCat/')
     
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/ILSVRC2010/'+'TestSplit/BrownDog/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/ILSVRC2010/'+'TestSplit/SmallCat/')
    
#     MnistTrainFile = '/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/mnist_train.csv'
#     MnistTestFile = '/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/mnist_test.csv'
#     SaveDir = '/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/DataJpeg/'
#     mnistimages(MnistTrainFile,MnistTestFile,SaveDir)
    
    
#     InDir = '/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/'
#     partitoner(InDir)

#     resizer('/home/aneesh/Documents/IJCNN Paper/IJCNN/images/Manipulated Images/')

#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/1 and 4/AdversarialSplitTest/1/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/3 and 8/AdversarialSplitTest/3/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/4 and 9/AdversarialSplitTest/4/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/7 and 9/AdversarialSplitTest/7/')
# 
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/1 and 4/AdversarialSplitTrain/1/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/3 and 8/AdversarialSplitTrain/3/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/4 and 9/AdversarialSplitTrain/4/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/7 and 9/AdversarialSplitTrain/7/')
    




#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/2 and 6/AdversarialSplitTest/2/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/2 and 8/AdversarialSplitTest/2/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/5 and 8/AdversarialSplitTest/5/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/6 and 8/AdversarialSplitTest/6/')

#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/2 and 6/AdversarialSplitTrain/2/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/2 and 8/AdversarialSplitTrain/2/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/5 and 8/AdversarialSplitTrain/5/')
#     resizer('/home/aneesh/Documents/AdversarialLearningDatasets/MNISTDatabase/Results/6 and 8/AdversarialSplitTrain/6/')
        